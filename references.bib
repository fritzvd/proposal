@article{Abdulrauf04052021,
  title = {Giving `Teeth' to the {{African Union}} towards Advancing Compliance with Data Privacy Norms},
  author = {Abdulrauf, Lukman Adebisi},
  year = 2021,
  journal = {Information \& Communications Technology Law},
  volume = {30},
  number = {2},
  eprint = {https://doi.org/10.1080/13600834.2021.1849953},
  pages = {87--107},
  publisher = {Routledge},
  doi = {10.1080/13600834.2021.1849953}
}

@article{acquistiPrivacyHumanBehavior2015,
  title = {Privacy and Human Behavior in the Age of Information},
  author = {Acquisti, Alessandro and Brandimarte, Laura and Loewenstein, George},
  year = 2015,
  month = jan,
  journal = {Science},
  volume = {347},
  number = {6221},
  pages = {509--514},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.aaa1465},
  urldate = {2025-09-11},
  abstract = {This Review summarizes and draws connections between diverse streams of empirical research on privacy behavior. We use three themes to connect insights from social and behavioral sciences: people's uncertainty about the consequences of privacy-related behaviors and their own preferences over those consequences; the context-dependence of people's concern, or lack thereof, about privacy; and the degree to which privacy concerns are malleable---manipulable by commercial and governmental interests. Organizing our discussion by these themes, we offer observations concerning the role of public policy in the protection of privacy in the information age.},
  langid = {english}
}

@article{adarkwah2025genai,
  title = {{{GenAI-Infused}} Adult Learning in the Digital Era: {{A}} Conceptual Framework for Higher Education},
  author = {Adarkwah, Michael Agyemang},
  year = 2025,
  journal = {Adult Learning},
  volume = {36},
  number = {3},
  pages = {149--161},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@article{aderibigbe2023artificial,
  title = {Artificial Intelligence in Developing Countries: {{Bridging}} the Gap between Potential and Implementation},
  author = {Aderibigbe, Adebayo Olamide and Ohenhen, Prince Ekong and Nwaobia, Nkechi Keziah and Gidiagba, Joseph Olamide and Ani, Emmanuel Chinedu},
  year = 2023,
  journal = {Computer Science \& IT Research Journal},
  volume = {4},
  number = {3},
  pages = {185--199},
  file = {/Users/fritz/Zotero/storage/WLCZGYUU/Aderibigbe et al. - 2023 - Artificial intelligence in developing countries Bridging the gap between potential and implementati.pdf}
}

@inproceedings{agbozo2018personal,
  title = {Personal Data and Privacy Barriers to E-{{Government}} Adoption, Implementation and Development in {{Sub-Saharan Africa}}},
  booktitle = {International Conference on Electronic Governance and Open Society: {{Challenges}} in Eurasia},
  author = {Agbozo, Ebenezer and Alhassan, Daniel and Spassov, Kamen},
  year = 2018,
  pages = {82--91},
  publisher = {Springer},
  file = {/Users/fritz/Zotero/storage/M8QXV43Y/2019 - Personal Data and Privacy Barriers to E-Government Adoption, Implementation and Development in Sub-S.pdf}
}

@article{almansooriGlobalSurveyAndroid2022,
  title = {A {{Global Survey}} of {{Android Dual-Use Applications Used}} in {{Intimate Partner Surveillance}}},
  author = {Almansoori, Majed and Gallardo, Andrea and Poveda, Julio and Ahmed, Adil and Chatterjee, Rahul},
  year = 2022,
  month = oct,
  journal = {Proceedings on Privacy Enhancing Technologies},
  volume = {2022},
  number = {4},
  pages = {120--139},
  issn = {2299-0984},
  doi = {10.56553/popets-2022-0102},
  urldate = {2025-11-06},
  abstract = {Intimate partner violence (IPV) is a pervasive societal problem that affects millions of people around the world. IPV perpetrators increasingly weaponize digital technologies like mobile applications (``apps'') to spy on, monitor, and harass victims. Surveillance-capable apps can have legitimate use cases, for example, locating children, and are therefore easily available on various mobile app stores like the Google Play Store. Nevertheless, these applications are easily repurposed by abusers to track their victims. The problem of such dual-use apps in IPV is global. However, current understanding of the ecosystem of such apps is limited to English-language apps, potentially limiting its relevance to non-English speaking IPV survivors across the world. In this paper, we study the prevalence of dualuse applications found in 15 languages and 27 countries. We collected 51,868 unique apps in 2020 from the Google Play Store, using queries such as ``track wife's location.'' Through a semi-manual analysis of a subset of these apps, we discovered 854 unique dualuse apps, and estimate that among the apps collected from Google Play, 3,988 are dual-use apps. We found notable differences in app search results, suggested queries, and marketed capabilities of dual-use apps across different languages. For instance, we identified that 18\% of dual-use apps do not have an English description, and 28\% could not be found using English queries. Google Play (cursorily) blocks certain queries referring explicitly to intimate partner surveillance (IPS) to discourage potential abusers, but the blocking efficacy varies across languages. For example, we found that 80\% of explicit IPS queries for English are blocked, but none for Bengali, Chinese, Hindi, Malay, Thai, and Vietnamese. Thus, abusers fluent in those languages can evade such blocking with no effort.},
  copyright = {https://creativecommons.org/licenses/by-nc-nd/3.0/},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/ZKCXJXP3/Almansoori et al. - 2022 - A Global Survey of Android Dual-Use Applications Used in Intimate Partner Surveillance.pdf}
}

@inproceedings{alshugranPreservingStudentPrivacy2025,
  title = {Preserving {{Student Privacy While Leveraging Generative AI}} in {{Higher Education}}},
  booktitle = {2025 {{Northeast Section Conference Proceedings}}},
  author = {Alshugran, Tariq A. and Kloub, Lina H.},
  year = 2025,
  month = mar,
  pages = {54995},
  publisher = {ASEE Conferences},
  address = {University of Bridgeport, Bridgeport, CT},
  doi = {10.18260/1-2-119-54995},
  urldate = {2025-11-11},
  abstract = {The integration of Generative Artificial Intelligence (GenAI) in higher education offers significant opportunities for personalized learning and the development of dynamic educational materials. However, the use of GenAI often involves processing sensitive student data, raising concerns about privacy and regulatory compliance. This paper examines these challenges, highlighting key risks such as data breaches and unauthorized data sharing. A comprehensive solution is proposed involving privacy-preserving technologies and robust data governance frameworks. By integrating anonymization techniques and hybrid AI models, institutions can balance local data processing with cloud-based capabilities, ensuring compliance and accountability. The findings underscore the necessity of strong institutional policies to protect student privacy and foster trust in AI-driven educational innovations.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/5LXESHT8/Alshugran and Kloub - 2025 - Preserving Student Privacy While Leveraging Generative AI in Higher Education.pdf}
}

@misc{amazonWorksAWSSouth2025,
  title = {In the Works -- {{AWS South America}} ({{Chile}}) {{Region}} \textbar{} {{AWS News Blog}}},
  author = {Amazon},
  year = 2025,
  month = may,
  urldate = {2025-12-08},
  chapter = {Announcements},
  howpublished = {https://aws.amazon.com/blogs/aws/coming-soon-aws-south-america-chile-region/}
}

@article{andreePredictingFoodCrises2020,
  title = {Predicting {{Food Crises}}},
  author = {Andree, Bo and Chamorro, Andres and Kraay, Aart and Spencer, Phoebe and Wang, Dieter},
  year = 2020,
  month = sep,
  journal = {World Bank Working Paper},
  volume = {9412},
  doi = {10.1596/1813-9450-9412},
  abstract = {Globally, more than 130 million people are estimated to be in food crisis. These humanitarian disasters are associated with severe impacts on livelihoods that can reverse years of development gains. The existing outlooks of crisis-affected populations rely on expert assessment of evidence and are limited in their temporal frequency and ability to look beyond several months. This paper presents a statistical forecasting approach to predict the outbreak of food crises with sufficient lead time for preventive action. Different use cases are explored related to possible alternative targeting policies and the levels at which finance is typically unlocked. The results indicate that, particularly at longer forecasting horizons, the statistical predictions compare favorably to expert-based outlooks. The paper concludes that statistical models demonstrate good ability to detect future outbreaks of food crises and that using statistical forecasting approaches may help increase lead time for action.},
  file = {/Users/fritz/Zotero/storage/LTFDWW3Y/Andree et al. - 2020 - Predicting Food Crises.pdf}
}

@misc{andreessenWhySoftwareEating2011,
  title = {Why {{Software Is Eating}} the {{World}}},
  author = {Andreessen, Marc},
  year = 2011,
  month = aug,
  journal = {Andreessen Horowitz},
  urldate = {2025-12-04},
  abstract = {Software is eating the world. More than 10 years after the peak of the 1990s dot-com bubble, a dozen or so new Internet companies like Facebook and Twitter are sparking controversy in Silicon Valley, due to their rapidly growing private market valuations, and even the occasional successful IPO. With scars from the heyday of Webvan...},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/TDKU3BKR/why-software-is-eating-the-world.html}
}

@article{anonymousRevealNotReveal1998,
  title = {To {{Reveal}} or {{Not}} to {{Reveal}}: {{A Theoretical Model}} of {{Anonymous Communication}}},
  shorttitle = {To {{Reveal}} or {{Not}} to {{Reveal}}},
  author = {{Anonymous}},
  year = 1998,
  month = nov,
  journal = {Communication Theory},
  volume = {8},
  number = {4},
  pages = {381--407},
  issn = {1050-3293, 1468-2885},
  doi = {10.1111/j.1468-2885.1998.tb00226.x},
  urldate = {2025-11-12},
  copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1.1},
  langid = {english}
}

@misc{anthropicHowYouUse,
  title = {How {{Do You Use Personal Data}} in {{Model Training}}? \textbar{} {{Anthropic Privacy Center}}},
  shorttitle = {How {{Do You Use Personal Data}} in {{Model Training}}?},
  author = {Anthropic},
  urldate = {2025-11-17},
  howpublished = {https://privacy.claude.com/en/articles/10023555-how-do-you-use-personal-data-in-model-training},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/JCPP78JE/10023555-how-do-you-use-personal-data-in-model-training.html}
}

@article{aroba2024systematic,
  title = {Systematic Literature Review on the Application of Precision Agriculture Using Artificial Intelligence by Small-Scale Farmers in {{Africa}} and Its Societal Impact},
  author = {Aroba, Oluwasegun Julius and Rudolph, Michael},
  year = 2024,
  journal = {Journal of Infrastructure, Policy and Development},
  volume = {8},
  number = {13},
  pages = {8872},
  publisher = {EnPress Publisher},
  file = {/Users/fritz/Zotero/storage/DPFJJQ9I/Aroba and Rudolph - 2024 - Systematic literature review on the application of precision agriculture using artificial intelligen.pdf}
}

@article{arora2019general,
  title = {General Data Protection Regulation---{{A}} Global Standard? {{Privacy}} Futures, Digital Activism, and Surveillance Cultures in the {{Global South}}},
  author = {Arora, Payal},
  year = 2019,
  journal = {Surveillance \& Society},
  volume = {17},
  number = {5},
  pages = {717--725},
  file = {/Users/fritz/Zotero/storage/Z4XUP8A9/Arora - 2019 - General data protection regulationâ€”A global standard Privacy futures, digital activism, and surveil.pdf}
}

@book{arora2019next,
  title = {The next Billion Users: {{Digital}} Life beyond the {{West}}},
  author = {Arora, Payal},
  year = 2019,
  publisher = {Harvard University Press}
}

@article{aroraCreativeDataJustice,
  title = {Creative Data Justice: A Decolonial and Indigenous Framework to Assess Creativity and Artificial Intelligence},
  shorttitle = {Creative Data Justice},
  author = {Arora, Payal},
  journal = {Information, Communication \& Society},
  volume = {0},
  number = {0},
  pages = {1--17},
  publisher = {Routledge},
  issn = {1369-118X},
  doi = {10.1080/1369118X.2024.2420041},
  urldate = {2025-08-18},
  abstract = {In the last decade, the Global South has emerged as a significant player in the data economy due to their majority user base, and studying its role is crucial to comprehend the future of AI. As societies grapple with the implications of AI on creative life, there is an opportunity to reevaluate the creative contributions of Global South cultures, ensuring they are acknowledged and foregrounded in the evolving landscape of human and machine creativity. This paper calls for reimagining and restructuring creative value with the emergence of AI enabled technologies by broadening who and what counts as creative in this data-driven era. To democratize creativity, a decolonial and indigenous framework of cross-cultural creative value is needed which critically intersects and examines the relations between creative labor, rights, and learning. The study of the Global South's data economies is important not only to harness its potential but also to address the cross-cultural ethics of building Creative AI tools with data from their underrepresented communities. At its core, the creative data justice framework emphasizes the need to challenge the existing power imbalances in global data governance. This paper proposes that fair creative value can be achieved by drawing inspiration from indigenous systems of care as a counterforce to neoliberal values of efficiency and utility. This framework will help scholars, policymakers and designers in their inclusive approaches to creativity in the age of AI.},
  keywords = {artificial intelligence,Creativity,data justice,decolonial,Global South},
  file = {/Users/fritz/Zotero/storage/4FBFQTGI/Arora - Creative data justice a decolonial and indigenous framework to assess creativity and artificial int.pdf}
}

@article{aroraDecolonizingPrivacyStudies2019,
  title = {Decolonizing {{Privacy Studies}}},
  author = {Arora, Payal},
  year = 2019,
  month = may,
  journal = {Television \& New Media},
  volume = {20},
  number = {4},
  pages = {366--378},
  publisher = {SAGE Publications},
  issn = {1527-4764, 1552-8316},
  doi = {10.1177/1527476418806092},
  urldate = {2025-07-17},
  abstract = {This paper calls for an epistemic disobedience in privacy studies by decolonizing the approach to privacy. As technology companies expand their reach worldwide, the notion of privacy continues to be viewed through an ethnocentric lens. It disproportionately draws from empirical evidence on Western-based, white, and middle-class demographics. We need to break away from the market-driven neoliberal ideology and the Development paradigm long dictating media studies if we are to foster more inclusive privacy policies. This paper offers a set of propositions to de-naturalize and estrange data from demographic generalizations and cultural assumptions, namely, (1) predicting privacy harms through the history of social practice, (2) recalibrating the core-periphery as evolving and moving targets, and (3) de-exoticizing ``natives'' by situating privacy in ludic digital cultures. In essence, decolonizing privacy studies is as much an act of reimagining people and place as it is of dismantling essentialisms that are regurgitated through scholarship.},
  copyright = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/XV79VBXC/Arora - 2019 - Decolonizing Privacy Studies.pdf}
}

@book{aswinGlobalDigitalCultures2019,
  title = {Global {{Digital Cultures}} : {{Perspectives From South Asia}}.},
  author = {Aswin, Punathambekar and Sriram, Mohan},
  year = 2019,
  publisher = {University of Michigan Press},
  abstract = {Digital media histories are part of a global network, and South Asia is a key nexus in shaping the trajectory of digital media in the twenty-first century. Digital platforms like Facebook, WhatsApp, and others are deeply embedded in the daily lives of millions of people around the world, shaping how people engage with others as kin, as citizens, and as consumers. Moving away from Anglo-American and strictly national frameworks, the essays in this book explore the intersections of local, national, regional, and global forces that shape contemporary digital culture(s) in regions like South Asia: the rise of digital and mobile media technologies, the ongoing transformation of established media industries, and emergent forms of digital media practice and use that are reconfiguring sociocultural, political, and economic terrains across the Indian subcontinent. From massive state-driven digital identity projects and YouTube censorship to Tinder and dating culture, from Twitter and primetime},
  isbn = {978-0-472-13140-2},
  file = {/Users/fritz/Zotero/storage/SLQHTRV6/Aswin and Sriram - 2019 - Global Digital Cultures  Perspectives From South Asia..epub}
}

@phdthesis{ba6c49f904d54e7dbe4c9c92e6e4c285,
  title = {Impossible and Inevitable: {{Reconstructing}} the Critique of Business Ethics},
  author = {Meijer, Kim},
  year = 2023,
  month = dec,
  abstract = {Business ethics is a booming subject. Most universities and business schools offer business ethics courses, and many larger businesses have an ethics program in place. Nevertheless, business ethics has a troubled history. The field has been criticized as shallow, simple, and, worst of all, hypocritical. Why, then, is business ethics met with such criticism? Is there something amiss with business ethics in particular, or do other fields of applied ethics face the same criticism? This study set out to address these questions by analyzing the academic critique of business ethics. This examination helps us to develop a better understanding of business ethics itself; that is, of the attempt to apply ethics to business settings. The study starts with a reflection on the early development of business ethics as a `practical' approach to ethics that aimed to appeal strongly to the business world. I show that this development made the field vulnerable to criticism. I then employ a literature review to reconstruct the academic critique of business ethics and to highlight five of its `central problems.' These problems mostly revolve around an alleged misunderstanding of ethics in business ethics. There are critics who frame these problems as specific for business ethics; as if these problems occur in business ethics only. In so doing, business ethics appears to be depicted as the `black sheep' of applied ethics. I, however, hypothesize these problems are related to ethics in general. A problem of ethics in general can be related to each attempt to apply ethics and, therefore, to all fields of applied ethics.Two methods are used to support this hypothesis. A comparative analysis of the critique of business ethics and the critique of bioethics shows that similar problems are related to the latter field. Following this, a hermeneutical study of the philosophical views of Emmanuel Levinas (on the `trauma' of ethics) and Simone de Beauvoir (on the `ambiguity' of ethics) shows that these are indeed problems of ethics in general. Therefore, I conclude these critics are largely mistaken to frame these problems as specific for business ethics and, thus, to depict this field as the `black sheep' of applied ethics. And yet, these critics are not mistaken for bringing these problems to our attention; and for arguing that business ethicists should take these problems seriously. I conclude that it is impossible to resolve these problems but, at the same time, inevitable for fields of applied ethics -- such as business ethics -- to develop approaches to them. Several conditions for approaching these problems are sketched in the epilogue to the study. -De bedrijfsethiek heeft twee gezichten. Aan de ene kant is het een zeer succesvol veld. De meeste universiteiten en hogescholen bieden cursussen bedrijfsethiek aan en vrijwel alle grotere bedrijven hebben een ethiekprogramma (e.g., ethische code of ethiek trainingen). De bedrijfsethiek heeft echter ook een andere kant. Al sinds de oprichting wordt het veld bestookt met felle en fundamentele kritiek. Volgens sommige critici is de moderne bedrijfsethiek niet alleen oppervlakkig en simpel; het is ook een uitermate hypocriet veld. Hoe komt het dat de bedrijfsethiek zo kwetsbaar is voor kritiek? En is deze kritiek alleen van toepassing op bedrijfsethiek, of hebben andere velden van toegepaste ethiek te maken met dezelfde kritiek? Om deze vragen te beantwoorden start ik met een reconstructie van de wetenschappelijke kritiek op de bedrijfsethiek. Ik laat zien dat er ten minste vijf centrale problemen met de bedrijfsethiek zijn. Het gros van deze problemen draait om de notie dat de moderne bedrijfsethiek niet begrijpt waar ethiek over gaat. Er is echter iets merkwaardigs aan deze kritiek; enkele prominente critici presenteren deze problemen alsof ze specifiek zijn voor bedrijfsethiek; alsof deze problemen zich alleen voordoen in dit veld. Hiermee wordt de bedrijfsethiek als het `zwarte schaap' van de toegepaste ethiek neergezet. Ik plaats deze manier van presenteren tussen haakjes en stel dat de problemen van de bedrijfsethiek lijken op problemen van de ethiek in het algemeen. Dit type problemen kan zich voordoen in iedere poging om ethiek toe te passen, en daarmee dus in ieder veld van toegepaste ethiek. Ik gebruik twee methodes om deze hypothese te onderzoeken. Een vergelijkende analyse tussen kritieken op bedrijfsethiek en bio-ethiek laat zien dat de vermeende problemen van de bedrijfsethiek zich in beide velden voordoen. En een hermeneutische studie van argumenten in het werk van Emmanuel Levinas (over ethiek en `trauma') en Simone de Beauvoir (over ethiek en `ambigu\"iteit') toont dat we hier inderdaad te maken hebben met problemen van de ethiek in het algemeen. In tegenstelling tot het beeld dat enkele critici ons voorhouden lijkt de bedrijfsethiek dus niet het `zwarte schaap' van de toegepaste ethiek te zijn. Deze critici hebben echter wel gelijk wanneer zij stellen dat deze problemen zich voordoen in dit veld en dat bedrijfsethici de implicaties van deze problemen moeten onderkennen. Ik concludeer dat het onmogelijk is om deze problemen met ethiek op te lossen maar dat het tegelijkertijd onvermijdelijk is voor velden van toegepaste ethiek om tot een goede benadering van deze problemen te komen. Enkele condities voor een dergelijke benadering worden geschetst in de epiloog.},
  isbn = {978-94-6483-498-7},
  langid = {english},
  school = {Ridderprint BV}
}

@article{baidoo-anuExploringStudentPerspectives2024,
  title = {Exploring Student Perspectives on Generative Artificial Intelligence in Higher Education Learning},
  author = {{Baidoo-Anu}, David and Asamoah, Daniel and Amoako, Isaac and Mahama, Inuusah},
  year = 2024,
  month = jul,
  journal = {Discover Education},
  volume = {3},
  number = {1},
  pages = {98},
  issn = {2731-5525},
  doi = {10.1007/s44217-024-00173-z},
  urldate = {2025-11-19},
  abstract = {This study examined the perspectives of Ghanaian higher education students on the use of ChatGPT. The Students' ChatGPT Experiences Scale (SCES) was developed and validated to evaluate students' perspectives of ChatGPT as a learning tool. A total of 277 students from  universities and colleges participated in the study. Through exploratory factor analysis, a three-factor structure~of students'~perspectives (ChatGPT academic benefits, ChatGPT academic concerns, and accessibility and attitude towards ChatGPT) was identified. A confirmatory factor analysis was carried out to confirm the identified factors. The majority of students are aware of and recognize the potential of Gen AI tools like ChatGPT in supporting their learning. However, a significant number of students reported using ChatGPT mainly for non-academic purposes, citing concerns such as academic policy violations, excessive reliance on technology, lack of originality in assignments, and potential security risks. Students mainly use ChatGPT for assignments rather than for class or group projects. Students noted that they have not received any training on how to use ChatGPT safely and effectively. The implications for policy and practice are discussed in terms of how well-informed policy guidelines and strategies on the use of Gen AI tools like ChatGPT can support teaching and improve student learning.},
  langid = {english},
  keywords = {AI models,ChatGPT,Global south,Higher education,Students' perceptions},
  file = {/Users/fritz/Zotero/storage/8E2C3V2F/Baidoo-Anu et al. - 2024 - Exploring student perspectives on generative artificial intelligence in higher education learning.pdf}
}

@book{ball2020system,
  title = {The System: {{Who}} Owns the Internet, and How It Owns Us},
  author = {Ball, James},
  year = 2020,
  publisher = {Bloomsbury Publishing}
}

@book{ballRoutledgeHandbookSurveillance2014,
  title = {Routledge Handbook of Surveillance Studies},
  editor = {Ball, Kirstie and Haggerty, Kevin D. and Lyon, David},
  year = 2014,
  series = {Routledge International Handbooks},
  edition = {Paperback},
  publisher = {Routledge},
  address = {London and New York},
  isbn = {978-0-415-58883-6 978-1-138-02602-5},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/3K6VJSLZ/Ball et al. - 2014 - Routledge handbook of surveillance studies.pdf}
}

@inproceedings{barthPrivacyContextualIntegrity2006,
  title = {Privacy and Contextual Integrity: Framework and Applications},
  shorttitle = {Privacy and Contextual Integrity},
  booktitle = {2006 {{IEEE Symposium}} on {{Security}} and {{Privacy}} ({{S}}\&{{P}}'06)},
  author = {Barth, A. and Datta, A. and Mitchell, J.C. and Nissenbaum, H.},
  year = 2006,
  pages = {15 pp.-198},
  publisher = {IEEE},
  address = {Berkeley/Oakland, CA},
  doi = {10.1109/SP.2006.32},
  urldate = {2025-11-17},
  abstract = {Contextual integrity is a conceptual framework for understanding privacy expectations and their implications developed in the literature on law, public policy, and political philosophy. We formalize some aspects of contextual integrity in a logical framework for expressing and reasoning about norms of transmission of personal information. In comparison with access control and privacy policy frameworks such as RBAC, EPAL, and P3P, these norms focus on who personal information is about, how it is transmitted, and past and future actions by both the subject and the users of the information. Norms can be positive or negative depending on whether they refer to actions that are allowed or disallowed. Our model is expressive enough to capture naturally many notions of privacy found in legislation, including those found in HIPAA, COPPA, and GLBA. A number of important problems regarding compliance with privacy norms, future requirements associated with specific actions, and relations between policies and legal standards reduce to standard decision procedures for temporal logic.},
  isbn = {978-0-7695-2574-7},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/4XBIS5E9/Barth et al. - 2006 - Privacy and contextual integrity framework and applications.pdf}
}

@article{bartschControlYourFacebook2016,
  title = {Control Your {{Facebook}}: {{An}} Analysis of Online Privacy Literacy},
  shorttitle = {Control Your {{Facebook}}},
  author = {Bartsch, Miriam and Dienlin, Tobias},
  year = 2016,
  month = mar,
  journal = {Computers in Human Behavior},
  volume = {56},
  pages = {147--154},
  issn = {0747-5632},
  doi = {10.1016/j.chb.2015.11.022},
  urldate = {2025-07-16},
  abstract = {For an effective and responsible communication on social network sites (SNSs) users must decide between withholding and disclosing personal information. For this so-called privacy regulation, users need to have the respective skills---in other words, they need to have online privacy literacy. In this study, we discuss factors that potentially contribute to and result from online privacy literacy. In an online questionnaire with 630 Facebook users, we found that people who spend more time on Facebook and who have changed their privacy settings more frequently reported to have more online privacy literacy. People with more online privacy literacy, in turn, felt more secure on Facebook and implemented more social privacy settings. A mediation analysis showed that time spend on Facebook and experience with privacy regulation did not per se increase safety and privacy behavior directly, stressing the importance of online privacy literacy as a mediator to a safe and privacy-enhancing online behavior. We conclude that Internet experience leads to more online privacy literacy, which fosters a more cautious privacy behavior on SNSs.},
  keywords = {Facebook,Media psychology,Privacy literacy,Social network site,Structural equation modeling},
  file = {/Users/fritz/Zotero/storage/UI9IAXWZ/Bartsch and Dienlin - 2016 - Control your Facebook An analysis of online privacy literacy.pdf;/Users/fritz/Zotero/storage/FNT5NN8Y/S0747563215302375.html}
}

@misc{beckerMeasuringImpactEarly20252025,
  title = {Measuring the {{Impact}} of {{Early-2025 AI}} on {{Experienced Open-Source Developer Productivity}}},
  author = {Becker, Joel and Rush, Nate and Barnes, Elizabeth and Rein, David},
  year = 2025,
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2507.09089},
  urldate = {2025-10-21},
  abstract = {Despite widespread adoption, the impact of AI tools on software development in the wild remains understudied. We conduct a randomized controlled trial (RCT) to understand how AI tools at the February-June 2025 frontier affect the productivity of experienced open-source developers. 16 developers with moderate AI experience complete 246 tasks in mature projects on which they have an average of 5 years of prior experience. Each task is randomly assigned to allow or disallow usage of early 2025 AI tools. When AI tools are allowed, developers primarily use Cursor Pro, a popular code editor, and Claude 3.5/3.7 Sonnet. Before starting tasks, developers forecast that allowing AI will reduce completion time by 24\%. After completing the study, developers estimate that allowing AI reduced completion time by 20\%. Surprisingly, we find that allowing AI actually increases completion time by 19\%--AI tooling slowed developers down. This slowdown also contradicts predictions from experts in economics (39\% shorter) and ML (38\% shorter). To understand this result, we collect and evaluate evidence for 20 properties of our setting that a priori could contribute to the observed slowdown effect--for example, the size and quality standards of projects, or prior developer experience with AI tooling. Although the influence of experimental artifacts cannot be entirely ruled out, the robustness of the slowdown effect across our analyses suggests it is unlikely to primarily be a function of our experimental design.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Human-Computer Interaction (cs.HC),I.2,Software Engineering (cs.SE)}
}

@article{beckVarietiesSecondModernity2016,
  title = {Varieties of {{Second Modernity}} and the {{Cosmopolitan Vision}}},
  author = {Beck, Ulrich},
  year = 2016,
  month = dec,
  journal = {Theory, Culture \& Society},
  volume = {33},
  number = {7-8},
  pages = {257--270},
  issn = {0263-2764, 1460-3616},
  doi = {10.1177/0263276416671585},
  urldate = {2025-06-26},
  abstract = {This text was prepared for presentation in Nagoya, Japan, in 2010. Its aim was to explore a dialogue with Asians toward a cosmopolitan sociology. Beginning from the idea of entangled modernities which threaten their own foundations, Ulrich Beck advocated a complete conceptual innovation of sociology in order to better comprehend the fundamental fragility and mutability of societal dynamics shaped by the globalization of capital and risks today. More specifically, he proposed a cosmopolitan turn of sociology: first, by criticizing methodological nationalism; second, by introducing the concept of cosmopolitization; third, by re-mapping social inequalities; fourth, by discussing risk society in the context of East Asian development; and fifth and finally, by proposing a cosmopolitan vision. Along this line, Beck attempted an overview of the researches done on second modern transformation in East Asia and suggested that an active dialogue may be possible when Asians begin to see the West from their perspectives rather than being caught in the Euro-centric and West-hegemonic presuppositions.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/KEPAWJGZ/Beck - 2016 - Varieties of Second Modernity and the Cosmopolitan Vision.pdf}
}

@article{bellemareHowPublishAcademic,
  title = {How to {{Publish}} in {{Academic Journals}}},
  author = {Bellemare, Marc F},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/YU42PE4R/Bellemare - How to Publish in Academic Journals.pdf}
}

@article{belliDigitalSovereigntyBRICS2025,
  title = {Digital {{Sovereignty}} in the {{BRICS Countries How}} the {{Global South}} and {{Emerging Power Alliances Are Reshaping Digital Governance}}},
  author = {Belli, Luca and Jiang, Min},
  year = 2025,
  journal = {Available at SSRN 5204408},
  file = {/Users/fritz/Zotero/storage/MKF9BVLJ/Bennett and Lawrence - communication, society and politics.pdf}
}

@inproceedings{benderDangersStochasticParrots2021,
  title = {On the {{Dangers}} of {{Stochastic Parrots}}: {{Can Language Models Be Too Big}}? ðŸ¦œ},
  shorttitle = {On the {{Dangers}} of {{Stochastic Parrots}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Bender, Emily M. and Gebru, Timnit and {McMillan-Major}, Angelina and Shmitchell, Shmargaret},
  year = 2021,
  month = mar,
  pages = {610--623},
  publisher = {ACM},
  address = {Virtual Event Canada},
  doi = {10.1145/3442188.3445922},
  urldate = {2025-11-06},
  abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
  isbn = {978-1-4503-8309-7},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/BSIJQIZR/Bender et al. - 2021 - On the Dangers of Stochastic Parrots Can Language Models Be Too Big .pdf}
}

@article{birchDataAssetMeasurement2021,
  title = {Data as Asset? {{The}} Measurement, Governance, and Valuation of Digital Personal Data by {{Big Tech}}},
  shorttitle = {Data as Asset?},
  author = {Birch, Kean and Cochrane, {\relax DT} and Ward, Callum},
  year = 2021,
  month = jan,
  journal = {Big Data \& Society},
  volume = {8},
  number = {1},
  pages = {20539517211017308},
  publisher = {SAGE Publications Ltd},
  issn = {2053-9517},
  doi = {10.1177/20539517211017308},
  urldate = {2025-11-19},
  abstract = {Digital personal data is increasingly framed as the basis of contemporary economies, representing an important new asset class. Control over these data assets seems to explain the emergence and dominance of so-called ?Big Tech? firms, consisting of Apple, Microsoft, Amazon, Google/Alphabet, and Facebook. These US-based firms are some of the largest in the world by market capitalization, a position that they retain despite growing policy and public condemnation?or ?techlash??of their market power based on their monopolistic control of personal data. We analyse the transformation of personal data into an asset in order to explore how personal data is accounted for, governed, and valued by Big Tech firms and other political-economic actors (e.g., investors). However, our findings show that Big Tech firms turn ?users? and ?user engagement? into assets through the performative measurement, governance, and valuation of user metrics (e.g., user numbers, user engagement), rather than extending ownership and control rights over personal data per se. We conceptualize this strategy as a form of ?techcraft? to center attention on the means and mechanisms that Big Tech firms deploy to make users and user data measurable and legible as future revenue streams.},
  file = {/Users/fritz/Zotero/storage/B5IIHY6Y/Birch et al. - 2021 - Data as asset The measurement, governance, and valuation of digital personal data by Big Tech.pdf}
}

@article{bovzic2023artifical,
  title = {Artifical Intelligence as the Reason and the Solution of Digital Divide},
  author = {Bo{\v z}i{\'c}, Velibor},
  year = 2023,
  journal = {Language Education and Technology},
  volume = {3},
  number = {2},
  file = {/Users/fritz/Zotero/storage/7T67KMMH/BoÅ¾iÄ‡ - 2023 - Artifical intelligence as the reason and the solution of digital divide.pdf}
}

@inproceedings{boyd2011six,
  title = {Six Provocations for Big Data},
  booktitle = {A Decade in Internet Time: {{Symposium}} on the Dynamics of the Internet and Society},
  author = {Boyd, Danah and Crawford, Kate},
  year = 2011,
  file = {/Users/fritz/Zotero/storage/HBRLSYPA/Boyd and Crawford - 2011 - Six provocations for big data.pdf}
}

@inproceedings{boyd2011social,
  title = {Social Privacy in Networked Publics: {{Teens}}' Attitudes, Practices, and Strategies},
  booktitle = {A Decade in Internet Time: {{Symposium}} on the Dynamics of the Internet and Society},
  author = {Boyd, Danah and Marwick, Alice E},
  year = 2011,
  file = {/Users/fritz/Zotero/storage/6LLT69FC/Boyd and Marwick - 2011 - Social privacy in networked publics Teensâ€™ attitudes, practices, and strategies.pdf}
}

@incollection{brevini2024critiques,
  title = {Critiques of Data Colonialism},
  booktitle = {Dialogues in Data Power},
  author = {Brevini, Benedetta and {Fubara-Manuel}, Irene and Le Ludec, Cl{\'e}ment and Jensen, Jakob Linaa and Jimenez, Andrea and Bates, Jo},
  year = 2024,
  pages = {120--137},
  publisher = {Bristol University Press},
  file = {/Users/fritz/Zotero/storage/WFCS6AWP/Brevini et al. - 2024 - Critiques of data colonialism.pdf}
}

@article{broughPhysicalDigitalPrivacy2023,
  title = {Physical and {{Digital Privacy}}: {{How Developed}} and {{Developing Countries Differ}} in {{Both Vulnerability}} and {{Protection}}},
  shorttitle = {Physical and {{Digital Privacy}}},
  author = {Brough, Aaron R. and Kamleitner, Bernadette and Martin, Kelly D.},
  year = 2023,
  month = dec,
  journal = {Journal of International Marketing},
  volume = {31},
  number = {4},
  pages = {76--79},
  issn = {1069-031X, 1547-7215},
  doi = {10.1177/1069031X231201362},
  urldate = {2025-09-11},
  langid = {english}
}

@misc{browneGoogleInvest$12024,
  title = {Google to Invest \$1 Billion in {{Thailand}} to Build Data Center and Accelerate {{AI}} Growth},
  author = {Browne, Ryan},
  year = 2024,
  month = sep,
  journal = {CNBC},
  urldate = {2025-12-08},
  abstract = {Google is investing 36 billion Thai baht, or \$1 billion, into Thailand to build a new data center and expand its cloud infrastructure, the company said Monday.},
  chapter = {Technology},
  howpublished = {https://www.cnbc.com/2024/09/30/google-to-invest-1-billion-in-thailand-data-center-and-ai-push.html},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/PS5FUBVV/google-to-invest-1-billion-in-thailand-data-center-and-ai-push.html}
}

@article{burnsMomentsClosureKnowledge2014,
  title = {Moments of Closure in the Knowledge Politics of Digital Humanitarianism},
  author = {Burns, Ryan},
  year = 2014,
  month = may,
  journal = {Geoforum},
  volume = {53},
  pages = {51--62},
  issn = {00167185},
  doi = {10.1016/j.geoforum.2014.02.002},
  urldate = {2025-10-16},
  abstract = {Geographers interested in the social and political implications of the geoweb have recently turned their attention to its attendant ``knowledge politics''. Such work looks at the processes and discrete moments in development that led to certain knowledges being represented and other knowledges remaining invisible. In this paper I build on these conversations by exploring the knowledge politics of digital humanitarianism. Digital humanitarianism, a technological corollary to the geoweb, is the set of social and institutional networks, technologies, and practices that enable large numbers of remote and on-theground individuals to collaborate on humanitarian projects. Specifically, in this paper I offer 4 ``moments of closure'' when knowledge politics have been negotiated, enacted, and made durable in digital humanitarianism. These moments of closure constellate around the themes of inclusion, categorization, accuracy, and visibility. I then consider the implications of these moments for the kinds of epistemologies digital humanitarianism espouses, and how knowledges come to be represented. I argue that these knowledge politics -- the struggles for legitimacy and means of representation -- are fluid and contested, yet become more stable when implemented through technology. Through these processes digital humanitarianism, and by extension the geoweb, embodies the social relations that first produced the debates around knowledge representation.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/NJNNR7DV/Burns - 2014 - Moments of closure in the knowledge politics of digital humanitarianism.pdf}
}

@article{burnsRethinkingBigData2015,
  title = {Rethinking Big Data in Digital Humanitarianism: Practices, Epistemologies, and Social Relations},
  shorttitle = {Rethinking Big Data in Digital Humanitarianism},
  author = {Burns, Ryan},
  year = 2015,
  month = aug,
  journal = {GeoJournal},
  volume = {80},
  number = {4},
  pages = {477--490},
  issn = {0343-2521, 1572-9893},
  doi = {10.1007/s10708-014-9599-x},
  urldate = {2025-10-16},
  abstract = {Spatial technologies and the organizations around them, such as the Standby Task Force and Ushahidi, are increasingly changing the ways crises and emergencies are addressed. Within digital humanitarianism, Big Data has featured strongly in recent efforts to improve digital humanitarian work. This shift toward social media and other Big Data sources has entailed unexamined assumptions about technological progress, social change, and the kinds of knowledge captured by data. These assumptions stand in tension with critical geographic scholarship, and in particular critical GIS research. In this paper I borrow from critical research on technologies to engage three important new facets of Big Data emerging from an interrogation of digital humanitarianism. I argue first that within digital humanitarianism, Big Data should be understood as a new set of practices, in addition to its usual conception as data and analytics technologies. Second, I argue that Big Data constitutes a distinct epistemology that obscures many forms of knowledge in crises and emergencies and produces a limited understanding of how a crisis is unfolding. Third, I argue that Big Data is constitutive of a social relation in which both the formal humanitarian sector and ``victims'' of crises are in need of the services and labor that can be provided by digital humanitarians.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/JMP26BHC/Burns - 2015 - Rethinking big data in digital humanitarianism practices, epistemologies, and social relations.pdf}
}

@misc{calzadaGenerativeAIUrban2025,
  type = {{{SSRN Scholarly Paper}}},
  title = {Generative {{AI}} and the {{Urban AI Policy Challenges Ahead}}: {{Trustworthy}} for {{Whom}}?},
  shorttitle = {Generative {{AI}} and the {{Urban AI Policy Challenges Ahead}}},
  author = {Calzada, Igor},
  year = 2025,
  month = oct,
  number = {5594632},
  eprint = {5594632},
  publisher = {Social Science Research Network},
  address = {Rochester, NY},
  urldate = {2025-12-08},
  abstract = {This Special Issue of TGPPP addresses the accelerating convergence between GenAI, Urban AI, and public governance. As algorithmic systems are deployed across domains such as transport, welfare, housing, education, and security, cities become both laboratories of innovation and battlegrounds of democratic legitimacy. Trustworthy AI has emerged as a policy imperative-but the question remains: trustworthy for whom? Rather than treating trust as a static feature of technical systems, this Special Issue reframes it as a relational, contested, and institutionally mediated concept-fundamental to the legitimacy of public action in the digital age. Contributions are encouraged that explore GenAI not only as a technological advance, but as a governance challenge that reconfigures discretion, authority, and the social contract between citizens and institutions. Inspired by Richard R. Nelson's enduring metaphor of "The Moon and the Ghetto"-which captures the asymmetries between technological sophistication and social equity-this Special Issue invites a renewed interrogation of how AI policy can bridge systemic inequalities rather than entrench them. Urban governance frameworks must move beyond techno-solutionism to embed pluralism, accountability, and public value at the core of GenAI deployments. Scholars, policymakers, and practitioners are invited to submit empirical, theoretical, and policy-oriented contributions that critically examine how Urban AI can be governed with legitimacy, reflexivity, and justice.},
  archiveprefix = {Social Science Research Network},
  langid = {english},
  keywords = {AI Economics,Algorithmic Governance,Applied Economics,Digital Inclusion,Epistemic Authority,Generative AI,Innovation Policies,Innovation Systems,Public Policy,Smart Cities,Trustworthy AI,Urban AI}
}

@article{camberoAmazonSpend$42025,
  title = {Amazon to Spend \$4 Billion on Cloud Infrastructure in {{Chile}}},
  author = {Cambero, Fabian},
  year = 2025,
  month = may,
  journal = {Reuters},
  urldate = {2025-12-08},
  abstract = {Amazon's cloud computing division will invest \$4 billion to build its first data centers and other cloud infrastructure in Chile, the company's head of South Latin America told Reuters.},
  chapter = {Energy},
  langid = {english}
}

@book{capurroDigitalWhonessIdentity2013,
  title = {Digital {{Whoness}}: {{Identity}}, {{Privacy}} and {{Freedom}} in the {{Cyberworld}}},
  shorttitle = {Digital {{Whoness}}},
  author = {Capurro, Rafael and Eldred, Michael and Nagel, Daniel},
  year = 2013,
  month = dec,
  publisher = {DE GRUYTER},
  doi = {10.1515/9783110320428},
  urldate = {2025-11-21},
  isbn = {978-3-11-032012-1 978-3-11-032042-8},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/UB4VQ2NZ/Capurro et al. - 2013 - Digital Whoness Identity, Privacy and Freedom in the Cyberworld.pdf}
}

@misc{carliniExtractingTrainingData2021,
  title = {Extracting {{Training Data}} from {{Large Language Models}}},
  author = {Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and {Herbert-Voss}, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Ulfar and Oprea, Alina and Raffel, Colin},
  year = 2021,
  month = jun,
  number = {arXiv:2012.07805},
  eprint = {2012.07805},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2012.07805},
  urldate = {2025-11-17},
  abstract = {It has become common to publish large (billion parameter) language models that have been trained on private datasets. This paper demonstrates that in such settings, an adversary can perform a training data extraction attack to recover individual training examples by querying the language model. We demonstrate our attack on GPT-2, a language model trained on scrapes of the public Internet, and are able to extract hundreds of verbatim text sequences from the model's training data. These extracted examples include (public) personally identifiable information (names, phone numbers, and email addresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible even though each of the above sequences are included in just one document in the training data. We comprehensively evaluate our extraction attack to understand the factors that contribute to its success. Worryingly, we find that larger models are more vulnerable than smaller models. We conclude by drawing lessons and discussing possible safeguards for training large language models.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  file = {/Users/fritz/Zotero/storage/B6LJPQB5/Carlini et al. - 2021 - Extracting Training Data from Large Language Models.pdf;/Users/fritz/Zotero/storage/ZDDAUVIJ/2012.html}
}

@article{carterExploringIntersectionDigital2020,
  title = {Exploring the {{Intersection}} of the {{Digital Divide}} and {{Artificial Intelligence}}: {{A Hermeneutic Literature Review}}},
  shorttitle = {Exploring the {{Intersection}} of the {{Digital Divide}} and {{Artificial Intelligence}}},
  author = {Carter, Lemuria and Liu, Dapeng and Cantrell, Caley},
  year = 2020,
  month = dec,
  journal = {AIS Transactions on Human-Computer Interaction},
  volume = {12},
  number = {4},
  pages = {253--275},
  issn = {1944-3900},
  doi = {10.17705/1thci.00138},
  file = {/Users/fritz/Zotero/storage/62QHVNNP/Carter et al. - 2020 - Exploring the Intersection of the Digital Divide and Artificial Intelligence A Hermeneutic Literatu.pdf;/Users/fritz/Zotero/storage/BNX2VTXS/5.html}
}

@article{casilli2017global,
  title = {Digital Labor Studies Go Global: {{Toward}} a Digital Decolonial Turn},
  author = {Casilli, Antonio A},
  year = 2017,
  journal = {International Journal of Communication},
  volume = {11},
  pages = {21},
  file = {/Users/fritz/Zotero/storage/ECZPAC5W/Casilli - 2017 - Digital labor studies go global Toward a digital decolonial turn.pdf}
}

@techreport{cerutti2025global,
  title = {The Global Impact of {{AI}}: {{Mind}} the Gap},
  author = {Cerutti, Eugenio and Pascual, Antonio Garcia and Kido, Yosuke and Li, Longji and Melina, Giovanni and Tavares, Marina Mendes and Wingender, Philippe},
  year = 2025,
  institution = {International Monetary Fund},
  file = {/Users/fritz/Zotero/storage/8RZQPR7A/Cerutti et al. - 2025 - The global impact of AI Mind the gap.pdf}
}

@misc{ChatCopilotOutlook,
  title = {Chat with {{Copilot}} in {{Outlook}} - {{Microsoft Support}}},
  urldate = {2025-11-06},
  howpublished = {https://support.microsoft.com/en-us/topic/chat-with-copilot-in-outlook-8090e7b3-5b1d-4c6d-9b06-02edac062f58},
  file = {/Users/fritz/Zotero/storage/GL24TN42/chat-with-copilot-in-outlook-8090e7b3-5b1d-4c6d-9b06-02edac062f58.html}
}

@misc{cheungRealityCheckBenefits2024,
  title = {A {{Reality}} Check of the Benefits of {{LLM}} in Business},
  author = {Cheung, Ming},
  year = 2024,
  month = jun,
  number = {arXiv:2406.10249},
  eprint = {2406.10249},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.10249},
  urldate = {2025-11-17},
  abstract = {Large language models (LLMs) have achieved remarkable performance in language understanding and generation tasks by leveraging vast amounts of online texts. Unlike conventional models, LLMs can adapt to new domains through prompt engineering without the need for retraining, making them suitable for various business functions, such as strategic planning, project implementation, and data-driven decision-making. However, their limitations in terms of bias, contextual understanding, and sensitivity to prompts raise concerns about their readiness for real-world applications. This paper thoroughly examines the usefulness and readiness of LLMs for business processes. The limitations and capacities of LLMs are evaluated through experiments conducted on four accessible LLMs using real-world data. The findings have significant implications for organizations seeking to leverage generative AI and provide valuable insights into future research directions. To the best of our knowledge, this represents the first quantified study of LLMs applied to core business operations and challenges.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/fritz/Zotero/storage/3X77MF6C/Cheung - 2024 - A Reality check of the benefits of LLM in business.pdf;/Users/fritz/Zotero/storage/ZDEBXGNB/2406.html}
}

@misc{chiangMicrosoftOpenNew2024,
  title = {Microsoft to Open New Data Center in {{Thailand}} as It Doubles down on {{AI}} and {{Southeast Asia}}},
  author = {Chiang, Sheila},
  year = 2024,
  month = may,
  journal = {CNBC},
  urldate = {2025-12-08},
  abstract = {The U.S. tech giant said it will also commit toward AI skills training for over 100,000 Thais and support local developers.},
  chapter = {Technology},
  howpublished = {https://www.cnbc.com/2024/05/02/microsoft-to-open-data-center-in-thailand-amid-southeast-asia-expansion.html},
  langid = {english}
}

@article{cinnamon2020attack,
  title = {Attack the Data: {{Agency}}, Power, and Technopolitics in {{South African}} Data Activism},
  author = {Cinnamon, Jonathan},
  year = 2020,
  journal = {Annals of the American Association of Geographers},
  volume = {110},
  number = {3},
  pages = {623--639},
  publisher = {Taylor \& Francis},
  file = {/Users/fritz/Zotero/storage/4XZPRA96/Attack_the_Data_Agency_Power_and_Technopolitics_in_South_African_Data_Activism.html}
}

@article{cirucci2015redefining,
  title = {Redefining Privacy and Anonymity through Social Networking Affordances},
  author = {Cirucci, Angela M},
  year = 2015,
  journal = {First Monday}
}

@article{clark-gordonAnonymityOnlineSelfDisclosure2019,
  title = {Anonymity and {{Online Self-Disclosure}}: {{A Meta-Analysis}}},
  shorttitle = {Anonymity and {{Online Self-Disclosure}}},
  author = {{Clark-Gordon}, Cathlin V. and Bowman, Nicholas D. and Goodboy, Alan K. and Wright, Alyssa},
  year = 2019,
  month = may,
  journal = {Communication Reports},
  volume = {32},
  number = {2},
  pages = {98--111},
  issn = {0893-4215, 1745-1043},
  doi = {10.1080/08934215.2019.1607516},
  urldate = {2025-11-12},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/DW758U4E/Clark-Gordon et al. - 2019 - Anonymity and Online Self-Disclosure A Meta-Analysis.pdf}
}

@article{coleman2018digital,
  title = {Digital Colonialism: {{The}} 21st Century Scramble for {{Africa}} through the Extraction and Control of User Data and the Limitations of Data Protection Laws},
  author = {Coleman, Danielle},
  year = 2018,
  journal = {Mich. J. Race \& L.},
  volume = {24},
  pages = {417},
  publisher = {HeinOnline}
}

@article{couldryDataColonialismRethinking2019,
  title = {Data {{Colonialism}}: {{Rethinking Big Data}}'s {{Relation}} to the {{Contemporary Subject}}},
  shorttitle = {Data {{Colonialism}}},
  author = {Couldry, Nick and Mejias, Ulises A.},
  year = 2019,
  month = may,
  journal = {Television \& New Media},
  volume = {20},
  number = {4},
  pages = {336--349},
  issn = {1527-4764, 1552-8316},
  doi = {10.1177/1527476418796632},
  urldate = {2025-12-02},
  abstract = {We are often told that data are the new oil. But unlike oil, data are not a substance found in nature. It must be appropriated. The capture and processing of social data unfolds through a process we call data relations, which ensures the ``natural'' conversion of daily life into a data stream. The result is nothing less than a new social order, based on continuous tracking, and offering unprecedented new opportunities for social discrimination and behavioral influence. We propose that this process is best understood through the history of colonialism. Thus, data relations enact a new form of data colonialism, normalizing the exploitation of human beings through data, just as historic colonialism appropriated territory and resources and ruled subjects for profit. Data colonialism paves the way for a new stage of capitalism whose outlines we only glimpse: the capitalization of life without limit.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/BWWMQAH8/Couldry and Mejias - 2019 - Data colonialism Rethinking big dataâ€™s relation to the contemporary subject.pdf;/Users/fritz/Zotero/storage/QRFTE8S7/Couldry and Mejias - 2019 - Data Colonialism Rethinking Big Dataâ€™s Relation to the Contemporary Subject.pdf}
}

@article{couldryMakingDataColonialism2019,
  title = {Making Data Colonialism Liveable: How Might Data's Social Order Be Regulated?},
  shorttitle = {Making Data Colonialism Liveable},
  author = {Couldry, Nick and Mejias, Ulises A.},
  year = 2019,
  month = jun,
  journal = {Internet Policy Review},
  volume = {8},
  number = {2},
  issn = {2197-6775},
  doi = {10.14763/2019.2.1411},
  urldate = {2025-07-05},
  abstract = {Humanity is currently undergoing a large-scale social, economic and legal transformation based on the massive appropriation of social life through data extraction. This quantification of the social represents a new colonial move. While the modes, intensities, scales and contexts of dispossession have changed, the underlying drive of today's data colonialism remains the same: to acquire ``territory'' and resources from which economic value can be extracted by capital. The injustices embedded in this system need to be made ``liveable'' through a new legal and regulatory order.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/TZ6HE2HR/Couldry and Mejias - 2019 - Making data colonialism liveable how might dataâ€™s social order be regulated.pdf}
}

@book{crawford2021atlas,
  title = {The Atlas of {{AI}}: {{Power}}, Politics, and the Planetary Costs of Artificial Intelligence},
  author = {Crawford, Kate},
  year = 2021,
  publisher = {Yale University Press}
}

@incollection{cukierRiseBigData2014,
  title = {The {{Rise}} of {{Big Data}}: {{How It}}'s {{Changing}} the {{Way We Think}} about the {{World}}},
  shorttitle = {The {{Rise}} of {{Big Data}}},
  booktitle = {The {{Best Writing}} on {{Mathematics}} 2014},
  author = {Cukier, Kenneth and {Mayer-Sch{\"o}nberger}, Viktor},
  editor = {Pitici, Mircea},
  year = 2014,
  month = dec,
  pages = {20--32},
  publisher = {Princeton University Press},
  doi = {10.1515/9781400865307-003},
  urldate = {2025-12-08},
  isbn = {978-1-4008-6530-7},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/7ILJRXYF/Cukier and Mayer-SchÃ¶nberger - 2014 - The Rise of Big Data How Itâ€™s Changing the Way We Think about the World.pdf}
}

@article{dakakniArtificialIntelligenceTool2025,
  title = {Artificial Intelligence as a Tool for Data, Economic and Political Hegemony: Releasing the Djinn},
  shorttitle = {Artificial Intelligence as a Tool for Data, Economic and Political Hegemony},
  author = {Dakakni, D},
  year = 2025,
  month = feb,
  journal = {Ethics in Science and Environmental Politics},
  volume = {25},
  pages = {1--10},
  issn = {1863-5415, 1611-8014},
  doi = {10.3354/esep00216},
  urldate = {2025-10-20},
  abstract = {Artificial intelligence, while presenting itself as a novelty in the fields of education, science and the business industry, is likely being used as a hegemonic tool for economic and political control. Concerns about privacy ethics, class division and the specter of AI-incited biowarfare controlled by supremacist-minded entities that benefit from the datafication of individuals for economic profit and the attainment of politicized control-seeking objectives are the axial arguments of this position paper. As a result, this review makes a case that AI is being used as a tool of hegemony by presenting an analytical framework derived from the `less mainstream' varied corpus of literature published between 1984 and 2024. Furthermore, while the literature also reveals attempts to monitor misuse of AI, to date there have been no solutions offered concerning privacy and surveillance, alternatives to the potential loss of jobs through automated AI or the menace of AI-operated biological warfare already being tested in war-torn parts of the world. Resolving the existing hegemonic challenges is of paramount importance and must be properly addressed in order not to be met with an existential crisis threatening the continuity of humanity.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/8FZDI79U/Dakakni - 2025 - Artificial intelligence as a tool for data, economic and political hegemony releasing the djinn.pdf}
}

@article{damilola2022fintech,
  title = {{{FinTech}} and Financial Inclusionin West Africa: {{Nigeria}}'s Smes Market},
  author = {Damilola, Arotile Omolabake},
  year = 2022,
  journal = {International Journal of Multidisciplinary and Current Educational Research},
  volume = {4},
  pages = {210--2018}
}

@article{de2024artificial,
  title = {Artificial Intelligence Solutions to Reduce Information Asymmetry for {{Colombian}} Cocoa Small-Scale Farmers},
  author = {{De la Pe{\~n}a}, Nicolas and Granados, Oscar M},
  year = 2024,
  journal = {Information Processing in Agriculture},
  volume = {11},
  number = {3},
  pages = {310--324},
  publisher = {Elsevier}
}

@article{defranceschiDataTradeableCommodity2015,
  title = {Data as {{Tradeable Commodity}} and {{New Measures}} for {{Their Protection Essays}}},
  author = {De Franceschi, Alberto and Lehmann, Michael},
  year = 2015,
  journal = {Italian Law Journal},
  volume = {1},
  number = {1},
  pages = {51--72},
  urldate = {2025-12-08},
  abstract = {Disclaimer: This summary was generated by AI based on the content of the source document.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/S7ZD6VLS/De Franceschi and Lehmann - 2015 - Data as Tradeable Commodity and New Measures for Their Protection Essays.pdf}
}

@inproceedings{dingSustainableLLMServing2024,
  title = {Sustainable {{LLM Serving}}: {{Environmental Implications}}, {{Challenges}}, and {{Opportunities}} : {{Invited Paper}}},
  shorttitle = {Sustainable {{LLM Serving}}},
  booktitle = {2024 {{IEEE}} 15th {{International Green}} and {{Sustainable Computing Conference}} ({{IGSC}})},
  author = {Ding, Yi and Shi, Tianyao},
  year = 2024,
  month = nov,
  pages = {37--38},
  publisher = {IEEE},
  address = {Austin, TX, USA},
  doi = {10.1109/IGSC64514.2024.00016},
  urldate = {2025-11-06},
  abstract = {Large language models (LLMs) have been widely used for their ability to handle complex natural language tasks with high accuracy. The lifecycle of LLMs development and deployment encompasses both training and serving phases. Although training takes months and consumes significant amounts of energy, recent studies show that the energy consumption of LLM serving has now surpassed that of training, leading to significant environmental impacts, especially in terms of carbon footprints. While much prior work has focused on improving LLM performance, the specific challenge of reducing the carbon footprint of LLM serving has been largely overlooked. This paper identifies key challenges and outlines research directions for making LLM serving more sustainable, aiming to inspire further environmentally responsible advancements in the field.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {979-8-3315-0786-2},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/PYM8NC2J/Ding and Shi - 2024 - Sustainable LLM Serving Environmental Implications, Challenges, and Opportunities  Invited Paper.pdf}
}

@misc{DoesChatGPTYour,
  title = {Does {{ChatGPT}} Save Your Data? (+ Other Data Privacy Concerns)},
  shorttitle = {Does {{ChatGPT}} Save Your Data?},
  urldate = {2025-11-17},
  abstract = {Learn more about how using ChatGPT impacts your data privacy, as well as information about OpenAI's Privacy Portal.},
  howpublished = {https://botpress.com/blog/does-chatgpt-save-data},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/ZJQHIQMQ/does-chatgpt-save-data.html}
}

@article{draperPrivacyResignationApathy2024,
  title = {Privacy Resignation, Apathy, and Cynicism: {{Introduction}} to a Special Theme},
  shorttitle = {Privacy Resignation, Apathy, and Cynicism},
  author = {Draper, Nora A and Pieter Hoffmann, Christian and Lutz, Christoph and Ranzini, Giulia and Turow, Joseph},
  year = 2024,
  month = sep,
  journal = {Big Data \& Society},
  volume = {11},
  number = {3},
  pages = {20539517241270663},
  publisher = {SAGE Publications Ltd},
  issn = {2053-9517},
  doi = {10.1177/20539517241270663},
  urldate = {2025-11-06},
  abstract = {The growing trend of collecting data about individuals to track past actions and infer future attitudes and behaviors has fueled popular and scholarly interest in the erosion of privacy. Recent shifts in technologies around machine learning and artificial intelligence have intensified these concerns. This editorial introduces the articles in the special theme on digital resignation and privacy cynicism: concepts developed in the past decade to explain the growing powerlessness individuals feel in relation to their digital privacy even as they continue to experience consternation over the collection and use of their personal information. The papers in this special theme engage and extend existing research on these topics. The original articles and commentaries pose theoretical and practical questions related to the ways people confront the powerful institutional forces that increasingly shape many aspects of the information environment. They employ several methodologies and theoretical perspectives and extend the range of geographic, political, cultural, and institutional contexts in which privacy cynicism and digital resignation can be identified and examined. In addition to contextualizing these contributions, this editorial maps a range of related concepts including digital resignation, privacy cynicism, privacy apathy, surveillance realism, privacy fatigue, and privacy helplessness. It concludes by identifying key themes across the papers in this collection and provides directions for future research.},
  file = {/Users/fritz/Zotero/storage/58V9WZGN/Draper et al. - 2024 - Privacy resignation, apathy, and cynicism Introduction to a special theme.pdf}
}

@misc{duckduckgoDuckaiDuckDuckGoHelp,
  title = {Duck.Ai - {{DuckDuckGo Help Pages}}},
  author = {{DuckDuckGo}},
  urldate = {2025-11-06},
  abstract = {Duck.ai allows you to chat anonymously with 3rd-party AI chat models for free.},
  howpublished = {https://duckduckgo.com/duckduckgo-help-pages/duckai},
  langid = {english}
}

@article{edsjsr.4392113820160101,
  title = {Data Hubris? {{Humanitarian}} Information Systems and the Mirage of Technology},
  author = {Read, R{\'o}is{\'s}n and Taithe, Bertrand and Mac Ginty, Roger},
  year = 2016,
  journal = {Third World Quarterly},
  volume = {37},
  number = {8},
  pages = {1314--1331},
  issn = {01436597; 13602241},
  abstract = {This article looks at the promise of technology to revolutionise humanitarian action, especially in terms of the gathering and use of data. With many heralding a 'data revolution', the opportunities and enthusiasm for using social media and SMS data in crisis response are on the rise. The article constructs an analytical framework in order to scrutinise the three main claims made on behalf of technologically advanced humanitarian information systems: that they can access data more accurately, more quickly, and alter power relations in emancipatory ways. It does so in relation to two aspects of digital humanitarianism: visual technology and crisis mapping, and big data. The article is partly informed by a historical perspective, but also by interview and other material that suggests some of the claims made on behalf of technology are exaggerated. In particular, we argue that the enthusiasm for the data is vastly outstripped by the capacity to meaningfully analyse it. We conclude by sco}
}

@article{enenkel2016combined,
  title = {A Combined Satellite-Derived Drought Indicator to Support Humanitarian Aid Organizations},
  author = {Enenkel, Markus and Steiner, Caroline and Mistelbauer, Thomas and Dorigo, Wouter and Wagner, Wolfgang and See, Linda and Atzberger, Clement and Schneider, Stefan and Rogenhofer, Edith},
  year = 2016,
  journal = {Remote Sensing},
  volume = {8},
  number = {4},
  pages = {340},
  publisher = {MDPI}
}

@article{farraj2010refugees,
  title = {Refugees and the Biometric Future: The Impact of Biometrics on Refugees and Asylum Seekers},
  author = {Farraj, Achraf},
  year = 2010,
  volume = {42},
  pages = {891},
  publisher = {HeinOnline},
  file = {/Users/fritz/Zotero/storage/ZGFNTUNI/refugees-and-the-biometric-future-the-impact-of-biometrics-on-refugees-and-asylum-seekers.pdf}
}

@article{ferraraGenAIHumanityNefarious2024,
  title = {{{GenAI}} against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models},
  shorttitle = {{{GenAI}} against Humanity},
  author = {Ferrara, Emilio},
  year = 2024,
  month = apr,
  journal = {Journal of Computational Social Science},
  volume = {7},
  number = {1},
  pages = {549--569},
  issn = {2432-2717, 2432-2725},
  doi = {10.1007/s42001-024-00250-1},
  urldate = {2025-09-17},
  abstract = {Abstract             Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) are marvels of technology; celebrated for their prowess in natural language processing and multimodal content generation, they promise a transformative future. But as with all powerful tools, they come with their shadows. Picture living in a world where deepfakes are indistinguishable from reality, where synthetic identities orchestrate malicious campaigns, and where targeted misinformation or scams are crafted with unparalleled precision. Welcome to the darker side of GenAI applications. This article is not just a journey through the meanders of potential misuse of GenAI and LLMs, but also a call to recognize the urgency of the challenges ahead. As we navigate the seas of misinformation campaigns, malicious content generation, and the eerie creation of sophisticated malware, we'll uncover the societal implications that ripple through the GenAI revolution we are witnessing. From AI-powered botnets on social media platforms to the unnerving potential of AI to generate fabricated identities, or alibis made of synthetic realities, the stakes have never been higher. The lines between the virtual and the real worlds are blurring, and the consequences of potential GenAI's nefarious applications impact us all. This article serves both as a synthesis of rigorous research presented on the risks of GenAI and misuse of LLMs and as a thought-provoking vision of the different types of harmful GenAI applications we might encounter in the near future, and some ways we can prepare for them.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/39DLAXAC/Ferrara - 2024 - GenAI against humanity nefarious applications of generative artificial intelligence and large langu.pdf}
}

@misc{FritzVanDeventer,
  title = {Fritz van {{Deventer}}},
  urldate = {2025-07-03},
  howpublished = {https://isas.han.nl/Default.aspx?F=OpdrachtStudenten\&DT=091117403},
  file = {/Users/fritz/Zotero/storage/SIW7LACC/Default.html}
}

@incollection{fuchsKarlMarxAge2019,
  title = {Karl {{Marx}} in the Age of Big Data Capitalism},
  booktitle = {Digital {{Objects}}, {{Digital Subjects}}: {{Interdisciplinary Perspectives}} on {{Capitalism}}, {{Labour}} and {{Politics}} in the {{Age}} of {{Big Data}}: {{Interdisciplinary Perspectives}} on {{Capitalism}}, {{Labour}} and {{Politics}} in the {{Age}} of {{Big Data}}},
  author = {Fuchs, Christian},
  year = 2019,
  pages = {53--71},
  publisher = {University of Westminster Press London}
}

@article{fuchsMarxAgeDigital,
  title = {Marx in the {{Age}} of {{Digital Capitalism}}},
  author = {Fuchs, Christian and Mosco, Vincent},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/RQ754VM7/Fuchs and Mosco - Marx in the Age of Digital Capitalism.pdf}
}

@article{gaillardRiseFallPromises2025,
  title = {The Rise and Fall of Promises: A Preliminary Method to Trace Promises in Science and Technology},
  shorttitle = {The Rise and Fall of Promises},
  author = {Gaillard, Stefan D. M. and Hachana, Sanda},
  year = 2025,
  month = dec,
  journal = {Journal of Responsible Innovation},
  volume = {12},
  number = {1},
  pages = {2440965},
  issn = {2329-9460, 2329-9037},
  doi = {10.1080/23299460.2024.2440965},
  urldate = {2025-12-01},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/XLREXMV7/Gaillard and Hachana - 2025 - The rise and fall of promises a preliminary method to trace promises in science and technology.pdf}
}

@book{gallowayProtocolHowControl2004,
  title = {Protocol: How Control Exists after Decentralization},
  shorttitle = {Protocol},
  author = {Galloway, Alexander R.},
  year = 2004,
  series = {Leonardo},
  publisher = {MIT Press},
  address = {Cambridge, Mass},
  isbn = {978-0-262-07247-2},
  langid = {english},
  lccn = {TK5105.59 .G35 2004},
  keywords = {Computer network protocols,Computer networks,Distributed processing,Electronic data processing,Management,Security measures},
  file = {/Users/fritz/Zotero/storage/QQ7EYPLJ/Galloway - 2004 - Protocol how control exists after decentralization.pdf}
}

@article{galpayaZeroratingEmergingEconomies2017,
  title = {Zero-Rating in {{Emerging Economies}}},
  author = {Galpaya, Helani},
  year = 2017,
  langid = {english},
  file = {/Users/fritz/Zotero/storage/F3F7IRZF/Galpaya - Zero-rating in Emerging Economies.pdf}
}

@inproceedings{gomezortegaDesigningSecondaryUsers2025,
  title = {Designing for {{Secondary Users}} of {{Intimate Technologies}}},
  booktitle = {Proceedings of the 2025 {{ACM Designing Interactive Systems Conference}}},
  author = {G{\'o}mez Ortega, Alejandra and Campo Woytuk, Nadia and Park, Joo Young and Tuli, Anupriya and Yadav, Deepika and Ciolfi Felice, Marianela and Balaam, Madeline and Lampinen, Airi},
  year = 2025,
  month = jul,
  pages = {2787--2802},
  publisher = {ACM},
  address = {Madeira Portugal},
  doi = {10.1145/3715336.3735420},
  urldate = {2025-11-05},
  isbn = {979-8-4007-1485-6},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/N93DJV8T/GÃ³mez Ortega et al. - 2025 - Designing for Secondary Users of Intimate Technologies.pdf}
}

@inproceedings{gomezortegaSurrenderingPowerlesnessGoverning2025,
  title = {Surrendering to {{Powerlesness}}: {{Governing Personal Data Flows}} in {{Generative AI}}},
  shorttitle = {Surrendering to {{Powerlesness}}},
  booktitle = {Proceedings of the 2025 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {G{\'o}mez Ortega, Alejandra and Morales Ornelas, Hosana and Gen{\c c}, U{\u g}ur},
  year = 2025,
  month = apr,
  pages = {1--18},
  publisher = {ACM},
  address = {Yokohama Japan},
  doi = {10.1145/3706598.3713504},
  urldate = {2025-11-05},
  isbn = {979-8-4007-1394-1},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/D3XGAB35/GÃ³mez Ortega et al. - 2025 - Surrendering to Powerlesness Governing Personal Data Flows in Generative AI.pdf}
}

@misc{googleGoogleAIMode,
  title = {Google {{AI Mode}} - a New Way to Search, Whatever's on Your Mind},
  author = {{Google}},
  journal = {Google AI Mode - a new way to search, whatever's on your mind},
  urldate = {2025-11-06},
  abstract = {Meet AI Mode in Google Search - a new generative AI search experience powered by Gemini 2.0.},
  howpublished = {https://search.google/ways-to-search/ai-mode/},
  langid = {american},
  file = {/Users/fritz/Zotero/storage/5W33SCEF/ai-mode.html}
}

@misc{googleNewDataCenter2024,
  title = {A New Data Center in {{Latin America}}},
  author = {Google},
  year = 2024,
  month = aug,
  journal = {Google},
  urldate = {2025-12-08},
  abstract = {We're announcing the construction of our new data center in Canelones, Uruguay --- our second data center in Latin America.},
  howpublished = {https://blog.google/around-the-globe/google-latin-america/a-new-data-center-in-latin-america/},
  langid = {american},
  file = {/Users/fritz/Zotero/storage/EPSXM9GW/a-new-data-center-in-latin-america.html}
}

@misc{googlePrivacyPolicyPrivacy,
  title = {Privacy {{Policy}} -- {{Privacy}} \& {{Terms}} -- {{Google}}},
  author = {Google},
  urldate = {2025-11-17},
  howpublished = {https://policies.google.com/privacy},
  file = {/Users/fritz/Zotero/storage/5YGVNAYJ/privacy.html}
}

@misc{grantham-philipsAIBecomingIngrained2024,
  title = {{{AI}} Is Becoming Ingrained in Businesses across Industries. {{Where}} Is It Going in 2025?},
  author = {{Grantham-Philips}, Wyatte},
  year = 2024,
  month = dec,
  journal = {AP News},
  urldate = {2025-11-06},
  abstract = {As artificial intelligence continues to grow at a rapid pace, more and more businesses are grappling with how to adapt quickly and responsibly.},
  chapter = {Business},
  howpublished = {https://apnews.com/article/artificial-intelligence-interview-pwc-dan-priest-a0458061469735aed7af5fa49682e076},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/ISZ4RSJG/artificial-intelligence-interview-pwc-dan-priest-a0458061469735aed7af5fa49682e076.html}
}

@inproceedings{guptaEyesKnowIt2020,
  title = {The Eyes Know It: {{FakeET- An Eye-tracking Database}} to {{Understand Deepfake Perception}}},
  shorttitle = {The Eyes Know It},
  booktitle = {Proceedings of the 2020 {{International Conference}} on {{Multimodal Interaction}}},
  author = {Gupta, Parul and Chugh, Komal and Dhall, Abhinav and Subramanian, Ramanathan},
  year = 2020,
  month = oct,
  pages = {519--527},
  publisher = {ACM},
  address = {Virtual Event Netherlands},
  doi = {10.1145/3382507.3418857},
  urldate = {2025-09-17},
  isbn = {978-1-4503-7581-8},
  langid = {english}
}

@misc{habiblantyerDataColonialismGeopolitics2025,
  type = {{{SSRN Scholarly Paper}}},
  title = {Data {{Colonialism}}: {{The Geopolitics}} of {{Information}}},
  shorttitle = {Data {{Colonialism}}},
  author = {Habib Lantyer, Victor},
  year = 2025,
  month = apr,
  number = {5236304},
  eprint = {5236304},
  publisher = {Social Science Research Network},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.5236304},
  urldate = {2025-12-08},
  abstract = {This article explores the concept of "data colonialism" as a contemporary analytical framework for understanding the power dynamics underlying global digital technologies and information flows. Drawing on scholarship from Couldry and Mejias, Zuboff, Kwet, Sassen, Noble, among others, the paper argues that contemporary practices of massive data extraction by global corporations and state actors replicate exploitative colonial logics. Data colonialism thus emerges not merely as a metaphor but as a new stage of historical colonialism, characterized by asymmetrical geopolitical relations and infrastructural invisibility that systematically extract personal and behavioral data, primarily benefiting global technology corporations and dominant states. The study critically analyzes concepts like surveillance capitalism, datafication, data extractivism, data imperialism, and digital sovereignty, examining specific cases from Brazil, the United States, the European Union, and China. Ultimately, the paper argues that combating digital colonialism requires more than regulatory interventions; it demands a fundamental cognitive shift---the Cognitive Reappropriation of Data---that empowers individuals and communities to critically engage with how their data is appropriated, monetized, and governed.},
  archiveprefix = {Social Science Research Network},
  langid = {english},
  keywords = {Big Tech,Cognitive Reappropriation,Data Colonialism,Data Extractivism,Data Imperialism,Datafication,Digital Infrastructure,Digital Sovereignty,Geopolitics of Information,Surveillance Capitalism}
}

@article{hammersley2019positivism,
  title = {From Positivism to Post-Positivism: {{Progress}} or Digression?},
  author = {Hammersley, Martyn},
  year = 2019,
  journal = {Teoria Polityki},
  number = {3},
  pages = {175--188},
  publisher = {Wydawnictwo Uniwersytetu Jagiello\'nskiego}
}

@book{hanckeIntelligentResearchDesign2023,
  title = {Intelligent Research Design: A Guide for Beginning Researchers in the Social Sciences},
  shorttitle = {Intelligent Research Design},
  author = {Hanck{\'e}, Bob},
  year = 2023,
  series = {Oxford Scholarship Online},
  publisher = {Oxford University Press},
  address = {Oxford},
  doi = {10.1093/oso/9780199570782.001.0001},
  abstract = {Offering advice to beginning doctoral researchers and advanced graduate students on how to embark on their research, this book, which is deliberately kept jargon-free and adopts a hands-on approach to research design, addresses the problems that research students face in the course of their first few years},
  isbn = {978-0-19-957078-2 978-1-383-04654-0},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/PVLZPSHN/HanckÃ© - 2023 - Intelligent research design a guide for beginning researchers in the social sciences.pdf}
}

@article{hanImpactGenAILearning2025,
  title = {The Impact of {{GenAI}} on Learning Outcomes: {{A}} Systematic Review and Meta-Analysis of Experimental Studies},
  shorttitle = {The Impact of {{GenAI}} on Learning Outcomes},
  author = {Han, Xiaoli and Peng, Hongchao and Liu, Mingzhuo},
  year = 2025,
  month = aug,
  journal = {Educational Research Review},
  volume = {48},
  pages = {100714},
  issn = {1747-938X},
  doi = {10.1016/j.edurev.2025.100714},
  urldate = {2025-11-11},
  abstract = {Generative Artificial Intelligence (GenAI) tools such as ChatGPT, Claude, and Gemini are increasingly being integrated into educational environments, prompting questions about their actual impact on student learning. While a growing body of literature reports anecdotal or correlational evidence of GenAI's educational potential, rigorous causal evaluations remain limited. To bridge this gap, this study conducted a systematic review and meta-analysis of experimental and quasi-experimental studies investigating the effect of GenAI on learning outcomes. Following PRISMA guidelines, we screened five academic databases and identified 68 relevant studies published between 2022 and 2025. These studies yielded a total of 337 effect sizes across various educational levels, subject domains, and instructional contexts. The meta-analysis revealed a moderate overall positive effect of GenAI on learning outcomes (SMD~=~0.45, 95~\% CI [0.43, 0.47]), suggesting that GenAI-supported interventions are generally more effective than traditional instruction. However, substantial heterogeneity was observed across studies (I2~=~95~\%), indicating that the magnitude of GenAI's impact varies significantly depending on contextual and methodological factors. Moderator analyses revealed stronger effects in primary and secondary education, within natural science disciplines, and in short-term interventions with smaller sample sizes. These patterns point to both the promise and the complexity of GenAI integration in educational practice. In conclusion, while GenAI shows considerable promise for enhancing learning outcomes, its true potential will only be realized through sustained, efforts to evaluate how, when, and for whom these technologies work best in diverse learning ecosystems.},
  keywords = {ChatGPT,GenAI,Learning outcomes,Meta-analysis,Systematic review}
}

@article{hararyRemoteSensingSatellites2017,
  title = {Remote {{Sensing Satellites}} as a {{Solution Towards Anticipating Food}} and {{Water Wars}}},
  author = {Harary, David C},
  year = 2017,
  journal = {Cornell International Affairs Review},
  volume = {10},
  number = {2},
  issn = {2153-5760}
}

@article{harbourEmergingTechnologiesPart1993,
  title = {Emerging Technologies Part 1: {{False}} Hopes: {{The}} Promise of Technology},
  shorttitle = {Emerging Technologies Part 1},
  author = {Harbour, Jerry L.},
  year = 1993,
  month = apr,
  journal = {Performance + Instruction},
  volume = {32},
  number = {4},
  pages = {30--33},
  issn = {0884-1985},
  doi = {10.1002/pfi.4170320409},
  urldate = {2025-12-01},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english}
}

@article{hartman2023privacy,
  title = {Privacy as Respect for Persons: Reimagining Privacy Literacy with the Six Private {{I}}'s Privacy Conceptual Framework},
  author = {{Hartman-Caverly}, Sarah and Chisholm, Alexandria Edyn},
  year = 2023,
  file = {/Users/fritz/Zotero/storage/2PCUSE9X/Hartman-Caverly - PRIVACY AS RESPECT FOR PERSONS.pdf}
}

@article{he2024emerged,
  title = {The Emerged Security and Privacy of Llm Agent: {{A}} Survey with Case Studies},
  author = {He, Feng and Zhu, Tianqing and Ye, Dayong and Liu, Bo and Zhou, Wanlei and Yu, Philip S},
  year = 2024,
  journal = {arXiv preprint arXiv:2407.19354},
  eprint = {2407.19354},
  archiveprefix = {arXiv},
  file = {/Users/fritz/Zotero/storage/4PJYP5YK/He et al. - 2024 - The emerged security and privacy of llm agent A survey with case studies.pdf}
}

@article{hendawy2024intensified,
  title = {The Intensified Digital Divide: {{Comprehending GenAI}}},
  author = {Hendawy, Mennatullah},
  year = 2024,
  journal = {Internet Policy Review}
}

@misc{herrmannObtainingPersonalData2016,
  title = {Obtaining Personal Data and Asking for Erasure: {{Do}} App Vendors and Website Owners Honour Your Privacy Rights?},
  shorttitle = {Obtaining Personal Data and Asking for Erasure},
  author = {Herrmann, Dominik and Lindemann, Jens},
  year = 2016,
  month = apr,
  number = {arXiv:1602.01804},
  eprint = {1602.01804},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1602.01804},
  urldate = {2025-07-11},
  abstract = {EU Directive 95/46/EC and the upcoming EU General Data Protection Regulation grant Europeans the right of access to data pertaining to them. Consumers can approach their service providers to obtain all personal data stored and processed there. Furthermore, they can demand erasure (or correction) of their data. We conducted an undercover field study to determine whether these rights can be exerted in practice. We assessed the behaviour of the vendors of 150 smartphone apps and 120 websites that are popular in Germany. Our deletion requests were fulfilled in 52 to 57\% of the cases and less than half of the data provision requests were answered satisfactorily. Further, we observed instances of carelessness: About 20\% of website owners would have disclosed our personal data to impostors. The results indicate that exerting privacy rights that have been introduced two decades ago is still a frustrating endeavour most of the time.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society},
  file = {/Users/fritz/Zotero/storage/KSALPQ9N/Herrmann and Lindemann - 2016 - Obtaining personal data and asking for erasure Do app vendors and website owners honour your privac.pdf;/Users/fritz/Zotero/storage/VFR952X4/1602.html}
}

@article{hickelGlobalInequalityGetting2017,
  title = {Is Global Inequality Getting Better or Worse? {{A}} Critique of the {{World Bank}}'s Convergence Narrative},
  shorttitle = {Is Global Inequality Getting Better or Worse?},
  author = {Hickel, Jason},
  year = 2017,
  month = oct,
  journal = {Third World Quarterly},
  publisher = {Routledge},
  issn = {0143-6597},
  urldate = {2025-12-01},
  abstract = {Inequality has emerged as a major political issue since the global financial crisis of 2008. Most of the attention in popular discourse has been focused on inequality within countries, which was Th...},
  copyright = {\copyright{} 2017 Southseries Inc., www.thirdworldquarterly.com},
  langid = {english}
}

@article{hicksDataRealmGlobal2021,
  title = {A `Data Realm' for the {{Global South}}? {{Evidence}} from {{Indonesia}}},
  shorttitle = {A `Data Realm' for the {{Global South}}?},
  author = {Hicks, Jacqueline},
  year = 2021,
  month = jul,
  journal = {Third World Quarterly},
  volume = {42},
  number = {7},
  pages = {1417--1435},
  publisher = {Informa UK Limited},
  issn = {0143-6597, 1360-2241},
  doi = {10.1080/01436597.2021.1901570},
  urldate = {2025-07-10},
  abstract = {This article examines the international and domestic pressures that shape the governance of personal data in the Global South. As developing countries become new terrain for the expansion of US Big Tech and develop their own digital economies, international policy discourses urge the adoption of data governance as self-evidently `good policy' moving into existing regulatory vacuums. However, like any valuable resource, the competition to govern personal data is subject to existing power relations, political interests, institutional pathways and ideologies. With evidence from Indonesia, this article shows how the governance of personal data in the digital economy is influenced by international and national commercial interests, and instrumentalised by domestic state and political elite. In doing so, it adapts the North American`information-security complex'for developing countries with their post-colonial economies, self-interested oligarchic elites and hybrid state-commercial data firms. The significance of this approach lies in its realistic understanding of the challenges and opportunities for supporting data governance reform around the world.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/FVPQ6XST/Hicks - 2021 - A â€˜data realmâ€™ for the Global South Evidence from Indonesia.pdf}
}

@misc{hineImpactModernBig2024,
  title = {The {{Impact}} of {{Modern Big Tech Antitrust}} on {{Digital Sovereignty}}},
  author = {Hine, Emmie and Wong, David and Floridi, Luciano},
  year = 2024,
  publisher = {SSRN},
  doi = {10.2139/ssrn.5000929},
  urldate = {2025-07-05},
  abstract = {This article examines the history of antitrust cases against Big Tech companies in the United States. It highlights a shift in the attitudes of enforcers away from the economic-analysis-informed Chicago and post-Chicago schools of antitrust thought, which are informed by economic analysis, towards New Brandeisian thinking, which emphasizes structural concerns and broader consumer welfare. However, it has yet to catch on in courtrooms. By contrasting the US's antitrust strategy with those of the European Union and China, we argue that antitrust enforcement may hinder economic and technological competitiveness in the short term, but may have long-term benefits. Regarding global digital sovereignty, the US increasing enforcement likely would not impact its global competitiveness, as it still presents a more favorable regulatory environment than the EU, and targeted economic measures prevent Chinese companies from being competitive in the US. New legislation may help address the complexities of modern digital markets so that the US can maintain its competitive edge in technology while enhancing consumer welfare.},
  archiveprefix = {SSRN},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/8EIGHEUT/Hine et al. - 2024 - The Impact of Modern Big Tech Antitrust on Digital Sovereignty.pdf}
}

@article{hirsch2024promises,
  title = {Promises and Myths of Artificial Intelligence},
  author = {{Hirsch-Kreinsen}, Hartmut and Krokowski, Thorben},
  year = 2024,
  journal = {Weizenbaum Journal of the Digital Society},
  volume = {4},
  number = {1}
}

@article{hollenbaughEffectsAnonymitySelfDisclosure2013,
  title = {The {{Effects}} of {{Anonymity}} on {{Self-Disclosure}} in {{Blogs}}: {{An Application}} of the {{Online Disinhibition Effect}}},
  shorttitle = {The {{Effects}} of {{Anonymity}} on {{Self-Disclosure}} in {{Blogs}}},
  author = {Hollenbaugh, Erin E. and Everett, Marcia K.},
  year = 2013,
  month = apr,
  journal = {Journal of Computer-Mediated Communication},
  volume = {18},
  number = {3},
  pages = {283--302},
  issn = {1083-6101},
  doi = {10.1111/jcc4.12008},
  urldate = {2025-11-12},
  abstract = {The connections between anonymity and self-disclosure online have received research attention, but the results have been inconclusive with regard to self-disclosure in blogs. This quantitative content analysis of 154 personal journal blogs tested some assumptions of the online disinhibition effect in order to examine the effect of types of anonymity on the amount, breadth, and depth of self-disclosure in blog entries. Results showed that participants disclosed more information in their blog entries when they were more visually identified (sharing a picture of themselves), contrary to the assumptions of the online disinhibition effect. Overall, a trend emerged where visual anonymity led to less disclosiveness, and discursive anonymity (sharing one's real name) led to less disclosiveness for particular types of bloggers.},
  file = {/Users/fritz/Zotero/storage/XYL6S7DX/Hollenbaugh and Everett - 2013 - The Effects of Anonymity on Self-Disclosure in Blogs An Application of the Online Disinhibition Eff.pdf;/Users/fritz/Zotero/storage/XJ5SC73W/jcc4.html}
}

@article{houChatGPTGivingRelationship2024,
  title = {{{ChatGPT Giving Relationship Advice}} -- {{How Reliable Is It}}?},
  author = {Hou, Haonan and Leach, Kevin and Huang, Yu},
  year = 2024,
  month = may,
  journal = {Proceedings of the International AAAI Conference on Web and Social Media},
  volume = {18},
  pages = {610--623},
  issn = {2334-0770, 2162-3449},
  doi = {10.1609/icwsm.v18i1.31338},
  urldate = {2025-11-17},
  abstract = {In the evolving realm of natural language processing (NLP), generative AI models like ChatGPT are increasingly utilized across various applications. Among the possible purposes, many people are considering asking ChatGPT for relationship advice. However, the lack of in-depth examination of ChatGPT's response quality could be concerning when it is used for personal topics like mental health issues and intimate relationship problems. In these topics, a piece of misleading advice could cause harmful repercussions. In response to people's growing interest in using ChatGPT as a relationship advisor, our research evaluates ChatGPT's proficiency in discerning relationship advice. Specifically, we investigate its alignment with human judgements. We conducted our analysis with 13,138 Reddit posts about intimate relationship problems to examine the overall alignment. Furthermore, we investigate ChatGPT's consistency in judging intimate relationship advice by re-prompting identical queries. Our results indicate a significant disparity between ChatGPT and human judgments, with the model displaying inconsistency in its own decisions. Our findings emphasize the need for comprehensive insights into ChatGPT's mechanisms for intimacy problems and future improvements in its proficiency in helping people's relationship struggles.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/C3LCEZ3V/Hou et al. - 2024 - ChatGPT Giving Relationship Advice â€“ How Reliable Is It.pdf}
}

@article{houstonDigitalDivideWho2002,
  title = {The Digital Divide: {{Who}} Really Benefits from the Proposed Solutions for Closing the Gap},
  shorttitle = {The Digital Divide},
  author = {Houston, Roland D. and Erdelez, Sanda},
  year = 2002,
  journal = {Proceedings of the American Society for Information Science and Technology},
  volume = {39},
  number = {1},
  pages = {99--106},
  issn = {1550-8390},
  doi = {10.1002/meet.1450390111},
  urldate = {2025-08-18},
  abstract = {The authors conducted an exploratory content analysis of 269 English language articles about the digital divide to identify potential connections between proposed solutions and the strategic interests of the proposers, or stakeholders. Articles were coded by type of suggested solution and by type of stakeholder offering the solution. Educators predominated in the study literature, stressing the need for a change in Internet connectivity, educational content, and a change in user education, socioeconomic status (SES), and culture. The digital industry provided the next largest number of articles, suggesting governmental policy changes to promote new equipment, increased Internet connectivity, the training of digital industry workers, and a change in content of the Internet. Articles from the nondigital business community suggested that no gap existed or that market dynamics (the status quo) would close it.},
  copyright = {Copyright \copyright{} 2002 American Society for Information Science and Technology},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/NNSNUFL4/Houston and Erdelez - 2002 - The digital divide Who really benefits from the proposed solutions for closing the gap.pdf;/Users/fritz/Zotero/storage/R9W5CB5M/meet.html}
}

@article{howeChatGPTsAdvicePerceived2023,
  title = {{{ChatGPT}}'s Advice Is Perceived as Better than That of Professional Advice Columnists},
  author = {Howe, Piers Douglas Lionel and Fay, Nicolas and Saletta, Morgan and Hovy, Eduard},
  year = 2023,
  month = nov,
  journal = {Frontiers in Psychology},
  volume = {14},
  pages = {1281255},
  issn = {1664-1078},
  doi = {10.3389/fpsyg.2023.1281255},
  urldate = {2025-11-17},
  abstract = {ChatGPT is a high-performance large language model that has the potential to significantly improve human-computer interactions. It can provide advice on a range of topics, but it is unclear how good this advice is relative to that provided by competent humans, especially in situations where empathy is required. Here, we report the first investigation of whether ChatGPT's responses are perceived as better than those of humans in a task where humans were attempting to be empathetic. Fifty social dilemma questions were randomly selected from 10 well-known advice columns. In a pre-registered survey, participants (               N               \,=\,404) were each shown one question, along with the corresponding response by an advice columnist and by ChatGPT. ChatGPT's advice was perceived as more balanced, complete, empathetic, helpful, and better than the advice provided by professional advice columnists (all values of               p               \,\&lt;\,0.001). Although participants could not determine which response was written by ChatGPT (54\%,               p               \,=\,0.29), most participants preferred that their own social dilemma questions be answered by a human than by a computer (77\%,               p               \,\&lt;\,0.001). ChatGPT's responses were longer than those produced by the advice columnists (mean 280.9 words vs. 142.2 words,               p               \,\&lt;\,0.001). In a second pre-registered survey, each ChatGPT answer was constrained to be approximately the same length as that of the advice columnist (mean 143.2 vs. 142.2 words,               p               \,=\,0.95). This survey (               N               \,=\,401) replicated the above findings, showing that the benefit of ChatGPT was not solely due to it writing longer answers.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/3FMA9GG7/Howe et al. - 2023 - ChatGPTâ€™s advice is perceived as better than that of professional advice columnists.pdf}
}

@article{hummel2021data,
  title = {Data Sovereignty: {{A}} Review},
  author = {Hummel, Patrik and Braun, Matthias and Tretter, Max and Dabrock, Peter},
  year = 2021,
  journal = {Big Data \& Society},
  volume = {8},
  number = {1},
  pages = {2053951720982012},
  publisher = {SAGE Publications Sage UK: London, England}
}

@misc{IfWereDigital,
  title = {If {{I}} Were a Digital Application, {{I}} Would Be {{ChatGPT}}: {{Student}} Perspectives on Digital Technology in {{Togo}}},
  shorttitle = {If {{I}} Were a Digital Application, {{I}} Would Be {{ChatGPT}}},
  doi = {10.1145/3757232.3757251},
  urldate = {2025-11-24},
  howpublished = {https://dl.acm.org/doi/epdf/10.1145/3757232.3757251},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/UUQEAI6X/3757232.html}
}

@misc{IntroducingProjectLoon2013,
  title = {Introducing {{Project Loon}}: {{Balloon-powered Internet}} Access},
  shorttitle = {Introducing {{Project Loon}}},
  year = 2013,
  month = jun,
  journal = {Google},
  urldate = {2025-07-10},
  abstract = {Today we're unveiling our latest moonshot from Google[x].},
  howpublished = {https://blog.google/alphabet/introducing-project-loon/},
  langid = {american},
  file = {/Users/fritz/Zotero/storage/S5S5CJHI/introducing-project-loon.html}
}

@article{jiangPreventingImmenseIncrease2024,
  title = {Preventing the {{Immense Increase}} in the {{Life-Cycle Energy}} and {{Carbon Footprints}} of {{LLM-Powered Intelligent Chatbots}}},
  author = {Jiang, Peng and Sonne, Christian and Li, Wangliang and You, Fengqi and You, Siming},
  year = 2024,
  month = sep,
  journal = {Engineering},
  volume = {40},
  pages = {202--210},
  issn = {2095-8099},
  doi = {10.1016/j.eng.2024.04.002},
  urldate = {2025-11-06},
  abstract = {Intelligent chatbots powered by large language models (LLMs) have recently been sweeping the world, with potential for a wide variety of industrial applications. Global frontier technology companies are feverishly participating in LLM-powered chatbot design and development, providing several alternatives beyond the famous ChatGPT. However, training, fine-tuning, and updating such intelligent chatbots consume substantial amounts of electricity, resulting in significant carbon emissions. The research and development of all intelligent LLMs and software, hardware manufacturing (e.g., graphics processing units and supercomputers), related data/operations management, and material recycling supporting chatbot services are associated with carbon emissions to varying extents. Attention should therefore be paid to the entire life-cycle energy and carbon footprints of LLM-powered intelligent chatbots in both the present and future in order to mitigate their climate change impact. In this work, we clarify and highlight the energy consumption and carbon emission implications of eight main phases throughout the life cycle of the development of such intelligent chatbots. Based on a life-cycle and interaction analysis of these phases, we propose a system-level solution with three strategic pathways to optimize the management of this industry and mitigate the related footprints. While anticipating the enormous potential of this advanced technology and its products, we make an appeal for a rethinking of the mitigation pathways and strategies of the life-cycle energy usage and carbon emissions of the LLM-powered intelligent chatbot industry and a reshaping of their energy and environmental implications at this early stage of development.},
  keywords = {Carbon emissions,Energy and environmental footprints,Global cooperation,Intelligent chatbots,Large language models,Life-cycle assessment},
  file = {/Users/fritz/Zotero/storage/6J6PZACI/Jiang et al. - 2024 - Preventing the Immense Increase in the Life-Cycle Energy and Carbon Footprints of LLM-Powered Intell.pdf;/Users/fritz/Zotero/storage/XJJ89ELC/S2095809924002315.html}
}

@article{johnson2023owns,
  title = {Who Owns the Map? {{Data}} Sovereignty and Government Spatial Data Collection, Use, and Dissemination},
  author = {Johnson, Peter A and Scassa, Teresa},
  year = 2023,
  journal = {Transactions in GIS},
  volume = {27},
  number = {1},
  pages = {275--289},
  publisher = {Wiley Online Library}
}

@incollection{joinsonDisinhibitionInternet2007,
  title = {Disinhibition and the {{Internet}}},
  booktitle = {Psychology and the {{Internet}}},
  author = {Joinson, Adam N.},
  year = 2007,
  pages = {75--92},
  publisher = {Elsevier},
  doi = {10.1016/B978-012369425-6/50023-0},
  urldate = {2025-11-12},
  isbn = {978-0-12-369425-6},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/LTTBRFAF/Joinson - 2007 - Disinhibition and the Internet.pdf}
}

@article{kee2024generative,
  title = {Generative Artificial Intelligence to Enhance Architecture Education to Develop Digital Literacy and Holistic Competency},
  author = {Kee, Tris and Kuys, Blair and King, Ronnel},
  year = 2024,
  journal = {Journal of Artificial Intelligence in Architecture},
  volume = {3},
  number = {1},
  pages = {24--41}
}

@article{keithLimitedInformationQuick,
  title = {Limited {{Information}} and {{Quick Decisions}}: {{Consumer Privacy Calculus}} for {{Mobile Applications}}},
  author = {Keith, Mark J and Babb, Jeffry and Furner, Christopher and Abdullat, Amjad and Lowry, Paul Benjamin},
  volume = {8},
  number = {3},
  abstract = {Mobile applications (also known as ``apps'') have rapidly grown into a multibillion-dollar industry. Because they are available through devices that are ``always on'' and often with the user, users often adopt mobile apps ``on the fly'' as they need them. As a result, users often base their adoption and disclosure decisions only on the information provided through the mobile app delivery platform (e.g., the Apple App Storeâ„¢ or Google Playâ„¢). The fact that using a mobile app often requires one to disclose an unprecedented combination of personal information (e.g., location data, preferences, contacts, calendars, browsing history, music library) means that one makes a complex risk/benefit tradeoff decision based on only the small amount of information that the mobile app delivery platform provides---and all in a short period of time. Hence, this process is much shorter and much riskier than traditional software adoption. Through two experiments involving 1,588 mobile app users, we manipulated three primary sources of information provided by a platform (app quality ratings, network size, and privacy assurances) to understand their effect on perceptions of privacy risks and benefits and, in turn, how they influence consumer adoption intentions and willingness to pay (WTP). We found that network size influenced not only perceived benefits but also the perceived risks of apps in the absence of perfect information. In addition, we found that integrating a third party privacy assurance system into the app platform had a significant influence on app adoption and information disclosure. We also found that a larger network size reduces LBS privacy risk perceptions, which confirms our information cascade hypothesis. We discuss the implications of these findings for research and practice.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/X99IGS3Q/Keith et al. - Limited Information and Quick Decisions Consumer Privacy Calculus for Mobile Applications.pdf}
}

@article{kernDesigningElectronicPatient2016,
  title = {Designing an {{Electronic Patient Management System}} for {{Multiple Sclerosis}}: {{Building}} a {{Next Generation Multiple Sclerosis Documentation System}}},
  shorttitle = {Designing an {{Electronic Patient Management System}} for {{Multiple Sclerosis}}},
  author = {Kern, Raimar and Haase, Rocco and Eisele, Judith Christina and Thomas, Katja and Ziemssen, Tjalf},
  year = 2016,
  month = jan,
  journal = {interactive Journal of Medical Research},
  volume = {5},
  number = {1},
  pages = {e2},
  issn = {1929-073X},
  doi = {10.2196/ijmr.4549},
  urldate = {2025-11-06},
  langid = {english}
}

@article{khanalWhyHowPower2025,
  title = {Why and How Is the Power of {{Big Tech}} Increasing in the Policy Process? {{The}} Case of Generative {{AI}}},
  shorttitle = {Why and How Is the Power of {{Big Tech}} Increasing in the Policy Process?},
  author = {Khanal, Shaleen and Zhang, Hongzhou and Taeihagh, Araz},
  year = 2025,
  month = jan,
  journal = {Policy and Society},
  volume = {44},
  number = {1},
  pages = {52--69},
  issn = {1449-4035, 1839-3373},
  doi = {10.1093/polsoc/puae012},
  urldate = {2025-11-28},
  abstract = {The growing digitalization of our society has led to a meteoric rise of large technology companies (Big Tech), which have amassed tremendous wealth and influence through their ownership of digital infrastructure and platforms. The recent launch of ChatGPT and the rapid popularization of generative artificial intelligence (GenAI) act as a focusing event to further accelerate the concentration of power in the hands of the Big Tech. By using Kingdon's multiple streams framework, this article investigates how Big Tech utilize their technological monopoly and political influence to reshape the policy landscape and establish themselves as key actors in the policy process. It explores the implications of the rise of Big Tech for policy theory in two ways. First, it develops the Big Tech-centric technology stream, highlighting the differing motivations and activities from the traditional innovation-centric technology stream. Second, it underscores the universality of Big Tech exerting ubiquitous influence within and across streams, to primarily serve their self-interests rather than promote innovation. Our findings emphasize the need for a more critical exploration of policy role of Big Tech to ensure balanced and effective policy outcomes in the age of AI.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/RR23RI58/Khanal et al. - 2025 - Why and how is the power of Big Tech increasing in the policy process The case of generative AI.pdf}
}

@article{khowajaChatGPTNeedsSPADE2024,
  title = {{{ChatGPT Needs SPADE}} ({{Sustainability}}, {{PrivAcy}}, {{Digital}} Divide, and {{Ethics}}) {{Evaluation}}: {{A Review}}},
  shorttitle = {{{ChatGPT Needs SPADE}} ({{Sustainability}}, {{PrivAcy}}, {{Digital}} Divide, and {{Ethics}}) {{Evaluation}}},
  author = {Khowaja, Sunder Ali and Khuwaja, Parus and Dev, Kapal and Wang, Weizheng and Nkenyereye, Lewis},
  year = 2024,
  month = sep,
  journal = {Cognitive Computation},
  volume = {16},
  number = {5},
  pages = {2528--2550},
  issn = {1866-9956, 1866-9964},
  doi = {10.1007/s12559-024-10285-1},
  urldate = {2025-10-21},
  abstract = {Abstract             ChatGPT is another large language model (LLM) vastly available for the consumers on their devices but due to its performance and ability to converse effectively, it has gained a huge popularity amongst research as well as industrial community. Recently, many studies have been published to show the effectiveness, efficiency, integration, and sentiments of chatGPT and other LLMs. In contrast, this study focuses on the important aspects that are mostly overlooked, i.e. sustainability, privacy, digital divide, and ethics and suggests that not only chatGPT but every subsequent entry in the category of conversational bots should undergo Sustainability, PrivAcy, Digital divide, and Ethics (SPADE) evaluation. This paper discusses in detail the issues and concerns raised over chatGPT in line with aforementioned characteristics. We also discuss the recent EU AI Act briefly in accordance with the SPADE evaluation. We support our hypothesis by some preliminary data collection and visualizations along with hypothesized facts. We also suggest mitigations and recommendations for each of the concerns. Furthermore, we also suggest some policies and recommendations for EU AI policy act concerning ethics, digital divide, and sustainability.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/STTW4XA4/Khowaja et al. - 2024 - ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation A Review.pdf}
}

@article{kimHowGoodChatGPT2025,
  title = {How {{Good Is ChatGPT}} in {{Giving Advice}} on {{Your Visualization Design}}?},
  shorttitle = {How {{Good Is}}},
  author = {Kim, Nam Wook and Ahn, Yongsu and Myers, Grace and Bach, Benjamin},
  year = 2025,
  month = oct,
  journal = {ACM Transactions on Computer-Human Interaction},
  volume = {32},
  number = {5},
  pages = {1--33},
  issn = {1073-0516, 1557-7325},
  doi = {10.1145/3745768},
  urldate = {2025-11-17},
  abstract = {Data visualization creators often lack formal training, resulting in a knowledge gap in design practice. Large-language models such as               ChatGPT               , with their vast internet-scale training data, offer transformative potential to address this gap. In this study, we used both qualitative and quantitative methods to investigate how well               ChatGPT               can address visualization design questions. First, we quantitatively compared the               ChatGPT               -generated responses with anonymous online               Human               replies to data visualization questions on the VisGuides user forum. Next, we conducted a qualitative user study examining the reactions and attitudes of practitioners toward               ChatGPT               as a visualization design assistant. Participants were asked to bring their visualizations and design questions and received feedback from both               Human               experts and               ChatGPT               in randomized order. Our findings from both studies underscore               ChatGPT               's strengths---particularly its ability to rapidly generate diverse design options---while also highlighting areas for improvement, such as nuanced contextual understanding and fluid interaction dynamics beyond the chat interface. Drawing on these insights, we discuss design considerations for future LLM-based design feedback systems.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/B8MVXCY6/Kim et al. - 2025 - How Good Is ChatGPT in Giving Advice on Your Visualiza.pdf}
}

@article{koganDroughtFoodSecurity2019,
  title = {Drought and Food Security Prediction from {{NOAA}} New Generation of Operational Satellites},
  author = {Kogan, Felix and Guo, Wei and Yang, Wenze},
  year = 2019,
  month = jan,
  journal = {Geomatics, Natural Hazards and Risk},
  volume = {10},
  number = {1},
  pages = {651--666},
  issn = {1947-5705, 1947-5713},
  doi = {10.1080/19475705.2018.1541257},
  urldate = {2025-10-16},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/6IWG8LSE/Kogan et al. - 2019 - Drought and food security prediction from NOAA new generation of operational satellites.pdf}
}

@article{koltay2016data,
  title = {Data Governance, Data Literacy and the Management of Data Quality},
  author = {Koltay, Tibor},
  year = 2016,
  journal = {IFLA journal},
  volume = {42},
  number = {4},
  pages = {303--312},
  publisher = {Sage Publications Sage UK: London, England}
}

@article{krokowskiOncePromisedForever2025,
  title = {Once Promised, Forever Believed? {{An}} Essay on the Blind Spots of {{AI}} Promises},
  shorttitle = {Once Promised, Forever Believed?},
  author = {Krokowski, Thorben and {Hirsch-Kreinsen}, Hartmut},
  year = 2025,
  month = nov,
  journal = {AI \& SOCIETY},
  issn = {0951-5666, 1435-5655},
  doi = {10.1007/s00146-025-02765-1},
  urldate = {2025-12-01},
  abstract = {Abstract             This essay explores the technological, economic, and sociocultural dimensions of artificial intelligence (AI) as a paradigmatic case of a promising technology. Drawing on concepts from science and technology studies (STS) and innovation research, it critically examines how future-oriented narratives---often framed as inevitable or deterministic---structure public discourse, mobilize resources, and shape expectations. These dynamics are particularly visible in the cases of artificial general intelligence (AGI) and generative AI (GenAI). The  thesis is that AI is, on the one hand, accompanied and propelled by far-reaching promises, while on the other hand diverse application problems and fundamental functional limitations are frequently overlooked. As a result, skeptical and critical perspectives are gaining increasing prominence in the AI discourse. Therefore, the future prospects of AI could be characterized more by a development path that can be described as routinization, and less by the vision of AGI.~However, it is argued that society's fascination with AI goes beyond technological and economic aspects, neglecting application problems and fundamental functional limitations.  This persuasiveness is ultimately based on the vagueness of the term AI and the long-standing myth of the intelligent machine.},
  langid = {english}
}

@article{kwetDigitalColonialismUS2019,
  title = {Digital Colonialism: {{US}} Empire and the New Imperialism in the {{Global South}}},
  shorttitle = {Digital Colonialism},
  author = {Kwet, Michael},
  year = 2019,
  month = apr,
  journal = {Race \& Class},
  volume = {60},
  number = {4},
  pages = {3--26},
  publisher = {SAGE Publications Ltd},
  issn = {0306-3968},
  doi = {10.1177/0306396818823172},
  urldate = {2025-12-08},
  abstract = {This article proposes a conceptual framework of how the United States is reinventing colonialism in the Global South through the domination of digital technology. Using South Africa as a case study, it argues that US multinationals exercise imperial control at the architecture level of the digital ecosystem: software, hardware and network connectivity, which then gives rise to related forms of domination. The monopoly power of multinational corporations is used for resource extraction through rent and surveillance ? economic domination. By controlling the digital ecosystem, Big Tech corporations control computer-mediated experiences, giving them direct power over political, economic and cultural domains of life ? imperial control. The centrepiece of surveillance capitalism, Big Data, violates the sanctity of privacy and concentrates economic power in the hands of US corporations ? a system of global surveillance capitalism. As a feature of surveillance capitalism, Global North intelligence agencies partner with their own corporations to conduct mass and targeted surveillance in the Global South ? which intensifies imperial state surveillance. US elites have persuaded people that society must proceed according to its ruling class conceptions of the digital world, setting the foundation for tech hegemony. The author argues for a different ecosystem that decentralises technology by placing control directly into the hands of the people to counter the rapidly advancing frontier of digital empire.},
  file = {/Users/fritz/Zotero/storage/KSLLBSWY/Kwet - 2019 - Digital colonialism US empire and the new imperialism in the Global South.pdf}
}

@article{langley2022fintech,
  title = {{{FinTech}} in {{Africa}}: {{An}} Editorial Introduction},
  author = {Langley, Paul and {Rodima-Taylor}, Daivi},
  year = 2022,
  journal = {Journal of Cultural Economy},
  volume = {15},
  number = {4},
  pages = {387--400},
  publisher = {Taylor \& Francis}
}

@inproceedings{lassakBalancingPrivacyData2025,
  title = {Balancing {{Privacy}} and {{Data Utilization}}: {{A Comparative Vignette Study}} on {{User Acceptance}} of {{Data Trustees}} in {{Germany}} and the {{US}}},
  shorttitle = {Balancing {{Privacy}} and {{Data Utilization}}},
  booktitle = {Proceedings 2025 {{Network}} and {{Distributed System Security Symposium}}},
  author = {Lassak, Leona and P{\"u}schel, Hanna and Reithmaier, Oliver D. and Gostomzyk, Tobias and D{\"u}rmuth, Markus},
  year = 2025,
  publisher = {Internet Society},
  address = {San Diego, CA, USA},
  doi = {10.14722/ndss.2025.241982},
  urldate = {2025-11-18},
  abstract = {In times of big data, connected devices, and increasing self-measurement, protecting consumer privacy remains a challenge despite ongoing technological and legislative efforts. Data trustees present a promising solution, aiming to balance data utilization with privacy concerns by facilitating secure data sharing and ensuring individual control. However, successful implementation hinges on user acceptance and trust. We conducted a large-scale, vignette-based, census-representative online study examining factors influencing the acceptance of data trustees for medical, automotive, IoT, and online data. With n = 714 participants from Germany and n = 1036 from the US, our study reveals varied willingness to use data trustees across both countries, with notable skepticism and outright rejection from a significant portion of users. We also identified significant domainspecific differences, including the influence of user anonymity, perceived personal and societal benefits, and the recipients of the data. Contrary to common beliefs, organizational and regulatory decisions such as the storage location, the operator, and supervision appeared less relevant to users' decisions. In conclusion, while there exists a potential user base for data trustees, achieving widespread acceptance will require explicit and targeted implementation strategies tailored to address diverse user expectations. Our findings underscore the importance of understanding these nuances for effectively deploying data trustee frameworks that meet both regulatory requirements and user preferences while upholding highest security and privacy standards.},
  isbn = {979-8-9894372-8-3},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/K5VYPUV9/Lassak et al. - 2025 - Balancing Privacy and Data Utilization A Comparative Vignette Study on User Acceptance of Data Trus.pdf}
}

@article{lautrupHearttoheartChatGPTImpact2023,
  title = {Heart-to-Heart with {{ChatGPT}}: The Impact of Patients Consulting {{AI}} for Cardiovascular Health Advice},
  shorttitle = {Heart-to-Heart with {{ChatGPT}}},
  author = {Lautrup, Anton Danholt and Hyrup, Tobias and {Schneider-Kamp}, Anna and Dahl, Marie and Lindholt, Jes Sanddal and {Schneider-Kamp}, Peter},
  year = 2023,
  month = nov,
  journal = {Open Heart},
  volume = {10},
  number = {2},
  pages = {e002455},
  issn = {2053-3624},
  doi = {10.1136/openhrt-2023-002455},
  urldate = {2025-11-17},
  abstract = {Objectives The advent of conversational artificial intelligence (AI) systems employing large language models such as ChatGPT has sparked public, professional and academic debates on the capabilities of such technologies. This mixed-methods study sets out to review and systematically explore the capabilities of ChatGPT to adequately provide health advice to patients when prompted regarding four topics from the field of cardiovascular diseases. Methods As of 30 May 2023, 528 items on PubMed contained the term ChatGPT in their title and/or abstract, with 258 being classified as journal articles and included in our thematic state-of-the-art review. For the experimental part, we systematically developed and assessed 123 prompts across the four topics based on three classes of users and two languages. Medical and communications experts scored ChatGPT's responses according to the 4Cs of language model evaluation proposed in this article: correct, concise, comprehensive and comprehensible. Results The articles reviewed were fairly evenly distributed across discussing how ChatGPT could be used for medical publishing, in clinical practice and for education of medical personnel and/or patients. Quantitatively and qualitatively assessing the capability of ChatGPT on the 123 prompts demonstrated that, while the responses generally received above-average scores, they occupy a spectrum from the concise and correct via the absurd to what only can be described as hazardously incorrect and incomplete. Prompts formulated at higher levels of health literacy generally yielded higher-quality answers. Counterintuitively, responses in a lower-resource language were often of higher quality. Conclusions The results emphasise the relationship between prompt and response quality and hint at potentially concerning futures in personalised medicine. The widespread use of large language models for health advice might amplify existing health inequalities and will increase the pressure on healthcare systems by providing easy access to many seemingly likely differential diagnoses and recommendations for seeing a doctor for even harmless ailments.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/UGBMYV2S/Lautrup et al. - 2023 - Heart-to-heart with ChatGPT the impact of patients consulting AI for cardiovascular health advice.pdf}
}

@inproceedings{layton2016free,
  title = {Free Basics Research Paper: {{Zero}} Rating, Free Data, and Use Cases in Mhealth, Local Content and Service Development, and {{ICT4D}} Policymaking},
  author = {Layton, Roslyn and {Elaluf-Calderwood}, Silvia},
  year = 2016,
  publisher = {TPRC}
}

@article{leenes2015taming,
  title = {Taming the Cookie Monster with Dutch Law--a Tale of Regulatory Failure},
  author = {Leenes, Ronald and Kosta, Eleni},
  year = 2015,
  journal = {Computer Law \& Security Review},
  volume = {31},
  number = {3},
  pages = {317--335},
  publisher = {Elsevier}
}

@article{leslieFutureShockGenerative2024,
  title = {Future {{Shock}}: {{Generative AI}} and the {{International AI Policy}} and {{Governance Crisis}}},
  shorttitle = {Future {{Shock}}},
  author = {Leslie, David and Perini, Antonella Maia},
  year = 2024,
  month = may,
  journal = {Harvard Data Science Review},
  number = {Special Issue 5},
  doi = {10.1162/99608f92.88b4cc98},
  urldate = {2025-11-06},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/7VIIEVKT/Leslie and Perini - 2024 - Future Shock Generative AI and the International AI Policy and Governance Crisis.pdf}
}

@article{li2023ai,
  title = {{{AI}} in Education: {{Bridging}} the Divide or Widening the Gap? {{Exploring}} Equity, Opportunities, and Challenges in the Digital Age},
  author = {Li, Haomin},
  year = 2023,
  journal = {Advances in Education, Humanities and Social Science Research},
  volume = {8},
  number = {1},
  pages = {355--355},
  file = {/Users/fritz/Zotero/storage/IPS44TMY/Li - 2023 - AI in education Bridging the divide or widening the gap Exploring equity, opportunities, and chall.pdf}
}

@article{liDoesDigitalLiteracy2024,
  title = {Does Digital Literacy Help Residents Avoid Becoming Victims of Frauds? {{Empirical}} Evidence Based on a Survey of Residents in Six Provinces of East {{China}}},
  shorttitle = {Does Digital Literacy Help Residents Avoid Becoming Victims of Frauds?},
  author = {Li, Peng and Li, Qinghai and Du, Shanxing},
  year = 2024,
  month = mar,
  journal = {International Review of Economics \& Finance},
  volume = {91},
  pages = {364--377},
  issn = {10590560},
  doi = {10.1016/j.iref.2024.01.056},
  urldate = {2025-09-11},
  langid = {english}
}

@misc{liMultistepJailbreakingPrivacy2023,
  title = {Multi-Step {{Jailbreaking Privacy Attacks}} on {{ChatGPT}}},
  author = {Li, Haoran and Guo, Dadi and Fan, Wei and Xu, Mingshi and Huang, Jie and Meng, Fanpu and Song, Yangqiu},
  year = 2023,
  month = nov,
  number = {arXiv:2304.05197},
  eprint = {2304.05197},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.05197},
  urldate = {2025-11-17},
  abstract = {With the rapid progress of large language models (LLMs), many downstream NLP tasks can be well solved given appropriate prompts. Though model developers and researchers work hard on dialog safety to avoid generating harmful content from LLMs, it is still challenging to steer AI-generated content (AIGC) for the human good. As powerful LLMs are devouring existing text data from various domains (e.g., GPT-3 is trained on 45TB texts), it is natural to doubt whether the private information is included in the training data and what privacy threats can these LLMs and their downstream applications bring. In this paper, we study the privacy threats from OpenAI's ChatGPT and the New Bing enhanced by ChatGPT and show that application-integrated LLMs may cause new privacy threats. To this end, we conduct extensive experiments to support our claims and discuss LLMs' privacy implications.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Cryptography and Security},
  file = {/Users/fritz/Zotero/storage/CAK3UXNS/Li et al. - 2023 - Multi-step Jailbreaking Privacy Attacks on ChatGPT.pdf;/Users/fritz/Zotero/storage/MM4GVVFB/2304.html}
}

@misc{liuRobustnessTimeUnderstanding2024,
  title = {Robustness {{Over Time}}: {{Understanding Adversarial Examples}}' {{Effectiveness}} on {{Longitudinal Versions}} of {{Large Language Models}}},
  shorttitle = {Robustness {{Over Time}}},
  author = {Liu, Yugeng and Cong, Tianshuo and Zhao, Zhengyu and Backes, Michael and Shen, Yun and Zhang, Yang},
  year = 2024,
  month = may,
  number = {arXiv:2308.07847},
  eprint = {2308.07847},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.07847},
  urldate = {2025-11-17},
  abstract = {Large Language Models (LLMs) undergo continuous updates to improve user experience. However, prior research on the security and safety implications of LLMs has primarily focused on their specific versions, overlooking the impact of successive LLM updates. This prompts the need for a holistic understanding of the risks in these different versions of LLMs. To fill this gap, in this paper, we conduct a longitudinal study to examine the adversarial robustness -- specifically misclassification, jailbreak, and hallucination -- of three prominent LLMs: GPT-3.5, GPT-4, and LLaMA. Our study reveals that LLM updates do not consistently improve adversarial robustness as expected. For instance, a later version of GPT-3.5 degrades regarding misclassification and hallucination despite its improved resilience against jailbreaks, and GPT-4 demonstrates (incrementally) higher robustness overall. Moreover, larger model sizes do not necessarily yield improved robustness. Specifically, larger LLaMA models do not uniformly exhibit improved robustness across all three aspects studied. Importantly, minor updates lacking substantial robustness improvements can exacerbate existing issues rather than resolve them. By providing a more nuanced understanding of LLM robustness over time, we hope our study can offer valuable insights for developers and users navigating model updates and informed decisions in model development and usage for LLM vendors.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {/Users/fritz/Zotero/storage/MBHE8AXF/Liu et al. - 2024 - Robustness Over Time Understanding Adversarial Examples' Effectiveness on Longitudinal Versions of.pdf;/Users/fritz/Zotero/storage/AK78DPLU/2308.html}
}

@article{lodinovaApplicationBiometricsMeans2016,
  title = {Application of Biometrics as a Means of Refugee Registration: Focusing on {{UNHCR}}'s Strategy},
  author = {Lodinov{\'a}, Anna},
  year = 2016,
  volume = {2},
  number = {2},
  abstract = {In 1950, the United Nations established the United Nations High Commissioner for Refugees (UNHCR), which claims credit for essential involvement in refugee issues. UNHCR teams have worked with several standard registration systems which, however, have still needed improvements. The search for the ideal system resulted in the establishment of the registration scheme -- Project Profile, which became the basis for the proGres platform. UNHCR and Microsoft developed a mobile registration database, the proGres Refugee Registration Platform, which provided refugees with new identification documents. In 2006, the UN OIOS (United Nations Office of international Oversight Services) published a report which suggested combining fingerprinting with the new database. The UNHCR officially announced its policy of biometric refugee registration in 2010 and introduced the registration technology in collaboration with several organisations. In addition, the team implemented iris scans into specialized ATMs in Jordan. The most recent registration technology, BIMS (Biometric Identity Management System), was field tested in Thailand in July 2015. The overall outcome was very impressive and the UNHCR plans to continue the application of the technology in the future. The author believes that biometrics contribute to the promotion of national welfare and sees concerns and ethical objections as legitimate, while also recognizing that these issues may contribute to the elimination of defects in the system.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/LH8BFK9G/LodinovÃ¡ - 2016 - Application of biometrics as a means of refugee registration focusing on UNHCRâ€™s strategy.pdf}
}

@article{lythreatisDigitalDivideReview2022,
  title = {The Digital Divide: {{A}} Review and Future Research Agenda},
  shorttitle = {The Digital Divide},
  author = {Lythreatis, Sophie and Singh, Sanjay Kumar and {El-Kassar}, Abdul-Nasser},
  year = 2022,
  month = feb,
  journal = {Technological Forecasting and Social Change},
  volume = {175},
  pages = {121359},
  issn = {0040-1625},
  doi = {10.1016/j.techfore.2021.121359},
  urldate = {2025-07-22},
  abstract = {This article provides a systematic review of the digital divide, a phenomenon which refers to disparities in Information and Communications Technology access, usage, and outcomes. It uniquely identifies the factors affecting the digital divide that have emerged in recent years (2017--2021) as well as investigate if there are new forms or levels of the divide that have surfaced in recent literature. The findings, based on 50 included studies, show that the factors affecting the digital divide can be classified into three different segments and nine main categories: sociodemographic, socioeconomic, personal elements, social support, type of technology, digital training, rights, infrastructure, and large-scale events. Out of all factors, education has been linked to the digital divide the most. The majority of recent literature have studied Level 2 of the divide. Also, only one article in the sample has considered the digital divide at the firm level. Findings also show that a new form, type-of-internet access, and two potential new levels of the digital divide, algorithmic awareness and data inequalities, have been identified in the contemporary literature. The results contribute to the understanding and development of the different perspectives of the digital divide concept. They also contribute to the stream of literature on the determinants of the divide and to the social inequalities and digital inclusion literature. This review can be seen as a guide for managers to realize and understand the forms that the divide can take and to delve into their organizational capabilities on the digitalization front and evaluate where further development is needed within their organizations to help diminish the divide.},
  keywords = {Determinants,Digital divide,Digital inequality,Levels,Systematic review},
  file = {/Users/fritz/Zotero/storage/AWFKRJZR/S0040162521007903.html}
}

@article{madianou2019technocolonialism,
  title = {Technocolonialism: {{Digital}} Innovation and Data Practices in the Humanitarian Response to Refugee Crises},
  author = {Madianou, Mirca},
  year = 2019,
  journal = {Social media+ society},
  volume = {5},
  number = {3},
  pages = {2056305119863146},
  publisher = {SAGE Publications Sage UK: London, England},
  file = {/Users/fritz/Zotero/storage/VD3PE7NU/Madianou - 2019 - Technocolonialism Digital Innovation and Data Practices in the Humanitarian Response to Refugee Cri.pdf}
}

@book{madianou2024technocolonialism,
  title = {Technocolonialism: {{When}} Technology for Good Is Harmful},
  author = {Madianou, Mirca},
  year = 2024,
  publisher = {John Wiley \& Sons}
}

@article{magalhaesGivingTakingAway,
  title = {Giving by {{Taking Away}}: {{Big Tech}}, {{Data Colonialism}}, and the {{Reconfiguration}} of {{Social Good}}},
  author = {Magalh{\~a}es, Jo{\~a}o Carlos},
  abstract = {Big Tech companies have recently led and financed projects that claim to use datafication for the ``social good.'' This article explores what kind of social good it is that this sort of datafication engenders. Drawing mostly on the analysis of corporate public communications and patent applications, it finds that these initiatives hinge on the reconfiguration of social good as datafied, probabilistic, and profitable. These features, the article argues, are better understood within the framework of data colonialism. Rethinking ``doing good'' as a facet of data colonialism illuminates the inherent harm to freedom these projects produce and why, to ``give,'' Big Tech must often take away.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/DK76T8DD/MagalhÃ£es - Giving by Taking Away Big Tech, Data Colonialism, and the Reconfiguration of Social Good.pdf}
}

@article{makhortykhTrackNotTrack2022,
  title = {To Track or Not to Track: Examining Perceptions of Online Tracking for Information Behavior Research},
  shorttitle = {To Track or Not to Track},
  author = {Makhortykh, Mykola and Urman, Aleksandra and {Gil-Lopez}, Teresa and Ulloa, Roberto},
  year = 2022,
  month = dec,
  journal = {Internet Research},
  volume = {32},
  number = {7},
  pages = {260--279},
  issn = {1066-2243},
  doi = {10.1108/INTR-01-2021-0074},
  urldate = {2025-08-20},
  abstract = {Purpose -- This study investigates perceptions of the use of online tracking, a passive data collection method relying on the automated recording of participant actions on desktop and mobile devices, for studying information behavior. It scrutinizes folk theories of tracking, the concerns tracking raises among the potential participants and design mechanisms that can be used to alleviate these concerns.},
  copyright = {https://www.emerald.com/insight/site-policies},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/93IFJ2E7/Makhortykh et al. - 2022 - To track or not to track examining perceptions of online tracking for information behavior research.pdf}
}

@article{malephane2022digital,
  title = {Digital Divide: {{Who}} in {{Africa}} Is Connected and Who Is Not},
  author = {Malephane, Libuseng},
  year = 2022,
  file = {/Users/fritz/Zotero/storage/F52Q67HA/AD582-PAP18-Digital-divide-Who-in-Africa-is-connected-and-who-is-not-Afrobarometer-Pan-Africa-Pr.pdf}
}

@article{mana2022survey,
  title = {Survey Review on Artificial Intelligence and Embedded Systems for Agriculture Safety: A Proposed {{IoT Agro-meteorology System}} for {{Local Farmers}} in {{Morocco}}},
  author = {Mana, {\relax AA} and Allouhi, A and Hamrani, A and Jamil, A and Ouazzani, K and Barrahmoune, A and Daffa, D},
  year = 2022,
  journal = {Smart embedded systems and applications},
  pages = {211--242},
  publisher = {CRC Press},
  file = {/Users/fritz/Zotero/storage/G4K6QI7N/Mana et al. - 2022 - Survey review on artificial intelligence and embedded systems for agriculture safety a proposed IoT.pdf}
}

@article{marcianoBigDataBig2020,
  title = {Big Data and Big Techs: Understanding the Value of Information in Platform Capitalism},
  shorttitle = {Big Data and Big Techs},
  author = {Marciano, Alain and Nicita, Antonio and Ramello, Giovanni Battista},
  year = 2020,
  month = dec,
  journal = {European Journal of Law and Economics},
  volume = {50},
  number = {3},
  pages = {345--358},
  issn = {0929-1261, 1572-9990},
  doi = {10.1007/s10657-020-09675-1},
  urldate = {2025-11-19},
  abstract = {Abstract             One of the major challenges that result from the digital transformation occurring in our societies bears on its impact on the organization and regulation of the economy. This leads to a dramatic change to the economic institutions of capitalism---into what could be defined as platform capitalism---that rests on a fundamental dilemma between `decentralization' on the one side and `concentration' on the other. This is the main puzzle that the emergence of a big data driven economy is actually offering to law and economics scholars and to policy makers. This paper introduces to some of the major aspects of this dilemma.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/C67T49HS/Marciano et al. - 2020 - Big data and big techs understanding the value of information in platform capitalism.pdf}
}

@article{martin2016measuring,
  title = {Measuring Privacy: {{An}} Empirical Test Using Context to Expose Confounding Variables},
  author = {Martin, Kirsten and Nissenbaum, Helen},
  year = 2016,
  journal = {Colum. Sci. \& Tech. L. Rev.},
  volume = {18},
  pages = {176},
  publisher = {HeinOnline}
}

@article{mckinnon2014sacrificing,
  title = {Sacrificing Privacy for Convenience: The Need for Stricter {{FTC}} Regulations in an Age of Smartphone Surveillance},
  author = {McKinnon, Ashton},
  year = 2014,
  journal = {J. Nat'l Ass'n Admin. L. Judiciary},
  volume = {34},
  pages = {484},
  publisher = {HeinOnline},
  file = {/Users/fritz/Zotero/storage/4KH39AQQ/McKinnon - Sacrificing Privacy for Convenience The Need for Stricter FTC Regulations in an Age of Smartphone S.pdf}
}

@article{mckinnonAreLibraryVendors2022,
  title = {Are Library Vendors Doing Enough to Protect Users? {{A}} Content Analysis of Major {{ILS}} Privacy Policies},
  shorttitle = {Are Library Vendors Doing Enough to Protect Users?},
  author = {McKinnon, Dawn and Turp, Clara},
  year = 2022,
  month = mar,
  journal = {The Journal of Academic Librarianship},
  volume = {48},
  number = {2},
  pages = {102505},
  issn = {0099-1333},
  doi = {10.1016/j.acalib.2022.102505},
  urldate = {2025-07-11},
  abstract = {While privacy is a core value of librarianship, privacy standards differ by library and library vendor. These types of guidelines are necessary and useful, but understanding them can be overwhelming. Academic libraries increasingly rely on third-party, cloudbased vendors to manage their systems and to provide access to their collections. When selecting library systems, library staff must understand privacy issues and be aware of how vendors use data. However, libraries do not always have the staffing, time or knowledge, and vendors are not always interested in upholding library values. The project examines the content of privacy policies for popular library systems used by Canadian academic libraries. The research aims to help librarians better understand the policies, to help them make informed decisions about their own library systems. The process used to code the privacy policies and the results of the coding are included alongside recommendations for vendors and library employees. Building on two seminal privacy studies, the methodology is revised for a Canadian context and updated with today's terminology and context, making it adaptable for other libraries and context around the world.},
  keywords = {Academic libraries,Content analysis,Library vendors,Privacy policies},
  file = {/Users/fritz/Zotero/storage/HRSHV27X/S0099133322000210.html}
}

@inproceedings{meli2024empowering,
  title = {Empowering Educators with Generative Ai: {{The}} Genai Education Frontier Initiative},
  booktitle = {{{EDULEARN24}} Proceedings},
  author = {Meli, K and Taouki, J and Pantazatos, D},
  year = 2024,
  pages = {4289--4299},
  publisher = {IATED}
}

@article{merry2019smartphone,
  title = {Smartphone {{GPS}} Accuracy Study in an Urban Environment},
  author = {Merry, Krista and Bettinger, Pete},
  year = 2019,
  journal = {PloS one},
  volume = {14},
  number = {7},
  pages = {e0219890},
  publisher = {Public Library of Science San Francisco, CA USA}
}

@misc{MetaConnectivity,
  title = {Meta {{Connectivity}}},
  urldate = {2025-07-10},
  abstract = {Meta Connectivity},
  howpublished = {https://www.facebook.com/connectivity/solutions/free-basics/},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/MKYAFKED/free-basics.html}
}

@misc{metaMetaAIWhatsApp,
  title = {Meta {{AI}} in {{WhatsApp}}: {{Chat}}, {{Create}} \& {{Get Things Done}}},
  shorttitle = {Meta {{AI}} in {{WhatsApp}}},
  author = {{Meta}},
  journal = {WhatsApp.com},
  urldate = {2025-11-06},
  abstract = {Use Meta AI in WhatsApp to do more. Chat with Meta AI assistant, plan meetups with friends, and share AI-generated images - all with the privacy of WhatsApp.},
  howpublished = {https://www.whatsapp.com/meta-ai},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/5S2GB3YM/meta-ai.html}
}

@misc{microsoftCelebratingCompletionNew2024,
  title = {Celebrating Completion of a New Datacenter in {{Busan}}},
  author = {Microsoft},
  year = 2024,
  month = nov,
  journal = {Microsoft Local},
  urldate = {2025-12-08},
  abstract = {On September 23, 2024, Microsoft and the city of Busan unveiled the newly constructed Miumsandan Datacenter, located in Busan's International Industrial Logistics City, Gangseo-gu. This new datacenter, larger than the other facility completed in 2020, is designed to support cloud services across the Asia-Pacific region. Partnering to establish Busan as a global innovation hub Over...},
  langid = {american}
}

@misc{microsoftIntroducingNewBing,
  title = {Introducing the New {{Bing}}. {{The AI-powered}} Assistant for Your Search.},
  author = {{Microsoft}},
  urldate = {2025-11-06},
  howpublished = {https://www.microsoft.com/en-us/edge/features/the-new-bing},
  langid = {american},
  file = {/Users/fritz/Zotero/storage/WYLHT4BB/the-new-bing.html}
}

@article{microsoftMicrosoftDatacentersBrazil,
  title = {Microsoft Datacenters in {{Brazil}}},
  author = {Microsoft},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/GUWAZ5FW/Microsoft datacenters in Brazil.pdf}
}

@misc{microsoftMicrosoftInauguraSu2025,
  title = {{Microsoft inaugura su primera Regi\'on de Datacenters en Chile para acelerar la innovaci\'on y el desarrollo econ\'omico local}},
  author = {Microsoft},
  year = 2025,
  month = jun,
  journal = {News Center Latinoam\'erica},
  urldate = {2025-12-08},
  abstract = {La nueva Regi\'on de Nube de Microsoft en Chile, ubicada en la Regi\'on Metropolitana de Santiago, est\'a compuesta por tres ubicaciones f\'isicas independientes ---cada una con uno o m\'as Datacenters --- y ya se encuentra operativa. Esta infraestructura de \'ultima generaci\'on brindar\'a servicios digitales avanzados a empresas y organizaciones p\'ublicas, mejorando la velocidad, privacidad, seguridad, [\dots ]},
  langid = {spanish}
}

@article{milan2018technopolitics,
  title = {Technopolitics in the Age of Big Data},
  author = {Milan, Stefania and Gutierrez, Miren},
  year = 2018,
  journal = {Networks, movements and technopolitics in Latin America: Critical analysis and current challenges},
  pages = {95--109},
  publisher = {Springer},
  file = {/Users/fritz/Zotero/storage/KRHVRX8B/Milan and Gutierrez - 2018 - Technopolitics in the age of big data.pdf}
}

@article{millerAIHyperrealismWhy2023,
  title = {{{AI Hyperrealism}}: {{Why AI Faces Are Perceived}} as {{More Real Than Human Ones}}},
  shorttitle = {{{AI Hyperrealism}}},
  author = {Miller, Elizabeth J. and Steward, Ben A. and Witkower, Zak and Sutherland, Clare A. M. and Krumhuber, Eva G. and Dawel, Amy},
  year = 2023,
  month = dec,
  journal = {Psychological Science},
  volume = {34},
  number = {12},
  pages = {1390--1403},
  issn = {0956-7976, 1467-9280},
  doi = {10.1177/09567976231207095},
  urldate = {2025-09-17},
  abstract = {Recent evidence shows that AI-generated faces are now indistinguishable from human faces. However, algorithms are trained disproportionately on White faces, and thus White AI faces may appear especially realistic. In Experiment 1 ( N = 124 adults), alongside our reanalysis of previously published data, we showed that White AI faces are judged as human more often than actual human faces---a phenomenon we term AI hyperrealism. Paradoxically, people who made the most errors in this task were the most confident (a Dunning-Kruger effect). In Experiment 2 ( N = 610 adults), we used face-space theory and participant qualitative reports to identify key facial attributes that distinguish AI from human faces but were misinterpreted by participants, leading to AI hyperrealism. However, the attributes permitted high accuracy using machine learning. These findings illustrate how psychological theory can inform understanding of AI outputs and provide direction for debiasing AI algorithms, thereby promoting the ethical use of AI.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/DEWK4XGX/Miller et al. - 2023 - AI Hyperrealism Why AI Faces Are Perceived as More Real Than Human Ones.pdf}
}

@misc{mireshghallahCanLLMsKeep2024,
  title = {Can {{LLMs Keep}} a {{Secret}}? {{Testing Privacy Implications}} of {{Language Models}} via {{Contextual Integrity Theory}}},
  shorttitle = {Can {{LLMs Keep}} a {{Secret}}?},
  author = {Mireshghallah, Niloofar and Kim, Hyunwoo and Zhou, Xuhui and Tsvetkov, Yulia and Sap, Maarten and Shokri, Reza and Choi, Yejin},
  year = 2024,
  month = jun,
  number = {arXiv:2310.17884},
  eprint = {2310.17884},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.17884},
  urldate = {2025-11-25},
  abstract = {The interactive use of large language models (LLMs) in AI assistants (at work, home, etc.) introduces a new set of inference-time privacy risks: LLMs are fed different types of information from multiple sources in their inputs and are expected to reason about what to share in their outputs, for what purpose and with whom, within a given context. In this work, we draw attention to the highly critical yet overlooked notion of contextual privacy by proposing ConfAIde, a benchmark designed to identify critical weaknesses in the privacy reasoning capabilities of instruction-tuned LLMs. Our experiments show that even the most capable models such as GPT-4 and ChatGPT reveal private information in contexts that humans would not, 39\% and 57\% of the time, respectively. This leakage persists even when we employ privacy-inducing prompts or chain-of-thought reasoning. Our work underscores the immediate need to explore novel inference-time privacy-preserving approaches, based on reasoning and theory of mind.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Cryptography and Security},
  file = {/Users/fritz/Zotero/storage/AKHVYAAT/Mireshghallah et al. - 2024 - Can LLMs Keep a Secret Testing Privacy Implications of Language Models via Contextual Integrity The.pdf;/Users/fritz/Zotero/storage/W2W6GPQ7/2310.html}
}

@article{mithani2022scoping,
  title = {A Scoping Review of Global Vaccine Certificate Solutions for {{COVID-19}}},
  author = {Mithani, Salima S and Bota, A Brianne and Zhu, David T and Wilson, Kumanan},
  year = 2022,
  journal = {Human vaccines \& immunotherapeutics},
  volume = {18},
  number = {1},
  pages = {1--12},
  publisher = {Taylor \& Francis}
}

@article{mwansa2025bridging,
  title = {Bridging the Digital Divide: Exploring the Challenges and Solutions for Digital Exclusion in Rural {{South Africa}}},
  author = {Mwansa, Gardner and Ngandu, Matipa Ricky and Mkwambi, Zolisa},
  year = 2025,
  journal = {Discover Global Society},
  volume = {3},
  number = {1},
  pages = {54},
  publisher = {Springer}
}

@misc{naikChatGPTAllYou2024,
  title = {{{ChatGPT Is All You Need}}: {{Untangling Its Underlying AI Models}}, {{Architecture}}, {{Training Procedure}}, {{Capabilities}}, {{Limitations And Applications}}},
  shorttitle = {{{ChatGPT Is All You Need}}},
  author = {Naik, Ishita and Naik, Dishita and Naik, Nitin},
  year = 2024,
  month = nov,
  publisher = {Preprints},
  doi = {10.36227/techrxiv.173273427.76836200/v1},
  urldate = {2025-11-17},
  abstract = {ChatGPT has now become a global phenomenon that has revolutionized the manner in which machines interact with humans. It is a noteworthy enhancement in the field of generative AI, where generative AI is designed to create new contents similar to human-generated contents. ChatGPT has been developed to utilise a generative AI model as its underlying model. It is self-adaptive as it learns from its multimodal interactions with users and improves its responses based on the feedback received from users; thus, providing more accurate and personalised responses to users. ChatGPT is constantly evolving to incorporate new technologies and capabilities within it; therefore, a comprehensive study is required to understand its various aspects. This paper will present a comprehensive study of ChatGPT exploring its architecture, underlying AI models and techniques, training procedures, capabilities, limitations and applications. This comprehensive study will provide users a stepby-step guide with detailed information by analysing the various aspects of ChatGPT systematically.},
  archiveprefix = {Preprints},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/MPNVPPL2/Naik et al. - 2024 - ChatGPT Is All You Need Untangling Its Underlying AI Models, Architecture, Training Procedure, Capa.pdf}
}

@misc{ngAnalyzingSecurityPrivacy2025,
  title = {Analyzing {{Security}} and {{Privacy Challenges}} in {{Generative AI Usage Guidelines}} for {{Higher Education}}},
  author = {Ng, Bei Yi and Li, Jiarui and Tong, Xinyuan and Ye, Kevin and Yenne, Gauthami and Chandrasekaran, Varun and Li, Jingjie},
  year = 2025,
  month = jun,
  number = {arXiv:2506.20463},
  eprint = {2506.20463},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2506.20463},
  urldate = {2025-11-11},
  abstract = {Educators and learners worldwide are embracing the rise of Generative Artificial Intelligence (GenAI) as it reshapes higher education. However, GenAI also raises significant privacy and security concerns, as models and privacy-sensitive user data, such as student records, may be misused by service providers. Unfortunately, end-users often have little awareness of or control over how these models operate. To address these concerns, universities are developing institutional policies to guide GenAI use while safeguarding security and privacy. This work examines these emerging policies and guidelines, with a particular focus on the often-overlooked privacy and security dimensions of GenAI integration in higher education, alongside other academic values. Through a qualitative analysis of GenAI usage guidelines from universities across 12 countries, we identify key challenges and opportunities institutions face in providing effective privacy and security protections, including the need for GenAI safeguards tailored specifically to the academic context.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Human-Computer Interaction},
  file = {/Users/fritz/Zotero/storage/X7FRWZCT/Ng et al. - 2025 - Analyzing Security and Privacy Challenges in Generative AI Usage Guidelines for Higher Education.pdf;/Users/fritz/Zotero/storage/53Y3MEXU/2506.html}
}

@article{nightingaleAIsynthesizedFacesAre2022,
  title = {{{AI-synthesized}} Faces Are Indistinguishable from Real Faces and More Trustworthy},
  author = {Nightingale, Sophie J. and Farid, Hany},
  year = 2022,
  month = feb,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {8},
  pages = {e2120481119},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2120481119},
  urldate = {2025-09-17},
  abstract = {Artificial intelligence (AI)--synthesized text, audio, image, and video are being weaponized for the purposes of nonconsensual intimate imagery, financial fraud, and disinformation campaigns. Our evaluation of the photorealism of AI-synthesized faces indicates that synthesis engines have passed through the uncanny valley and are capable of creating faces that are indistinguishable---and more trustworthy---than real faces.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/VAQ4PJQW/Nightingale and Farid - 2022 - AI-synthesized faces are indistinguishable from real faces and more trustworthy.pdf}
}

@article{nissenbaum2004privacy,
  title = {Privacy as Contextual Integrity},
  author = {Nissenbaum, Helen},
  year = 2004,
  volume = {79},
  pages = {119},
  publisher = {HeinOnline},
  file = {/Users/fritz/Zotero/storage/I4CMQVMD/Nissenbaum - 2004 - Privacy as contextual integrity.pdf}
}

@article{nissenbaum2019contextual,
  title = {Contextual Integrity up and down the Data Food Chain},
  author = {Nissenbaum, Helen},
  year = 2019,
  journal = {Theoretical inquiries in law},
  volume = {20},
  number = {1},
  pages = {221--256},
  publisher = {De Gruyter},
  file = {/Users/fritz/Zotero/storage/LI3HNA4W/Nissenbaum - 2019 - Contextual integrity up and down the data food chain.pdf}
}

@article{norheim2010crowdsourcing,
  title = {Crowdsourcing for Crisis Mapping in {{Haiti}}},
  author = {{Norheim-Hagtun}, Ida and Meier, Patrick},
  year = 2010,
  journal = {Innovations: Technology\textbar{} Governance\textbar{} Globalization},
  volume = {5},
  number = {4},
  pages = {81}
}

@article{nothias2020access,
  title = {Access Granted: {{Facebook}}'s Free Basics in {{Africa}}},
  shorttitle = {Access Granted},
  author = {Nothias, Toussaint},
  year = 2020,
  month = apr,
  journal = {Media, Culture \& Society},
  volume = {42},
  number = {3},
  pages = {329--348},
  publisher = {SAGE Publications Sage UK: London, England},
  issn = {0163-4437},
  doi = {10.1177/0163443719890530},
  urldate = {2025-07-10},
  abstract = {This article explores one of the most notorious and controversial initiatives by tech corporations to increase connectivity across the Global South: Facebook?s Free Basics project. Public attention focused on its ban in India following nationwide protests about net neutrality. In Africa, however, Free Basics expanded without much public scrutiny to some 32 countries. This article traces this quiet expansion by using an innovative virtual private network (VPN)-based method and by calling for an analytical focus on the landscape of the digital civil society in Africa. Specifically, I outline two key, interrelated phenomena: (1) Facebook?s evolving strategy, including a greater engagement with civil society organizations and (2) the focus of digital rights activists in Africa on issues like Internet shutdowns, government surveillance, and the lack of data privacy frameworks. In the process, I illuminate broader trends in the digital industry including tech corporations? growing investments in mobile social media, network infrastructures, and in civil society; the use of disadvantaged populations and unregulated territories for digital experiments and data extraction; and the mounting recognition of Facebook?s political role, both within and outside the corporation.},
  file = {/Users/fritz/Zotero/storage/DUF2SFYL/Nothias - 2020 - Access granted Facebookâ€™s free basics in Africa.pdf}
}

@article{oehlerDoesChatGPTProvide2024,
  title = {Does {{ChatGPT}} Provide Better Advice than Robo-Advisors?},
  author = {Oehler, Andreas and Horn, Matthias},
  year = 2024,
  month = feb,
  journal = {Finance Research Letters},
  volume = {60},
  pages = {104898},
  issn = {1544-6123},
  doi = {10.1016/j.frl.2023.104898},
  urldate = {2025-11-17},
  abstract = {We develop three investor profiles with different risk attitudes and consult ChatGPT and 17 robo-advisors to recommend an investment portfolio. We compare the recommendations with a benchmark derived from academic literature. ChatGPT's recommendations align with the three investor profiles and the benchmark. In contrast, only three out of the 17 robo-advisors come close to meeting the benchmark for all three investor profiles. Three robo-advisors fail to meet the benchmark for all investor profiles. Our findings reveal that ChatGPT provides better financial advice for one-time investments than robo-advisors. A policy implication is to clearly disclose that independent sophisticated chatbots can be recommended as a trustworthy source of information for retail investors.},
  keywords = {ChatGPT,Financial advice,Fintech,Portfolio management,Robo-advisor},
  file = {/Users/fritz/Zotero/storage/V87UUJ8H/S1544612323012709.html}
}

@article{okenyi2024meta,
  title = {Meta: {{The}} Cost of Strict Data Privacy Regime in the Era of Technology-Driven Economy},
  author = {Okenyi, Sunday Chinweike},
  year = 2024,
  journal = {Available at SSRN 4971392},
  file = {/Users/fritz/Zotero/storage/GNK2VN85/Okenyi - 2024 - Meta The cost of strict data privacy regime in the era of technology-driven economy.pdf}
}

@misc{onagGoogleUnveils$3B,
  title = {Google Unveils \${{3B}} Cloud and Data Center Investment in {{Thailand}} and {{Malaysia}}},
  author = {Onag, Gigi},
  journal = {Light Reading},
  urldate = {2025-12-08},
  abstract = {Google will build data center and cloud region infrastructure in Thailand and Malaysia to meet growing AI and cloud demand.},
  howpublished = {https://www.lightreading.com/data-centers/google-unveils-3b-cloud-and-data-center-investment-in-thailand-and-malaysia},
  langid = {english}
}

@misc{openaiPrivacyPolicy,
  title = {Privacy Policy},
  author = {OpenAi},
  urldate = {2025-11-17},
  abstract = {Privacy policy},
  howpublished = {https://openai.com/policies/row-privacy-policy/},
  langid = {american},
  file = {/Users/fritz/Zotero/storage/K9BBBSCV/row-privacy-policy.html}
}

@article{ozonsi103WHATSAPPDOC2025,
  title = {103. {{WHATSAPP DOC}}?!: {{OLDER IMMIGRANTS}}, {{COMMUNICATION AND MENTAL HEALTH}}.},
  author = {Ozonsi, Rosain and Mahamed, Amaal and Kim, Emily and Hashem, Saeed and Arias, Jessenia and Vahia, Ipsit},
  year = 2025,
  month = oct,
  journal = {The American Journal of Geriatric Psychiatry},
  volume = {33},
  number = {10},
  pages = {S76},
  publisher = {Elsevier},
  issn = {1064-7481},
  doi = {10.1016/j.jagp.2025.04.105},
  urldate = {2025-09-11}
}

@article{panahiDigitalDoubleData2025,
  title = {The {{Digital Double}}: {{Data Privacy}}, {{Security}}, and {{Consent}} in {{AI}}  {{Implants}}},
  author = {Panahi, Omid},
  year = 2025,
  journal = {Data Privacy},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/2VQJXHH8/2025 - WestLand publishers.pdf}
}

@article{papacharissiPrivacyLuxuryCommodity2010,
  title = {Privacy as a Luxury Commodity},
  author = {Papacharissi, Zizi},
  year = 2010,
  month = jul,
  journal = {First Monday},
  volume = {15},
  number = {8},
  issn = {13960466},
  doi = {10.5210/fm.v15i8.3075},
  urldate = {2025-09-11}
}

@article{pauwelsPreparingNextgenerationInformation2024,
  title = {Preparing for Next-Generation Information Warfare with Generative {{AI}}},
  author = {Pauwels, Eleonore},
  year = 2024,
  number = {310},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/YK42ZDVX/Pauwels - 2024 - Preparing for next-generation information warfare with generative AI.pdf}
}

@article{paytonVignetteResearchMethodology2022,
  title = {Vignette {{Research Methodology}}: {{An Essential Tool}} for {{Quality Improvement Collaboratives}}},
  shorttitle = {Vignette {{Research Methodology}}},
  author = {Payton, Kurlen S. E. and Gould, Jeffrey B.},
  year = 2022,
  month = dec,
  journal = {Healthcare},
  volume = {11},
  number = {1},
  pages = {7},
  issn = {2227-9032},
  doi = {10.3390/healthcare11010007},
  urldate = {2025-11-24},
  abstract = {Variation in patient outcomes among institutions and within institutions is a major problem in healthcare. Some of this variation is due to differences in practice, termed practice variation. Some practice variation is expected due to appropriately personalized care for a given patient. However, some practice variation is due to the individual preference or style of the clinicians. Quality improvement collaboratives are commonly used to disseminate quality care on a wide scale. Practice variation is a notable barrier to any quality improvement effort. A detailed and accurate understanding of practice variation can help optimize the quality improvement efforts. The traditional survey methods do not capture the complex nuances of practice variation. Vignette methods have been shown to accurately measure the actual practice variation and quality of care delivered by clinicians. Vignette methods are cost-effective relative to other methods of measuring quality of care. This review describes our experience and lessons from implementing vignette research methods in quality improvement collaboratives in California neonatal intensive care units. Vignette methodology is an ideal tool to address practice variation in quality improvement collaboratives, actively engage a large number of participants, and support more evidence-based practice to improve outcomes.},
  pmcid = {PMC9818599},
  pmid = {36611468},
  file = {/Users/fritz/Zotero/storage/NS4PZWU5/Payton and Gould - 2022 - Vignette Research Methodology An Essential Tool for Quality Improvement Collaboratives.pdf}
}

@misc{penaOppressiveAIFeminist2021,
  title = {Oppressive {{A}}.{{I}}.: {{Feminist Categories}} to {{Understand}} Its {{Political Effects}} >> {{Not}} My {{A}}.{{I}}.},
  shorttitle = {Oppressive {{A}}.{{I}}.},
  author = {Pena, Paz and Varon, Joana},
  year = 2021,
  month = may,
  journal = {Not my A.I.},
  urldate = {2025-12-01},
  abstract = {Base document for crafting a feminist framework to challenge the trend of deploying algorithmic decision-making systems in welfare programs},
  langid = {american}
}

@article{penneyAdvancingHumanRightsbyDesignDualUse2018,
  title = {Advancing {{Human-Rights-by-Design}} in the {{Dual-Use Technology Industry}}},
  author = {Penney, Jonathon and McKune, Sarah and Gill, Lex and Deibert, Ronald J.},
  year = 2018,
  journal = {Journal of International Affairs},
  volume = {71},
  number = {2},
  eprint = {26552332},
  eprinttype = {jstor},
  pages = {103--110},
  publisher = {Journal of International Affairs Editorial Board},
  issn = {0022-197X},
  urldate = {2025-11-06},
  file = {/Users/fritz/Zotero/storage/5JKBKKPT/Penney et al. - 2018 - Advancing Human-Rights-by-Design in the Dual-Use Technology Industry.pdf}
}

@misc{perezIgnorePreviousPrompt2022,
  title = {Ignore {{Previous Prompt}}: {{Attack Techniques For Language Models}}},
  shorttitle = {Ignore {{Previous Prompt}}},
  author = {Perez, F{\'a}bio and Ribeiro, Ian},
  year = 2022,
  month = nov,
  number = {arXiv:2211.09527},
  eprint = {2211.09527},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2211.09527},
  urldate = {2025-11-17},
  abstract = {Transformer-based large language models (LLMs) provide a powerful foundation for natural language tasks in large-scale customer-facing applications. However, studies that explore their vulnerabilities emerging from malicious user interaction are scarce. By proposing PromptInject, a prosaic alignment framework for mask-based iterative adversarial prompt composition, we examine how GPT-3, the most widely deployed language model in production, can be easily misaligned by simple handcrafted inputs. In particular, we investigate two types of attacks -- goal hijacking and prompt leaking -- and demonstrate that even low-aptitude, but sufficiently ill-intentioned agents, can easily exploit GPT-3's stochastic nature, creating long-tail risks. The code for PromptInject is available at https://github.com/agencyenterprise/PromptInject.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language}
}

@article{perifanouCollaborativeUsesGenAI2025,
  title = {Collaborative {{Uses}} of {{GenAI Tools}} in {{Project-Based Learning}}},
  author = {Perifanou, Maria and Economides, Anastasios A.},
  year = 2025,
  month = mar,
  journal = {Education Sciences},
  volume = {15},
  number = {3},
  pages = {354},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2227-7102},
  doi = {10.3390/educsci15030354},
  urldate = {2025-11-11},
  abstract = {Artificial intelligence (AI) is forcing a dramatic transformation of the methods by which we acquire knowledge and engage in collaborative learning. Although there are several studies on how AI can support collaborative learning, there are no published studies examining how students can actually collaborate among themselves while interacting with AI tools. For this study, thirty postgraduate students were organized into teams of three, and each team developed a project mainly exploiting responses from ChatGPT, Google Gemini, and MS Copilot, as well as the internet and class resources. Each team selected a specific internet of things (IoT) application area and described the technologies and real-world cases in this area. Then, each team delivered a report with the full description of their project and their interactions with these generative AI (GenAI) tools and presented their work in class. Additionally, students answered an online questionnaire with closed- and open-ended questions and participated in focus group discussions. Members of each team collaborated to design prompts using five suggested modes of collaboration. Eventually, half of the students exploited all five collaborative modes, but they mostly liked and preferred three of these collaborative modes. On average, teammates initially disagreed 24\% of the time but eventually reached an agreement. Students appreciated GenAI tools for their quick and well-structured responses, natural communication style, broad subject coverage, as well as their ability to simplify complex topics and support personalized learning. However, they expressed concerns about GenAI tools' inaccurate and inconsistent responses and identified key risks, such as passive learning, over-dependence, outdated information, and privacy issues. Finally, students recommended that GenAI tools should provide a shared and well-organized discussion space for collaborative prompt asking, allowing all team members to simultaneously view each other's prompts and the tool's responses. They also advised source verification and proper training to ensure these tools remain supplementary rather than primary learning resources.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {<i>ChatGPT</i>,<i>Copilot</i>,<i>Gemini</i>,collaborative learning,collaborative modes,collaborative prompting,GenAI,project-based learning,small group,team-based learning},
  file = {/Users/fritz/Zotero/storage/C35B8HIM/Perifanou and Economides - 2025 - Collaborative Uses of GenAI Tools in Project-Based Learning.pdf}
}

@article{pisa2019governing,
  title = {Governing Big Tech's Pursuit of the ``next Billion Users''},
  author = {Pisa, Michael and Polcari, John},
  year = 2019,
  journal = {Center for Global Development. Policy Paper},
  volume = {138}
}

@article{prinslooDataPrivacyAfrican2022,
  title = {Data Privacy on the {{African}} Continent: {{Opportunities}}, Challenges and Implications for Learning Analytics},
  shorttitle = {Data Privacy on the {{African}} Continent},
  author = {Prinsloo, Paul and Kaliisa, Rogers},
  year = 2022,
  journal = {British Journal of Educational Technology},
  volume = {53},
  number = {4},
  pages = {894--913},
  issn = {1467-8535},
  doi = {10.1111/bjet.13226},
  urldate = {2025-07-17},
  abstract = {Whilst learning analytics is still nascent in most African higher education institutions, many African higher education institutions use learning platforms and analytic services from providers outside of the African continent. A critical consideration of the protection of data privacy on the African continent and its implications for learning analytics in African higher education is therefore needed. In this paper, we map the current state of legal and regulatory environments and frameworks on privacy to establish their implications for learning analytics. This scoping review of privacy regulations in 32 African countries, complemented by 15 scholarly papers, revealed that there are numerous national and regional legislation and regulatory frameworks, providing clear pointers pertaining to (student) data privacy to governments, higher education institutions and researchers. As such, the findings of this research have implications for African higher education to ensure not only legal compliance but also to oversee and safeguard student data privacy as part of their fiduciary duty. This research provides crucial insights regarding the importance of context for thinking about the expansion and institutional adoption of learning analytics. Practitioner notes What is already known about this topic Personal data have become commodified and are regarded as a valuable commercial asset. The commercial value of data relies on the collection and analysis of increasing volumes, granularity, variety and velocity of personal data (both identifiable and aggregated). Africa and African higher education are regarded as new data frontiers to be exploited. What this paper adds This paper, for the first time, makes an attempt to map privacy legislation and academic research on (student) data privacy in the African continent. Maps key implications for African higher educations to consider in collecting, analysing, using and sharing student data. It provides pointers for a research agenda pertaining to student data privacy on the African continent. Implications for practice and/or policy African higher education institutions should consider student data privacy when entering into service level agreements with educational technology and platform providers. African governments should develop common data sharing frameworks to facilitate cross-border data transfer. Current African data privacy legislation provides important implications for the adoption and institutionalisation of learning analytics. African higher education also has to consider the ethical aspects of learning analytics.},
  langid = {english},
  keywords = {Africa,data protection,higher education,learning analytics,legislation,privacy},
  file = {/Users/fritz/Zotero/storage/SMGYXVZV/Prinsloo and Kaliisa - 2022 - Data privacy on the African continent Opportunities, challenges and implications for learning analy.pdf;/Users/fritz/Zotero/storage/W9R4R63N/bjet.html}
}

@article{puaschunder2018dignity,
  title = {Dignity and Utility of Privacy and Information Sharing in the Digital Big Data Age},
  author = {Puaschunder, Julia M},
  year = 2018,
  journal = {International Journal of Commerce and Management Research},
  volume = {5},
  number = {4},
  pages = {62--70},
  file = {/Users/fritz/Zotero/storage/DNZV2PB5/Puaschunder - 2018 - Dignity and utility of privacy and information sharing in the digital big data age.pdf}
}

@article{quinnWeCareDifferent2019,
  title = {We {{Care About Different Things}}: {{Non-Elite Conceptualizations}} of {{Social Media Privacy}}},
  shorttitle = {We {{Care About Different Things}}},
  author = {Quinn, Kelly and Epstein, Dmitry and Moon, Brenda},
  year = 2019,
  month = apr,
  journal = {Social Media + Society},
  volume = {5},
  number = {3},
  pages = {2056305119866008},
  issn = {2056-3051, 2056-3051},
  doi = {10.1177/2056305119866008},
  urldate = {2025-09-11},
  abstract = {This study explores privacy from the perspective of the user. It leverages a ``framing in thought'' approach to capture how users make sense of privacy in their social media use. It builds on a unique dataset of privacy definitions collected from a representative sample of 608 US social media users. The data are analyzed using topic modeling and semantic network analysis to unpack the multidimensionality of social media privacy. These dimensions are further examined in relation to established demographic antecedents of privacy concerns and behaviors. Results indicate the dominance of frames related to horizontal dimensions of privacy, or privacy vis-\`a-vis peers, as compared with the vertical dimensions, or privacy vis-\`a-vis institutions. In addition, the findings suggest that user conceptualization of privacy reflects a cognate-based approach that emphasizes control and limits to information access. Implications for privacy research, policy, and technology design are discussed.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/HLAF6HS6/Quinn et al. - 2019 - We Care About Different Things Non-Elite Conceptualizations of Social Media Privacy.pdf}
}

@article{ralph2019racial,
  title = {Racial Capitalism},
  author = {Ralph, Michael and Singhal, Maya},
  year = 2019,
  journal = {Theory and Society},
  volume = {48},
  number = {6},
  pages = {851--881},
  publisher = {Springer},
  file = {/Users/fritz/Zotero/storage/N7Z4BZ46/Ralph and Singhal - 2019 - Racial capitalism.pdf}
}

@article{rathenauinstituutPrijsVanGratis2025,
  title = {{De prijs van gratis internet}},
  author = {{Rathenau Instituut}},
  year = 2025,
  langid = {dutch},
  file = {/Users/fritz/Zotero/storage/W4CYDAUD/Redeker - De prijs van gratis internet.pdf}
}

@inproceedings{razaghpanahAppsTrackersPrivacy2018,
  title = {Apps, {{Trackers}}, {{Privacy}}, and {{Regulators}}: {{A Global Study}} of the {{Mobile Tracking Ecosystem}}},
  shorttitle = {Apps, {{Trackers}}, {{Privacy}}, and {{Regulators}}},
  booktitle = {Proceedings 2018 {{Network}} and {{Distributed System Security Symposium}}},
  author = {Razaghpanah, Abbas and Nithyanand, Rishab and {Vallina-Rodriguez}, Narseo and Sundaresan, Srikanth and Allman, Mark and Kreibich, Christian and Gill, Phillipa},
  year = 2018,
  publisher = {Internet Society},
  address = {San Diego, CA},
  doi = {10.14722/ndss.2018.23353},
  urldate = {2025-08-20},
  abstract = {Third-party services form an integral part of the mobile ecosystem: they ease application development and enable features such as analytics, social network integration, and app monetization through ads. However, aided by the general opacity of mobile systems, such services are also largely invisible to users. This has negative consequences for user privacy as third-party services can potentially track users without their consent, even across multiple applications. Using real-world mobile traffic data gathered by the Lumen Privacy Monitor (Lumen), a privacyenhancing app with the ability to analyze network traffic on mobile devices in user space, we present insights into the mobile advertising and tracking ecosystem and its stakeholders. In this study, we develop automated methods to detect third-party advertising and tracking services at the traffic level. Using this technique we identify 2,121 such services, of which 233 were previously unknown to other popular advertising and tracking blacklists. We then uncover the business relationships between the providers of these services and characterize them by their prevalence in the mobile and Web ecosystem. Our analysis of the privacy policies of the largest advertising and tracking service providers shows that sharing harvested data with subsidiaries and third-party affiliates is the norm. Finally, we seek to identify the services likely to be most impacted by privacy regulations such as the European General Data Protection Regulation (GDPR) and ePrivacy directives.},
  isbn = {978-1-891562-49-5},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/8KMDBDVY/Razaghpanah et al. - 2018 - Apps, Trackers, Privacy, and Regulators A Global Study of the Mobile Tracking Ecosystem.pdf}
}

@misc{Refugeesandthebiometricfuturetheimpactofbiometricsonrefugeesandasylumseekers,
  title = {Refugees-and-the-Biometric-Future-the-Impact-of-Biometrics-on-Refugees-and-Asylum-Seekers},
  publisher = {Koninklijke Brill NV},
  doi = {10.1163/2210-7975_HRD-9947-0034},
  urldate = {2025-07-05},
  langid = {english}
}

@article{reidRisksGenerativeArtificial2024,
  title = {Risks of Generative Artificial Intelligence ({{GenAI}})-Assisted Scams on Online Sharing-Economy Platforms},
  author = {Reid, Julie},
  year = 2024,
  month = aug,
  journal = {The African Journal of Information and Communication (AJIC)},
  number = {33},
  pages = {1--21},
  issn = {2077-7213, 2077-7205},
  doi = {10.23962/ajic.i33.18162},
  urldate = {2025-09-17},
  abstract = {The prevalence of scams proliferating via online platforms has been identified as an emerging societal problem resulting in large-scale financial losses for victims. Online scams typically rely for their success on the generation of fake but convincing user profiles to conceal the identities of the scammers from the people being tricked into parting with their money. The increasing sophistication of generative artificial intelligence (GenAI), which can produce outputs indistinguishable from real content, thus carries the risk of being adopted by fraudsters to assist in the enactment of online scams. This article considers the risks of the potential uptake and use of GenAI applications by online scammers operating in the sharing economy, with a focus on homestay-marketplace platforms and, in particular, the largest such platform, Airbnb.},
  copyright = {https://creativecommons.org/licenses/by/4.0},
  file = {/Users/fritz/Zotero/storage/NGP8FYUI/Reid - 2024 - Risks of generative artificial intelligence (GenAI)-assisted scams on online sharing-economy platfor.pdf}
}

@article{ren2024reconciling,
  title = {Reconciling the Contrasting Narratives on the Environmental Impact of Large Language Models},
  author = {Ren, Shaolei and Tomlinson, Bill and Black, Rebecca W and Torrance, Andrew W},
  year = 2024,
  journal = {Scientific Reports},
  volume = {14},
  number = {1},
  pages = {26310},
  publisher = {Nature Publishing Group UK London}
}

@article{rennie2024private,
  title = {Private Commercial Companies Sharing Health-Relevant Consumer Data with Health Researchers in Sub-{{Saharan Africa}}: An Ethical Exploration},
  author = {Rennie, Stuart and Litewka, Sergio and Vayena, Effy and Chingarande, George and Mtande, Tiwonge and Cengiz, Nezerith and Singh, Jerome and Jaoko, Walter and Moodley, Keymanthri},
  year = 2024,
  journal = {Policy Studies},
  pages = {1--18},
  publisher = {Taylor \& Francis},
  file = {/Users/fritz/Zotero/storage/YX2EZBWK/Rennie et al. - 2024 - Private commercial companies sharing health-relevant consumer data with health researchers in sub-Sa.pdf}
}

@article{ricaurteDataEpistemologiesColoniality2019,
  title = {Data {{Epistemologies}}, {{The Coloniality}} of {{Power}}, and {{Resistance}}},
  author = {Ricaurte, Paola},
  year = 2019,
  month = may,
  journal = {Television \& New Media},
  volume = {20},
  number = {4},
  pages = {350--365},
  publisher = {SAGE Publications},
  issn = {1527-4764},
  doi = {10.1177/1527476419831640},
  urldate = {2025-12-08},
  abstract = {Data assemblages amplify historical forms of colonization through a complex arrangement of practices, materialities, territories, bodies, and subjectivities. Data-centric epistemologies should be understood as an expression of the coloniality of power manifested as the violent imposition of ways of being, thinking, and feeling that leads to the expulsion of human beings from the social order, denies the existence of alternative worlds and epistemologies, and threatens life on Earth. This article develops a theoretical model to analyze the coloniality of power through data and explores the multiple dimensions of coloniality as a framework for identifying ways of resisting data colonization. Finally, this article suggests possible alternative data epistemologies that are respectful of populations, cultural diversity, and environments.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/3C98YE93/Ricaurte - 2019 - Data Epistemologies, The Coloniality of Power, and Resistance.pdf}
}

@article{ricaurteEthicsMajorityWorld2022,
  title = {Ethics for the Majority World: {{AI}} and the Question of Violence at Scale},
  shorttitle = {Ethics for the Majority World},
  author = {Ricaurte, Paola},
  year = 2022,
  month = may,
  journal = {Media, Culture \& Society},
  volume = {44},
  number = {4},
  pages = {726--745},
  publisher = {SAGE Publications Ltd},
  issn = {0163-4437},
  doi = {10.1177/01634437221099612},
  urldate = {2025-11-29},
  abstract = {In this work, I argue that hegemonic AI is becoming a more powerful force capable of perpetrating global violence through three epistemic processes: datafication (extraction and dispossession), algorithmisation (mediation and governmentality) and automation (violence, inequality and displacement of responsibility). These articulated epistemic mechanisms lead to global classification orders and epistemic, economic, social, cultural and environmental inequality. Hegemonic AI can be thought of as a bio-necro-technopolitical machine that serves to maintain the capitalist, colonialist and patriarchal order of the world. To make this point, the proposed approach bridges the macro and micropolitical, building on Suely Rolnik?s call for understanding the effects of the macropolitical in the micropolitical, as well as what feminist black scholar Patricia Hill Collins made visible about oppressive systems operating at the structural, institutional and individual levels. A critical AI ethics is one that is concerned with the preservation of life and the coresponsibility of AI harms to the majority of the planet.},
  file = {/Users/fritz/Zotero/storage/VVVXJ53Z/Ricaurte - 2022 - Ethics for the majority world AI and the question of violence at scale.pdf}
}

@article{rillig2023risks,
  title = {Risks and Benefits of Large Language Models for the Environment},
  author = {Rillig, Matthias C and {\AA}gerstrand, Marlene and Bi, Mohan and Gould, Kenneth A and Sauerland, Uli},
  year = 2023,
  journal = {Environmental science \& technology},
  volume = {57},
  number = {9},
  pages = {3464--3466},
  publisher = {ACS Publications}
}

@article{rivaDisembodiedDisconnectHypothesis2024,
  title = {The {{Disembodied Disconnect Hypothesis}}: {{How Online Interactions Undermine Neurobiological Foundations}} of {{Social Cohesion}}},
  shorttitle = {The {{Disembodied Disconnect Hypothesis}}},
  author = {Riva, Giuseppe and Wiederhold, Brenda K. and Mantovani, Fabrizia},
  year = 2024,
  month = oct,
  journal = {Cyberpsychology, Behavior, and Social Networking},
  volume = {27},
  number = {10},
  pages = {680--682},
  issn = {2152-2715, 2152-2723},
  doi = {10.1089/cyber.2024.0334},
  urldate = {2025-11-27},
  copyright = {https://www.liebertpub.com/nv/resources-tools/text-and-data-mining-policy/121/},
  langid = {english}
}

@article{rodima2022sending,
  title = {Sending Money Home in Conflict Settings: {{Revisiting}} Migrant Remittances},
  author = {{Rodima-Taylor}, Daivi},
  year = 2022,
  journal = {Georgetown Journal of International Affairs},
  volume = {23},
  number = {1},
  pages = {43--51},
  publisher = {Johns Hopkins University Press},
  file = {/Users/fritz/Zotero/storage/LSFJ6WEG/Rodima-Taylor - 2022 - Sending money home in conflict settings Revisiting migrant remittances.pdf}
}

@article{rodima2024grassroots,
  title = {Grassroots Data Activism and Polycentric Governance: {{Perspectives}} from the Margins},
  author = {{Rodima-Taylor}, Daivi},
  year = 2024,
  journal = {Available at SSRN 5061474},
  file = {/Users/fritz/Zotero/storage/8ZTP78Y5/Rodima-Taylor - 2024 - Grassroots data activism and polycentric governance Perspectives from the margins.pdf}
}

@misc{roeGenAIDigitalPlastic2025,
  title = {{{GenAI}} as {{Digital Plastic}}: {{Understanding Synthetic Media Through Critical AI Literacy}}},
  shorttitle = {{{GenAI}} as {{Digital Plastic}}},
  author = {Roe, Jasper and Furze, Leon and Perkins, Mike},
  year = 2025,
  month = feb,
  number = {arXiv:2502.08249},
  eprint = {2502.08249},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2502.08249},
  urldate = {2025-09-17},
  abstract = {This paper introduces the conceptual metaphor of 'digital plastic' as a framework for understanding the implications of Generative Artificial Intelligence (GenAI) content through a multiliteracies lens, drawing parallels with the properties of physical plastic. Similar to its physical counterpart, GenAI content offers possibilities for content creation and accessibility while potentially contributing to digital pollution and ecosystem degradation. Drawing on multiliteracies theory and Conceptual Metaphor Theory, we argue that Critical Artificial Intelligence Literacy (CAIL) must be integrated into educational frameworks to help learners navigate this synthetic media landscape. We examine how GenAI can simultaneously lower the barriers to creative and academic production while threatening to degrade digital ecosystems through misinformation, bias, and algorithmic homogenization. The digital plastic metaphor provides a theoretical foundation for understanding both the affordances and challenges of GenAI, particularly in educational contexts, where issues of equity and access remain paramount. Our analysis concludes that cultivating CAIL through a multiliteracies lens is vital for ensuring the equitable development of critical competencies across geographical and cultural contexts, especially for those disproportionately vulnerable to GenAI's increasingly disruptive effects worldwide.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society},
  file = {/Users/fritz/Zotero/storage/WX8SSYBX/Roe et al. - 2025 - GenAI as Digital Plastic Understanding Synthetic Media Through Critical AI Literacy.pdf;/Users/fritz/Zotero/storage/9ZI5HX83/2502.html}
}

@article{rotman2009you,
  title = {Are You Looking at Me?-{{Social}} Media and Privacy Literacy},
  author = {Rotman, Dana},
  year = 2009,
  file = {/Users/fritz/Zotero/storage/DVYU3L4F/Rotman - Are You Looking At Me - Social Media and Privacy Literacy.pdf}
}

@article{sadowskiWhenDataCapital2019,
  title = {When Data Is Capital: {{Datafication}}, Accumulation, and Extraction},
  shorttitle = {When Data Is Capital},
  author = {Sadowski, Jathan},
  year = 2019,
  month = jan,
  journal = {Big Data \& Society},
  volume = {6},
  number = {1},
  pages = {2053951718820549},
  publisher = {SAGE Publications Ltd},
  issn = {2053-9517},
  doi = {10.1177/2053951718820549},
  urldate = {2025-11-19},
  abstract = {The collection and circulation of data is now a central element of increasingly more sectors of contemporary capitalism. This article analyses data as a form of capital that is distinct from, but has its roots in, economic capital. Data collection is driven by the perpetual cycle of capital accumulation, which in turn drives capital to construct and rely upon a universe in which everything is made of data. The imperative to capture all data, from all sources, by any means possible influences many key decisions about business models, political governance, and technological development. This article argues that many common practices of data accumulation should actually be understood in terms of data extraction, wherein data is taken with little regard for consent and compensation. By understanding data as a form capital, we can better analyse the meaning, practices, and implications of datafication as a political economic regime.},
  file = {/Users/fritz/Zotero/storage/8WBZL24X/Sadowski - 2019 - When data is capital Datafication, accumulation, and extraction.pdf}
}

@article{sartoriMindingGapsPublic2023,
  title = {Minding the Gap(s): Public Perceptions of {{AI}} and Socio-Technical Imaginaries},
  shorttitle = {Minding the Gap(s)},
  author = {Sartori, Laura and Bocca, Giulia},
  year = 2023,
  month = apr,
  journal = {AI \& SOCIETY},
  volume = {38},
  number = {2},
  pages = {443--458},
  issn = {1435-5655},
  doi = {10.1007/s00146-022-01422-1},
  urldate = {2025-11-10},
  abstract = {Deepening and digging into the social side of AI is a novel but emerging requirement within the AI community. Future research should invest in an ``AI for people'', going beyond the undoubtedly much-needed efforts into ethics, explainability and responsible AI. The article addresses this challenge by problematizing the discussion around AI shifting the attention to individuals and their awareness, knowledge and emotional response to AI. First, we outline our main argument relative to the need for a socio-technical perspective in the study of AI social implications. Then, we illustrate the main existing narratives of hopes and fears associated with AI and robots. As building blocks of broader ``sociotechnical imaginaries'', narratives are powerful tools that shape how society sees, interprets and organizes technology. An original empirical study within the University of Bologna collects the data to examine the levels of awareness, knowledge and emotional response towards AI, revealing interesting insights to be carried on in future research. Replete with exaggerations, both utopian and dystopian narratives are analysed with respect to some relevant socio-demographic variables (gender, generation and competence). Finally, focusing on two issues---the state of AI anxiety and the point of view of non-experts---opens the floor to problematizing the discourse around AI, sustaining the need for a sociological perspective in the field of AI and discussing future comparative research.},
  langid = {english},
  keywords = {AI anxiety,AI narratives,Inequalities,Role of non-experts,Socio-technical imaginaries}
}

@book{schneier2015data,
  title = {Data and {{Goliath}}: {{The}} Hidden Battles to Collect Your Data and Control Your World},
  author = {Schneier, Bruce},
  year = 2015,
  publisher = {WW Norton \& Company}
}

@article{segura2019between,
  title = {Between Data Capitalism and Data Citizenship},
  author = {Segura, Maria Soledad and Waisbord, Silvio},
  year = 2019,
  journal = {Television \& New Media},
  volume = {20},
  number = {4},
  pages = {412--419},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA},
  file = {/Users/fritz/Zotero/storage/9T22CV3B/Segura and Waisbord - 2019 - Between data capitalism and data citizenship.pdf}
}

@inproceedings{senFreeBridgeDigital2016,
  title = {On the {{Free Bridge Across}} the {{Digital Divide}}: {{Assessing}} the {{Quality}} of {{Facebook}}'s {{Free Basics Service}}},
  shorttitle = {On the {{Free Bridge Across}} the {{Digital Divide}}},
  booktitle = {Proceedings of the 2016 {{Internet Measurement Conference}}},
  author = {Sen, Rijurekha and Pirzada, Hasnain Ali and Phokeer, Amreesh and Farooq, Zaid Ahmed and Sengupta, Satadal and Choffnes, David and Gummadi, Krishna P.},
  year = 2016,
  month = nov,
  pages = {127--133},
  publisher = {ACM},
  address = {Santa Monica California USA},
  doi = {10.1145/2987443.2987485},
  urldate = {2025-07-16},
  abstract = {Free Basics is an initiative backed by Facebook to provide users in developing countries free mobile Internet access to selected services. Despite its wide-spread deployment and its potential impact on bridging the digital divide, to date, few studies have rigorously measured the quality of the free Internet service offered by Free Basics. In this short paper, we characterize the quality of the Free Basics service offered in Pakistan and South Africa along three dimensions: (i) the selection of accessible Web services, (ii) the functionality of those services, and (iii) the network performance for those services. While preliminary, our findings show that datadriven studies are essential for having more informed public debates on the pros and cons of the current design of the Free Basics service.},
  copyright = {https://www.acm.org/publications/policies/copyright\_policy\#Background},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/3SJQNDC4/Sen et al. - 2016 - On the Free Bridge Across the Digital Divide Assessing the Quality of Facebook's Free Basics Servic.pdf}
}

@article{senWalledGardenDeconstructing2017,
  title = {Inside the {{Walled Garden}}: {{Deconstructing Facebook}}'s {{Free Basics Program}}},
  shorttitle = {Inside the {{Walled Garden}}},
  author = {Sen, Rijurekha and Ahmad, Sohaib and Phokeer, Amreesh and Farooq, Zaid Ahmed and Qazi, Ihsan Ayyub and Choffnes, David and Gummadi, Krishna P.},
  year = 2017,
  month = oct,
  journal = {ACM SIGCOMM Computer Communication Review},
  volume = {47},
  number = {5},
  pages = {12--24},
  publisher = {Association for Computing Machinery (ACM)},
  issn = {0146-4833},
  doi = {10.1145/3155055.3155058},
  urldate = {2025-07-16},
  abstract = {Free Basics is a Facebook initiative to provide zero-rated web services in developing countries. The program has grown rapidly to 60+ countries in the past two years [14]. But it has also seen strong opposition from Internet activists and has been banned in some countries like India [4, 11, 12, 22]. Facebook highlights the societal benefits of providing lowincome populations with free Internet access, while detractors point to concerns about privacy and network neutrality.},
  copyright = {https://www.acm.org/publications/policies/copyright\_policy\#Background},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/5Q3NV5LG/Sen et al. - 2017 - Inside the Walled Garden Deconstructing Facebook's Free Basics Program.pdf}
}

@misc{shoaibDeepfakesMisinformationDisinformation2023,
  title = {Deepfakes, {{Misinformation}}, and {{Disinformation}} in the {{Era}} of {{Frontier AI}}, {{Generative AI}}, and {{Large AI Models}}},
  author = {Shoaib, Mohamed R. and Wang, Zefan and Ahvanooey, Milad Taleby and Zhao, Jun},
  year = 2023,
  month = nov,
  number = {arXiv:2311.17394},
  eprint = {2311.17394},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.17394},
  urldate = {2025-09-17},
  abstract = {With the advent of sophisticated artificial intelligence (AI) technologies, the proliferation of deepfakes and the spread of m/disinformation have emerged as formidable threats to the integrity of information ecosystems worldwide. This paper provides an overview of the current literature. Within the frontier AI's crucial application in developing defense mechanisms for detecting deepfakes, we highlight the mechanisms through which generative AI based on large models (LM-based GenAI) craft seemingly convincing yet fabricated contents. We explore the multifaceted implications of LM-based GenAI on society, politics, and individual privacy violations, underscoring the urgent need for robust defense strategies. To address these challenges, in this study, we introduce an integrated framework that combines advanced detection algorithms, cross-platform collaboration, and policy-driven initiatives to mitigate the risks associated with AI-Generated Content (AIGC). By leveraging multi-modal analysis, digital watermarking, and machine learning-based authentication techniques, we propose a defense mechanism adaptable to AI capabilities of ever-evolving nature. Furthermore, the paper advocates for a global consensus on the ethical usage of GenAI and implementing cyber-wellness educational programs to enhance public awareness and resilience against m/disinformation. Our findings suggest that a proactive and collaborative approach involving technological innovation and regulatory oversight is essential for safeguarding netizens while interacting with cyberspace against the insidious effects of deepfakes and GenAI-enabled m/disinformation campaigns.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {/Users/fritz/Zotero/storage/926PAN64/Shoaib et al. - 2023 - Deepfakes, Misinformation, and Disinformation in the Era of Frontier AI, Generative AI, and Large AI.pdf;/Users/fritz/Zotero/storage/F56MC7DK/2311.html}
}

@article{shomotovaWhatShapesStudents2025,
  title = {What Shapes Students' {{AI}} Literacy? {{Investigating}} Digital Competence, Student Background, and {{GenAI}} Use in Higher Education},
  shorttitle = {What Shapes Students' {{AI}} Literacy?},
  author = {Shomotova, Aizhan and ElSayary, Areej and Husain, Salwa},
  year = 2025,
  month = nov,
  journal = {Education and Information Technologies},
  issn = {1360-2357, 1573-7608},
  doi = {10.1007/s10639-025-13832-x},
  urldate = {2025-11-28},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/9PSLNHF6/Shomotova et al. - 2025 - What shapes studentsâ€™ AI literacy Investigating digital competence, student background, and GenAI u.pdf}
}

@inproceedings{silvennoinenStudentsUsageGenAI2025,
  title = {Students' {{Usage}} of {{GenAI}} in {{Universities}} of {{Applied Sciences}}: {{Experiences}} and {{Development Needs}} for {{Guidance}} and {{Support}}},
  shorttitle = {Students' {{Usage}} of {{GenAI}} in {{Universities}} of {{Applied Sciences}}},
  booktitle = {38th {{Bled eConference}}: {{Empowering Transformation}}: {{Shaping Digital Futures}} for {{All}}: {{Conference Proceedings}}},
  author = {Silvennoinen, Minna and Aksovaara, Satu and {Alanko-Turunen}, Merja},
  year = 2025,
  month = jun,
  pages = {467--482},
  publisher = {University of Maribor Press},
  doi = {10.18690/um.fov.4.2025.29},
  urldate = {2025-11-11},
  abstract = {This article explores University of Applied Sciences students' awareness and use of GenAI, as well as their experiences with institutional guidelines and educator support. At the time of data collection, these institutions were in the early stages of GenAI adoption. A survey of 160 students revealed varied uses of GenAI and suggested that a notable proportion of students perceived the guidelines, and their delivery as unclear or inconsistent. Our results indicate that GenAI usage is not yet fully addressed in course-level practices, which may contribute to fragmented and inconsistent use of the technology among students. Moreover, students were more likely to seek help from peers than from educators when encountering difficulties with AI applications, which may reflect students' perceptions of the limited availability of educator support. The findings support previous research that there is a need for increased awareness of GenAI use in higher education among both students and educators. The study highlights the need for strengthening the role of educators in encouraging and influencing how their students perceive and adopt GenAI technology.},
  isbn = {978-961-286-998-4},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/HIBV5AWI/Silvennoinen et al. - 2025 - Studentsâ€™ Usage of GenAI in Universities of Applied Sciences Experiences and Development Needs for.pdf}
}

@misc{sirimanneHowArtificialIntelligence2023,
  title = {How Artificial Intelligence Chatbots Could Affect Jobs \textbar{} {{UN Trade}} and {{Development}} ({{UNCTAD}})},
  author = {Sirimanne, Shamika N.},
  year = 2023,
  month = jan,
  urldate = {2025-11-10},
  abstract = {The recent launch of ChatGPT, a chatbot created by Open AI for public use, has underscored the growing reach of digital technologies like artificial},
  howpublished = {https://unctad.org/news/blog-how-artificial-intelligence-chatbots-could-affect-jobs},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/FG87UA6D/blog-how-artificial-intelligence-chatbots-could-affect-jobs.html}
}

@inproceedings{soden2014crowdsourced,
  title = {From Crowdsourced Mapping to Community Mapping: {{The}} Post-Earthquake Work of {{OpenStreetMap Haiti}}},
  booktitle = {{{COOP}} 2014-Proceedings of the 11th International Conference on the Design of Cooperative Systems, 27-30 May 2014, Nice (France)},
  author = {Soden, Robert and Palen, Leysia},
  year = 2014,
  pages = {311--326},
  publisher = {Springer}
}

@article{sovacoolPromotingNoveltyRigor2018,
  title = {Promoting Novelty, Rigor, and Style in Energy Social Science: {{Towards}} Codes of Practice for Appropriate Methods and Research Design},
  shorttitle = {Promoting Novelty, Rigor, and Style in Energy Social Science},
  author = {Sovacool, Benjamin K. and Axsen, Jonn and Sorrell, Steve},
  year = 2018,
  month = nov,
  journal = {Energy Research \& Social Science},
  series = {Special {{Issue}} on the {{Problems}} of {{Methods}} in {{Climate}} and {{Energy Research}}},
  volume = {45},
  pages = {12--42},
  issn = {2214-6296},
  doi = {10.1016/j.erss.2018.07.007},
  urldate = {2025-07-15},
  abstract = {A series of weaknesses in creativity, research design, and quality of writing continue to handicap energy social science. Many studies ask uninteresting research questions, make only marginal contributions, and lack innovative methods or application to theory. Many studies also have no explicit research design, lack rigor, or suffer from mangled structure and poor quality of writing. To help remedy these shortcomings, this Review offers suggestions for how to construct research questions; thoughtfully engage with concepts; state objectives; and appropriately select research methods. Then, the Review offers suggestions for enhancing theoretical, methodological, and empirical novelty. In terms of rigor, codes of practice are presented across seven method categories: experiments, literature reviews, data collection, data analysis, quantitative energy modeling, qualitative analysis, and case studies. We also recommend that researchers beware of hierarchies of evidence utilized in some disciplines, and that researchers place more emphasis on balance and appropriateness in research design. In terms of style, we offer tips regarding macro and microstructure and analysis, as well as coherent writing. Our hope is that this Review will inspire more interesting, robust, multi-method, comparative, interdisciplinary and impactful research that will accelerate the contribution that energy social science can make to both theory and practice.},
  keywords = {Interdisciplinary research,Research excellence,Research methodology,Research methods,Validity},
  file = {/Users/fritz/Zotero/storage/U3958P6I/Sovacool et al. - 2018 - Promoting novelty, rigor, and style in energy social science Towards codes of practice for appropri.pdf;/Users/fritz/Zotero/storage/B48X4QH2/S2214629618307230.html}
}

@article{sovacoolPromotingNoveltyRigor2018a,
  title = {Promoting Novelty, Rigor, and Style in Energy Social Science: {{Towards}} Codes of Practice for Appropriate Methods and Research Design},
  shorttitle = {Promoting Novelty, Rigor, and Style in Energy Social Science},
  author = {Sovacool, Benjamin K. and Axsen, Jonn and Sorrell, Steve},
  year = 2018,
  month = nov,
  journal = {Energy Research \& Social Science},
  series = {Special {{Issue}} on the {{Problems}} of {{Methods}} in {{Climate}} and {{Energy Research}}},
  volume = {45},
  pages = {12--42},
  issn = {2214-6296},
  doi = {10.1016/j.erss.2018.07.007},
  urldate = {2025-07-17},
  abstract = {A series of weaknesses in creativity, research design, and quality of writing continue to handicap energy social science. Many studies ask uninteresting research questions, make only marginal contributions, and lack innovative methods or application to theory. Many studies also have no explicit research design, lack rigor, or suffer from mangled structure and poor quality of writing. To help remedy these shortcomings, this Review offers suggestions for how to construct research questions; thoughtfully engage with concepts; state objectives; and appropriately select research methods. Then, the Review offers suggestions for enhancing theoretical, methodological, and empirical novelty. In terms of rigor, codes of practice are presented across seven method categories: experiments, literature reviews, data collection, data analysis, quantitative energy modeling, qualitative analysis, and case studies. We also recommend that researchers beware of hierarchies of evidence utilized in some disciplines, and that researchers place more emphasis on balance and appropriateness in research design. In terms of style, we offer tips regarding macro and microstructure and analysis, as well as coherent writing. Our hope is that this Review will inspire more interesting, robust, multi-method, comparative, interdisciplinary and impactful research that will accelerate the contribution that energy social science can make to both theory and practice.},
  keywords = {Interdisciplinary research,Research excellence,Research methodology,Research methods,Validity},
  file = {/Users/fritz/Zotero/storage/VE94M7GQ/Sovacool et al. - 2018 - Promoting novelty, rigor, and style in energy social science Towards codes of practice for appropri.pdf;/Users/fritz/Zotero/storage/65H5TT44/S2214629618307230.html}
}

@misc{stacciariniDataCentersCritical2025,
  title = {Data {{Centers}}, {{Critical Minerals}}, {{Energy}}, and {{Geopolitics}}: {{The Foundations}} of {{Artificial Intelligence}}},
  shorttitle = {Data {{Centers}}, {{Critical Minerals}}, {{Energy}}, and {{Geopolitics}}},
  author = {Stacciarini, Jo{\~a}o Henrique Santana and Gon{\c c}alves, Ricardo Junior De Assis Fernandes},
  year = 2025,
  month = feb,
  publisher = {SocArXiv},
  doi = {10.31235/osf.io/2zvkt_v1},
  urldate = {2025-12-08},
  abstract = {Artificial Intelligence (AI) has expanded significantly in recent years, permeating various sectors of the economy and the daily lives of over 5.5 billion active internet users worldwide. However, this rapid adoption necessitates an analysis of the trade-offs inherent to its operation, many of which remain largely unknown to the public. Drawing on data from academic articles, technical reports, data repositories, and government documents, this article examines the physical, energy, and geopolitical dimensions underpinning AI. Although often perceived as immaterial, AI depends on a vast and complex physical infrastructure, sustained by data centers that house thousands of devices composed of a diverse array of minerals and metals, many classified as critical. Currently, approximately 12,000 data centers are in operation globally, including 992 hyperscale facilities spanning thousands of square meters. The short lifecycle of equipment in these centers, combined with inadequate disposal practices, leads to the loss of valuable metals from the supply chain, further intensifying mineral extraction and exacerbating socio-environmental impacts. Simultaneously, the rivalry between the United States and China over control of critical minerals and dominance in AI technologies has escalated geopolitical tensions, resulting in mutual restrictions on the export of advanced technologies and essential minerals. Another critical factor is AI's substantial energy consumption: in the United States, data centers already account for approximately 4\% of national electricity consumption, with projections reaching 9.1\% by 2030. While major technology companies invest in renewable energy sources such as solar and wind to meet this growing demand, these sources also require significant volumes of critical minerals. These interrelated factors underscore the intricate connections between Artificial Intelligence, Data Centers, Critical Minerals, Energy, and Geopolitics.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/BG393ZAE/Stacciarini and GonÃ§alves - 2025 - Data Centers, Critical Minerals, Energy, and Geopolitics The Foundations of Artificial Intelligence.pdf}
}

@book{Stiegler2019-STITAO-9,
  title = {The Age of Disruption: {{Technology}} and Madness in Computational Capitalism},
  author = {Stiegler, Bernard},
  year = 2019,
  publisher = {Polity}
}

@article{stojkovic2024towards,
  title = {Towards Greener Llms: {{Bringing}} Energy-Efficiency to the Forefront of Llm Inference},
  author = {Stojkovic, Jovan and Choukse, Esha and Zhang, Chaojie and Goiri, Inigo and Torrellas, Josep},
  year = 2024,
  journal = {arXiv preprint arXiv:2403.20306},
  eprint = {2403.20306},
  archiveprefix = {arXiv}
}

@article{sujarwoForecastingRiceStatus2022,
  title = {Forecasting {{Rice Status}} for a {{Food Crisis Early Warning System Based}} on {{Satellite Imagery}} and {{Cellular Automata}} in {{Malang}}, {{Indonesia}}},
  author = {{Sujarwo} and Putra, Aditya Nugraha and Setyawan, Raden Arief and Teixeira, Heitor Mancini and Khumairoh, Uma},
  year = 2022,
  month = jul,
  journal = {Sustainability},
  volume = {14},
  number = {15},
  pages = {8972},
  issn = {2071-1050},
  doi = {10.3390/su14158972},
  urldate = {2025-10-16},
  abstract = {The increasing population in Indonesia is challenging rice production to feed more people while rice fields are being converted to other land-use land cover (LULC). This study analyzes land use in 2015, 2017, 2019, 2021, and 2025 using an artificial neural network cellular automata (ANN-CA) and rice data from Statistics Indonesia to predict future rice status in Malang Districts, Indonesia. The primary LULC change driver was the rapid conversion of rice fields, which had their area reduced by 18\% from 2019 to 2021 and 2\% from 2021 to 2025. Rice fields are mainly being converted to settlements and buildings. The Kappa coefficient of simulation achieved 88\%, with 91 accuracies. The model predicted a 2\% lower rate of rice production but a 3\% higher demand in 2025 compared to 2021. Lower rice production and higher demand are predicted to reduce the rice surplus by 57\% in 2025, suggesting that the Malang district might lower its supply of rice to other areas by 2025. Our study provides a food crisis early warning system that decision makers can use to form adequate strategic plans and solutions to combat food insecurity.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/SSD62G72/Sujarwo et al. - 2022 - Forecasting Rice Status for a Food Crisis Early Warning System Based on Satellite Imagery and Cellul.pdf}
}

@article{suler2004online,
  title = {The Online Disinhibition Effect},
  author = {Suler, John},
  year = 2004,
  journal = {Cyberpsychology \& behavior},
  volume = {7},
  number = {3},
  pages = {321--326},
  publisher = {Mary Ann Liebert, Inc.}
}

@inproceedings{suonpaaStudentsPerceptionsGenerative2024,
  title = {Students' {{Perceptions Of Generative Ai Usage And Risks In A Finnish Higher Education Institution}}},
  booktitle = {18th {{International Technology}}, {{Education}} and {{Development Conference}}},
  author = {Suonp{\"a}{\"a}, Maija and Heikkil{\"a}, Jutta and Dimkar, Ana},
  year = 2024,
  month = mar,
  pages = {3071--3077},
  address = {Valencia, Spain},
  doi = {10.21125/inted.2024.0825},
  urldate = {2025-11-11},
  abstract = {The latest developments in modern technologies, in particular Generative AI (GenAI) have prompted a significant change in education. This trend of growing GenAI tools is expected to cause significant changes in the use of technological tools in higher education. Consequently, it will influence the skills of the students and their ability to adjust to these new trends.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/5M7M5UDV/SuonpÃ¤Ã¤ et al. - 2024 - STUDENTSâ€™ PERCEPTIONS OF GENERATIVE AI USAGE AND RISKS IN A FINNISH HIGHER EDUCATION INSTITUTION.pdf}
}

@article{sutherlandDigitalPrivacyAfrica2018,
  title = {Digital {{Privacy}} in {{Africa}}: {{Cybersecurity}}, {{Data Protection}} \& {{Surveillance}}},
  shorttitle = {Digital {{Privacy}} in {{Africa}}},
  author = {Sutherland, Ewan},
  year = 2018,
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3201310},
  urldate = {2025-08-17},
  abstract = {The push in Africa for the widespread adoption of telecommunications and Internet is aimed at boosting economic growth and access to digital government services. However, it has significant effects on privacy by enabling surveillance of the networks, by allowing the collection of data about customers, their locations and transactions, which can be linked to other data and analysed for commercial or governmental purposes. Data can also be stolen or destroyed, by criminals, foreign powers and terrorists. While countries have enthusiastically created telecommunications regulatory authorities, they have only rarely created data protection authorities to oversee well established principles for the collection, use and storage of data. Similarly, they have lagged on the introduction of strategies for cybersecurity and the centres needed to collect data on attacks and defences. Surveillance by secret police has grown in sophistication, with facilities for lawful interception, IMSIcatchers and surveillance RATs, none of which is overseen by parliaments or the courts. Consequently, the rights to dignity and privacy are very poorly observed and more often breached.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/PULXN7I6/Sutherland - 2018 - Digital Privacy in Africa Cybersecurity, Data Protection & Surveillance.pdf}
}

@article{szomszorDataCategorizationUnderstanding,
  title = {Data Categorization: Understanding Choices and Outcomes},
  author = {Szomszor, Martin and Adams, Jonathan and Pendlebury, David A and Rogers, Gordon},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/3I3FVKEI/Szomszor et al. - Data categorization understanding choices and outcomes.pdf}
}

@article{thatcher2016data,
  title = {Data Colonialism through Accumulation by Dispossession: {{New}} Metaphors for Daily Data},
  author = {Thatcher, Jim and O'Sullivan, David and Mahmoudi, Dillon},
  year = 2016,
  journal = {Environment and Planning D: Society and Space},
  volume = {34},
  number = {6},
  pages = {990--1006},
  publisher = {SAGE Publications Sage UK: London, England},
  file = {/Users/fritz/Zotero/storage/HTWWLILC/Thatcher et al. - 2016 - Data colonialism through accumulation by dispossession New metaphors for daily data.pdf}
}

@book{turner2010counterculture,
  title = {From Counterculture to Cyberculture: {{Stewart Brand}}, the {{Whole Earth Network}}, and the Rise of Digital Utopianism},
  author = {Turner, Fred},
  year = 2010,
  publisher = {University of Chicago Press}
}

@article{udehRoleGenerativeAI2025,
  title = {The Role of Generative {{AI}} in Personalized Learning for Higher Education},
  author = {Udeh, Chinemelum Goodness},
  year = 2025,
  journal = {World Journal of Advanced Engineering Technology and Sciences},
  volume = {14},
  number = {2},
  pages = {205--207},
  issn = {2582-8266},
  doi = {10.30574/wjaets.2025.14.2.0077},
  urldate = {2025-11-11},
  abstract = {The burgeoning field of Generative Artificial Intelligence has profoundly transformed the landscape of higher education, particularly in the domain of personalized learning. This comprehensive investigation examines the multifaceted role of GenAI tools in higher education, scrutinizing their capacity to amplify student engagement, deliver customized content, and enhance learning outcomes. Furthermore, the research delves into the critical ethical and pedagogical implications associated with the integration of these transformative technologies within the higher education ecosystem. This study adopts a multidimensional approach to analyze GenAI's impact on personalized learning, offering insights for educational stakeholders to navigate challenges and harness its potential in higher education.},
  copyright = {Copyrights to World Journal of Advanced Engineering Technology and Sciences},
  langid = {english}
}

@book{universityofwestminstergbDigitalObjectsDigital2019,
  title = {Digital {{Objects}}, {{Digital Subjects}}: {{Interdisciplinary Perspectives}} on {{Capitalism}}, {{Labour}} and {{Politics}} in the {{Age}} of {{Big Data}}},
  shorttitle = {Digital {{Objects}}, {{Digital Subjects}}},
  editor = {{University of Westminster, GB} and Chandler, David and Fuchs, Christian and {University of Westminster, GB}},
  year = 2019,
  month = jan,
  publisher = {University of Westminster Press},
  doi = {10.16997/book29},
  urldate = {2025-06-26},
  isbn = {978-1-912656-20-2},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/5T9PD3ZE/University of Westminster, GB et al. - 2019 - Digital Objects, Digital Subjects Interdisciplinary Perspectives on Capitalism, Labour and Politics.pdf}
}

@incollection{van2012body,
  title = {The Body as Data in the Age of Information},
  booktitle = {Routledge Handbook of Surveillance Studies},
  author = {{Van der Ploeg}, Irma},
  year = 2012,
  pages = {176--183},
  publisher = {Routledge}
}

@article{van2017digital,
  title = {Digital Divide: {{Impact}} of Access},
  author = {Van Dijk, {\relax JAGM}},
  year = 2017,
  journal = {The international encyclopedia of media effects},
  volume = {1},
  pages = {1--11}
}

@article{vetterFrameworkLocalInterrogation2024,
  title = {Towards a Framework for Local Interrogation of {{AI}} Ethics: {{A}} Case Study on Text Generators, Academic Integrity, and Composing with {{ChatGPT}}},
  shorttitle = {Towards a Framework for Local Interrogation of {{AI}} Ethics},
  author = {Vetter, Matthew A. and Lucia, Brent and Jiang, Jialei and Othman, Mahmoud},
  year = 2024,
  month = mar,
  journal = {Computers and Composition},
  volume = {71},
  pages = {102831},
  issn = {8755-4615},
  doi = {10.1016/j.compcom.2024.102831},
  urldate = {2025-12-08},
  abstract = {Ethical frameworks for text generators (TGs) in education are generally concerned with personalized instruction, a dependency on data, biases in training data, academic integrity, and lack of creativity from students. While broad-level, institutional guidelines provide value in understanding the ethical dimensions of artificial intelligence (AI) for the classroom, there is a need for a more ecological understanding of how AI ethics might be constructed locally, one that takes into account the negotiation of AI between teacher and student. This article investigates how an educational ethical framework for AI use emerges through a qualitative case study of one composition student's interaction with and understanding of using ChatGPT as a type of writing partner. Analysis of interview data and student logs uncover what we term an emergent ``local ethic'' -- a framework that is capable of exploring unique ethical considerations, values, and norms that develop at the most foundational unit of higher education -- the individual classroom. Our framework is meant to provide a heuristic for other writing teacher-scholars as they interrogate issues related to pedagogy, student criticality, agency, reliability, and access within the context of powerful AI systems.},
  keywords = {Academic integrity,academic policy,Artificial intelligence (AI),Composition pedagogy,Ethics,Text generators}
}

@incollection{walford2018if,
  title = {`{{If}} Everything Is Information': Archives and Collecting on the Frontiers of Data-Driven Science},
  booktitle = {Ethnography for a Data-Saturated World},
  author = {Walford, Antonia},
  year = 2018,
  pages = {105--127},
  publisher = {Manchester University Press}
}

@article{walfordDataOvaGene2021,
  title = {Data -- Ova -- Gene -- Data},
  author = {Walford, Antonia},
  year = 2021,
  journal = {Journal of the Royal Anthropological Institute},
  volume = {27},
  number = {S1},
  pages = {127--141},
  issn = {1467-9655},
  doi = {10.1111/1467-9655.13484},
  urldate = {2025-12-04},
  abstract = {In this essay, I observe that data is valuable not only for what it is, but also for what it will become: that is, that data is a form of potential. I explore two aspects of this by drawing two comparisons with other forms of potential: ova and genes. First, building on ethnographic fieldwork with environmental scientists and technicians in the Brazilian Amazon, I compare data processing with ova donation in the United Kingdom in order to explore how data processing might be considered a form of reproductive labour. I then turn to emergent big data infrastructures in the environmental sciences, and compare the environmental sciences with genomics, in order to gesture towards some critical questions that need to be asked of such open data initiatives. I end with a reflection on comparison as a privileged means of drawing out the forms understood to be latent within data.},
  copyright = {\copyright{} 2021 The Authors. Journal of the Royal Anthropological Institute published by John Wiley \& Sons Ltd on behalf of Royal Anthropological Institute},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/WIRJFFV7/Walford - 2021 - Data â€“ ova â€“ gene â€“ data.pdf;/Users/fritz/Zotero/storage/9X6X9ARA/1467-9655.html}
}

@article{wangGenerativeAIHigher2024,
  title = {Generative {{AI}} in Higher Education: {{Seeing ChatGPT}} through Universities' Policies, Resources, and Guidelines},
  shorttitle = {Generative {{AI}} in Higher Education},
  author = {Wang, Hui and Dang, Anh and Wu, Zihao and Mac, Son},
  year = 2024,
  month = dec,
  journal = {Computers and Education: Artificial Intelligence},
  volume = {7},
  pages = {100326},
  issn = {2666-920X},
  doi = {10.1016/j.caeai.2024.100326},
  urldate = {2025-11-11},
  abstract = {The advancements in Generative Artificial Intelligence (GenAI) can provide opportunities for enriching educational experiences, but at the same time raise concerns regarding academic integrity. Many educators have expressed anxiety and hesitation when it comes to integrating GenAI in their teaching practices. Thus, recommendations and guidance from institutions are needed to support instructors in this new and emerging GenAI era. In response to this need, this study explores different U.S. universities' academic policies and guidelines regarding the use of GenAI tools (e.g., ChatGPT) for teaching and learning, and from there, gains understanding of how these universities respond and adapt to the development of GenAI in their academic contexts. Data sources include academic policies, statements, guidelines, and relevant resources provided by the top 100 universities in the U.S. Results show that the majority of these universities adopt an open but cautious approach towards GenAI. Primary concerns lie in ethical usage, accuracy, and data privacy. Most universities actively respond and provide diverse types of resources, such as syllabus templates, workshops, shared articles, and one-on-one consultations; focusing on a range of topics, namely general technical introduction, ethical concerns, pedagogical applications, preventive strategies, data privacy, limitations, and detective tools. The findings provide four practical pedagogical implications for educators when considering GenAI in teaching practices: 1) accepting GenAI presence, 2) aligning GenAI use with learning objectives, 3) evolving curriculum to prevent misuse of GenAI, and 4) adopting multifaceted evaluation strategies. For recommendations toward policy making, the article suggests two possible directions for the use of GenAI tools: 1) establishing discipline-specific policies and guidelines, and 2) managing students' sensitive information in a transparent and careful manner.},
  keywords = {AI in education (AIED),Educational resources,Generative Artificial Intelligence,Higher education,Technology in education},
  file = {/Users/fritz/Zotero/storage/HAA3HHXI/Wang et al. - 2024 - Generative AI in higher education Seeing ChatGPT through universities' policies, resources, and gui.pdf;/Users/fritz/Zotero/storage/6Q5IN82Q/S2666920X24001292.html}
}

@article{wernerfeltEstimatingValueOffsite2025,
  title = {Estimating the {{Value}} of {{Offsite Tracking Data}} to {{Advertisers}}: {{Evidence}} from {{Meta}}},
  shorttitle = {Estimating the {{Value}} of {{Offsite Tracking Data}} to {{Advertisers}}},
  author = {Wernerfelt, Nils and Tuchman, Anna and Shapiro, Bradley T. and Moakler, Robert},
  year = 2025,
  month = mar,
  journal = {Marketing Science},
  volume = {44},
  number = {2},
  pages = {268--286},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2023.0274},
  urldate = {2025-07-16},
  abstract = {Third-party cookies and related ``offsite'' tracking technologies are frequently used to share user data across applications in support of ad delivery. These data are viewed as highly valuable for online advertisers, but their usage faces increasing headwinds. In this paper, we quantify the benefit to advertisers from using such offsite tracking data in their ad delivery. With this goal in mind, we conduct a large-scale, randomized experiment that includes more than 70,000 advertisers on Facebook and Instagram. We first estimate advertising effectiveness at baseline across our broad sample. We then estimate the change in effectiveness of the same campaigns were advertisers to lose the ability to optimize ad delivery with offsite data. In each of these cases, we use recently developed deconvolution techniques to flexibly estimate the underlying distribution of effects. We find a median cost per incremental customer at baseline of \$38.16 that under the median loss in effectiveness would rise to \$49.93, a 31\% increase. Further, we find ads targeted using offsite data generate more long-term customers per dollar than those without, and losing offsite data disproportionately hurts small scale advertisers. Taken together, our results suggest that offsite data bring large benefits to a wide range of advertisers. History: Catherine Tucker served as the senior editor for this article. Conflict of Interest Statement: N. Wernerfelt and R. Moakler were employees of Meta when this research was conducted and the latter owns stock in the company. Meta was able to review this publication for proprietary, trade-secret, or non-aggregated information that could potentially identify any individual(s), but did not have the right to restrict publication based on the results or content of the findings. Supplemental Material: The online appendices and data files are available at https://doi.org/10.1287/mksc.2023.0274.},
  keywords = {advertising,cookies,field experiments,meta analysis,privacy,targeting},
  file = {/Users/fritz/Zotero/storage/A32X8KVN/Wernerfelt et al. - 2025 - Estimating the Value of Offsite Tracking Data to Advertisers Evidence from Meta.pdf}
}

@article{west2019data,
  title = {Data Capitalism: {{Redefining}} the Logics of Surveillance and Privacy},
  author = {West, Sarah Myers},
  year = 2019,
  journal = {Business \& society},
  volume = {58},
  number = {1},
  pages = {20--41},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@article{westerExploringPeoplesPerceptions2024,
  title = {Exploring People's Perceptions of {{LLM-generated}} Advice},
  author = {Wester, Joel and {de Jong}, Sander and Pohl, Henning and {van Berkel}, Niels},
  year = 2024,
  month = aug,
  journal = {Computers in Human Behavior: Artificial Humans},
  volume = {2},
  number = {2},
  pages = {100072},
  issn = {2949-8821},
  doi = {10.1016/j.chbah.2024.100072},
  urldate = {2025-11-12},
  abstract = {When searching and browsing the web, more and more of the information we encounter is generated or mediated through large language models (LLMs). This can be looking for a recipe, getting help on an essay, or looking for relationship advice. Yet, there is limited understanding of how individuals perceive advice provided by these LLMs. In this paper, we explore people's perception of LLM-generated advice, and what role diverse user characteristics (i.e., personality and technology readiness) play in shaping their perception. Further, as LLM-generated advice can be difficult to distinguish from human advice, we assess the perceived creepiness of such advice. To investigate this, we run an exploratory study (N~=~91), where participants rate advice in different styles (generated by GPT-3.5 Turbo). Notably, our findings suggest that individuals who identify as more agreeable tend to like the advice more and find it more useful. Further, individuals with higher technological insecurity are more likely to follow and find the advice more useful, and deem it more likely that a friend could have given the advice. Lastly, we see that advice given in a `skeptical' style was rated most unpredictable, and advice given in a `whimsical' style was rated least malicious---indicating that LLM advice styles influence user perceptions. Our results also provide an overview of people's considerations on likelihood, receptiveness, and what advice they are likely to seek from these digital assistants. Based on our results, we provide design takeaways for LLM-generated advice and outline future research directions to further inform the design of LLM-generated advice for support applications targeting people with diverse expectations and needs.},
  keywords = {Advice,Generative AI,Large language models,LLM,User characteristics}
}

@article{westerveldModellingFoodInsecurity,
  title = {Modelling {{Food Insecurity}} in {{Ethiopia}}},
  author = {Westerveld, Joris},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/GAEU3BBS/Westerveld - Modelling Food Insecurity in Ethiopia.pdf}
}

@article{wissingerPrivacyLiteracyTheory2017,
  title = {Privacy {{Literacy}}: {{From Theory}} to {{Practice}}},
  shorttitle = {Privacy {{Literacy}}},
  author = {Wissinger, Christina},
  year = 2017,
  journal = {Communications in Information Literacy},
  volume = {11},
  number = {2},
  pages = {378--389},
  publisher = {Portland State University Library},
  issn = {1933-5954},
  doi = {10.15760/comminfolit.2017.11.2.9},
  urldate = {2025-07-10},
  abstract = {Libraries and librarians have dealt with patron privacy issues since their inception, often serving as educators and advocates. In today's social media-filled landscape, patron privacy has moved from the safeguarding of traditional library records to the creation, use, and ownership of information maintained in an online world. As the core educators for many aspects of literacy, librarians need to keep pace with the issues their users face daily. This paper centers on privacy literacy as an independent area of instruction for library sessions. It reviews a theoretical framework to support privacy literacy instruction and showcases resources and tools for creating privacy literacy education. Finally, privacy issues in healthcare are used to demonstrate the potential impact of privacy literacy instruction.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/XYL5A2JK/Wissinger - 2017 - Privacy Literacy From Theory to Practice.pdf}
}

@article{wittInternationalApproachesResearch2016,
  title = {International Approaches to Research Data Services in Libraries},
  author = {Witt, Michael and Horstmann, Wolfram},
  year = 2016,
  month = dec,
  journal = {IFLA Journal},
  volume = {42},
  number = {4},
  pages = {251--252},
  publisher = {SAGE Publications},
  issn = {0340-0352, 1745-2651},
  doi = {10.1177/0340035216678726},
  urldate = {2025-07-11},
  abstract = {Data is the new buzzword in academic libraries, as policy increasingly mandates that data must be open and accessible, funders require formal data management plans, and institutions are implementing guidelines around best practice. Given concerns about the current data management practices of researchers, this paper reports on the initial findings from a project being undertaken at Griffith University to apply a conceptual (A-COM-B) framework to understanding researchers' behaviour. The objective of the project is to encourage the use of institutionally endorsed solutions for research data management. Based on interviews conducted by a team of librarians in a small, social science research centre, preliminary results indicate that attitude is the key element which will need to be addressed in designing intervention strategies to modify behaviour. The paper concludes with a discussion of the next stages in the project, which involve further data collection and analysis, the implementation of targeted strategies, and a follow-up activity to assess the extent of modifications to current undesirable practices.},
  copyright = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/4K6ZYRPL/Witt and Horstmann - 2016 - International approaches to research data services in libraries.pdf}
}

@misc{worldhealthorganisationGlobalDigitalHealth,
  title = {Global {{Digital Health Certification Network}}},
  author = {World Health Organisation},
  journal = {www.who.int},
  urldate = {2025-06-26},
  howpublished = {https://www.who.int/initiatives/global-digital-health-certification-network},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/4FPE4EZE/global-digital-health-certification-network.html}
}

@misc{xTermsServiceConsumer,
  title = {Terms of {{Service}} - {{Consumer}} \textbar{} {{xAI}}},
  author = {X},
  urldate = {2025-11-17},
  abstract = {The xAI terms of service.},
  howpublished = {https://x.ai/legal/terms-of-service},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/KSHRSI5X/terms-of-service.html}
}

@misc{yanesPrivacyAnonymity2014,
  title = {Privacy and {{Anonymity}}},
  author = {Yanes, Adrian},
  year = 2014,
  month = jul,
  number = {arXiv:1407.0423},
  eprint = {1407.0423},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1407.0423},
  urldate = {2025-11-13},
  abstract = {Since the beginning of the digital area, privacy and anonymity have been impacted drastically (both, positively and negatively), by the different technologies developed for communications purposes. The broad possibilities that the Internet offers since its conception, makes it a mandatory target for those entities that are aiming to know and control the different channels of communication and the information that flows through. In this paper, we address the current threats against privacy and anonymity on the Internet, together with the methods applied against them. In addition, we enumerate the publicly known entities behind those threats and their motivations. Finally, we analyze the state of the art concerning the protection of the privacy and anonymity on the Internet; introducing future lines of research.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Cryptography and Security},
  file = {/Users/fritz/Zotero/storage/HDBV4S4R/Yanes - 2014 - Privacy and Anonymity.pdf;/Users/fritz/Zotero/storage/XKCU4MBG/1407.html}
}

@article{yorkNothingNewSun2010,
  title = {Nothing {{New Under}} the {{Sun}}? {{The Old False Promise}} of {{New Technology}}},
  shorttitle = {Nothing {{New Under}} the {{Sun}}?},
  author = {York, Richard and Clark, Brett},
  year = 2010,
  journal = {Review (Fernand Braudel Center)},
  volume = {33},
  number = {2/3},
  eprint = {23346882},
  eprinttype = {jstor},
  pages = {203--224},
  publisher = {Research Foundation of SUNY},
  issn = {0147-9032},
  urldate = {2025-12-01},
  abstract = {To understand contemporary environmental problems---including food and energy crises---it is necessary to employ a broad historical view. While existing problems have distinctive features, the underlying causes, which stem from the structure of the world-system, are not novel to this or the previous century. We assert that it is useful to distinguish between three tiers of time in order to recognize the various forces, systems, and processes that operate within the world. The global capitalist system, which operates on the second tier, acts as a form of "social gravity" that is pervasive and constant. Too often, it goes unnoticed or is simply assumed to be immutable. As a result, mainstream thinkers focus on the particularities of environmental problems and offer "solutions" (such as energy efficiency, new sources of energy, and other technological fixes) that fail to address or solve the original problems. Often attempts to solve one problem generate new problems, given specific shifts in the capitalist system and its technical regimes. To overcome modern environmental crises will require addressing the root causes of them: the contradictions inherent in the capitalist system.},
  file = {/Users/fritz/Zotero/storage/JRHSSVDU/York and Clark - 2010 - Nothing New Under the Sun The Old False Promise of New Technology.pdf}
}

@article{zhangDesigningGenAITools2025,
  title = {Designing {{GenAI Tools}} for {{Personalized Learning Implementation}}: {{Theoretical Analysis}} and {{Prototype}} of a {{Multi-Agent System}}},
  shorttitle = {Designing {{GenAI Tools}} for {{Personalized Learning Implementation}}},
  author = {Zhang, Ling and Yao, Zijun and Hadizadeh Moghaddam, Arya},
  year = 2025,
  month = may,
  journal = {Journal of Teacher Education},
  volume = {76},
  number = {3},
  pages = {280--293},
  publisher = {SAGE Publications Inc},
  issn = {0022-4871},
  doi = {10.1177/00224871251325109},
  urldate = {2025-11-11},
  abstract = {Educator preparation, personalized learning (PL) implementation, and applications of Generative AI converge as three interrelated systems that, when carefully designed, can help achieve the long-sought goal of providing inclusive education for all learners. However, realizing this potential comes with challenges resulting from theoretical complexities and technological constraints. This article provides a theoretical analysis of the complex interconnectedness among these systems guided by the Cultural-Historical Activity Theory (CHAT). Building on the analysis, we introduce CoPL, a multi-agent system consisting of multiple agents with distinct functions that facilitate the complex PL design and engage pre-service teachers (PSTs) in dynamic conversations while prompting them to reflect on the inclusivity of agent-generated instructional suggestions. We describe the affordances and limitations of the system as a professional learning tool for PSTs to develop competencies for designing inclusive PL to meet diverse learning needs of all learners. Finally, we discuss future research on refining CoPL and its practical applications.},
  file = {/Users/fritz/Zotero/storage/GTVKHBUC/Zhang et al. - 2025 - Designing GenAI Tools for Personalized Learning Implementation Theoretical Analysis and Prototype o.pdf}
}

@article{zhangPublicPrivatePowerplaysGenerative2025,
  title = {Public-{{Private Powerplays}} in {{Generative AI Era}}: {{Balancing Big Tech Regulation Amidst Global AI Race}}},
  shorttitle = {Public-{{Private Powerplays}} in {{Generative AI Era}}},
  author = {Zhang, Hongzhou and Khanal, Shaleen and Taeihagh, Araz},
  year = 2025,
  month = jun,
  journal = {Digital Government: Research and Practice},
  volume = {6},
  number = {2},
  pages = {1--11},
  issn = {2691-199X, 2639-0175},
  doi = {10.1145/3664824},
  urldate = {2025-12-08},
  abstract = {The past decades have seen unbridled growth in the economic, social, and political influence of large technology corporations (Big Tech) in the United States. The rising popularity of Generative Artificial Intelligence (GenAI) is likely to further consolidate the power of these companies. The rapid expansion of Big Tech in various domains has triggered a wide range of economic, ethical, and political concerns. However, the US Government is also engaged in a growing technology and AI race with China. As a result, the US government now faces the challenges of balancing the external goal of winning the AI race through close collaboration with the Big Tech and the internal objective of regulating the Big Tech. In this article, we argue that this intersection of interest has been the primary motivator of US policy on the governance of Big Tech. By exploring the evolution of AI policy in the US, we highlight the role internal and external pressures have played in its approach to AI governance.},
  langid = {english}
}

@article{zhangSecretUseLarge2025,
  title = {Secret {{Use}} of {{Large Language Model}} ({{LLM}})},
  author = {Zhang, Zhiping and Shen, Chenxinran and Yao, Bingsheng and Wang, Dakuo and Li, Tianshi},
  year = 2025,
  month = may,
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {9},
  number = {2},
  pages = {1--26},
  issn = {2573-0142},
  doi = {10.1145/3711061},
  urldate = {2025-11-12},
  abstract = {The advancements of Large Language Models (LLMs) have decentralized the responsibility for the transparency of AI usage. Specifically, LLM users are now encouraged or required to disclose the use of LLM-generated content for varied types of real-world tasks. However, an emerging phenomenon, users'               secret use of LLM               , raises challenges in ensuring end users adhere to the transparency requirement. Our study used mixed-methods with an exploratory survey (125 real-world secret use cases reported) and a controlled experiment among 300 users to investigate the contexts and causes behind the secret use of LLMs. We found that such secretive behavior is often triggered by certain tasks, transcending demographic and personality differences among users. Task types were found to affect users' intentions to use secretive behavior, primarily through influencing perceived external judgment regarding LLM usage. Our results yield important insights for future work on designing interventions to encourage more transparent disclosure of the use of LLMs or other AI technologies.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/C4RB6DJ7/Zhang et al. - 2025 - Secret Use of Large Language Model (LLM).pdf}
}

@misc{zhangTakingAdviceChatGPT2023,
  title = {Taking {{Advice}} from {{ChatGPT}}},
  author = {Zhang, Peter},
  year = 2023,
  month = jun,
  number = {arXiv:2305.11888},
  eprint = {2305.11888},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.11888},
  urldate = {2025-11-17},
  abstract = {A growing literature studies how humans incorporate advice from algorithms. This study examines an algorithm with millions of daily users: ChatGPT. In a preregistered study, 118 student participants answer 2,828 multiple-choice questions across 25 academic subjects. Participants receive advice from a GPT model and can update their initial responses. The advisor's identity ("AI chatbot" versus a human "expert"), presence of a written justification, and advice correctness do not significantly affect weight on advice. Instead, participants weigh advice more heavily if they (1) are unfamiliar with the topic, (2) used ChatGPT in the past, or (3) received more accurate advice previously. The last two effects -- algorithm familiarity and experience -- are stronger with an AI chatbot as the advisor. Participants that receive written justifications are able to discern correct advice and update accordingly. Student participants are miscalibrated in their judgements of ChatGPT advice accuracy; one reason is that they significantly misjudge the accuracy of ChatGPT on 11/25 topics. Participants under-weigh advice by over 50\% and can score better by trusting ChatGPT more.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Human-Computer Interaction},
  file = {/Users/fritz/Zotero/storage/YTZRG93D/Zhang - 2023 - Taking Advice from ChatGPT.pdf;/Users/fritz/Zotero/storage/A2VCQAF8/2305.html}
}

@article{zimmerAddressingConceptualGaps2018,
  title = {Addressing {{Conceptual Gaps}} in {{Big Data Research Ethics}}: {{An Application}} of {{Contextual Integrity}}},
  shorttitle = {Addressing {{Conceptual Gaps}} in {{Big Data Research Ethics}}},
  author = {Zimmer, Michael},
  year = 2018,
  month = apr,
  journal = {Social Media + Society},
  volume = {4},
  number = {2},
  pages = {2056305118768300},
  issn = {2056-3051, 2056-3051},
  doi = {10.1177/2056305118768300},
  urldate = {2025-09-08},
  abstract = {The rise of big data has provided new avenues for researchers to explore, observe, and measure human opinions, activities, and interactions. While scholars, professional societies, and ethical review boards have long-established research ethics frameworks to ensure the rights and welfare of the research subjects are protected, the rapid rise of big data-based research generates new challenges to long-held ethical assumptions and guidelines. This article discloses emerging conceptual gaps in relation to how researchers and ethical review boards think about privacy, anonymity, consent, and harm in the context of big data research. It closes by invoking Nissenbaum's theory of ``privacy as contextual integrity'' as a useful heuristic to guide ethical decision-making in big data research projects.},
  langid = {english},
  file = {/Users/fritz/Zotero/storage/PBCU3UIG/Zimmer - 2018 - Addressing Conceptual Gaps in Big Data Research Ethics An Application of Contextual Integrity.pdf}
}
