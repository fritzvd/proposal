{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "Frederik J. Van Deventer\n",
    "\n",
    "-   “While privacy is recognised as a right by some African states, this is only rarely translated into justiciable rights and is almost never a constraint on the behaviour of governments and their secret police. This can be seen in the areas of data protection, surveillance and cybersecurity.” - Sutherland ([2018](#ref-sutherlandDigitalPrivacyAfrica2018))\n",
    "\n",
    "### Hypotheses to work with or maxims and possible case studies\n",
    "\n",
    "-   ## Digital divide discourse is not advancing the closing of the divide\n",
    "\n",
    "-   Closing the digital divide is not alleviating poverty\n",
    "\n",
    "-   Big tech’s push for the next billion users is unethically preying on the new and inexperienced users\n",
    "\n",
    "-   Improving privacy literacy will improve a users engagement with platforms\n",
    "\n",
    "-   Privacy and security are low priority\n",
    "\n",
    "-   The global south is likely to fall prey to exposurism or pilotism, the idea that companies use interventions and experiments to test a theory and increase their PR by showing that they are involved in “community efforts”\n",
    "    -   Why is it likely to fall prey? Or are they able to rise above.\n",
    "    -   shown by humanitarianism in Technocolonialism\n",
    "\n",
    "-   AI hype and positivity nudges people to put their trust in platforms, but support will lack in the future\n",
    "    -   who will benefit ([Houston and Erdelez 2002](#ref-houstonDigitalDivideWho2002))\n",
    "\n",
    "-   Technosolutionism puts too much trust in AI and will ask from new users to engage with these tools. These tools are not free and cost a lot to maintain\n",
    "\n",
    "-   Offline-first education tools.\n",
    "\n",
    "-   Data protection regulation is not being enforced and falls short.\n",
    "\n",
    "-   Machine learning’s biases are implicit but not without consequence\n",
    "    -   example DRC refugees: Madianou ([2024](#ref-madianou2024technocolonialism)) p.140. When the decision is made by the machine without any clear explanation about the criteria used, then it is harder to challenge \\[.. exclusion\\].\n",
    "    -   Example Australia robodebt.\n",
    "\n",
    "## gesprek Eelco\n",
    "\n",
    "\\_ Bart Jacobs - Digital security. \\_ Jaap Henk Hoepman - Fundamentalist privacy, data minimalisation. Digital security \\_ - Misgaan met data \\_\n",
    "\n",
    "Theoretical Framework\n",
    "\n",
    "-   Privacy\n",
    "-   Helen Nissenbaum Contextual Integrity (up and own the data food chain)\n",
    "-   Mireille Hildebrandt ()\n",
    "-   Timothy Garton Ash: Free Speech\n",
    "\n",
    "Big Tech en hun algoritmen vs. perceptie privacy in Botswana en wat aanvaarden mensen.\n",
    "\n",
    "Association Computer and Machinery - Chapter India, China - Chapter Africa - Technology policy council\n",
    "\n",
    "Houston, Roland D., and Sanda Erdelez. 2002. “The Digital Divide: Who Really Benefits from the Proposed Solutions for Closing the Gap.” *Proceedings of the American Society for Information Science and Technology* 39 (1): 99–106. <https://doi.org/10.1002/meet.1450390111>.\n",
    "\n",
    "Madianou, Mirca. 2024. *Technocolonialism: When Technology for Good Is Harmful*. John Wiley & Sons.\n",
    "\n",
    "Sutherland, Ewan. 2018. “Digital Privacy in Africa: Cybersecurity, Data Protection & Surveillance.” *SSRN Electronic Journal*. <https://doi.org/10.2139/ssrn.3201310>."
   ],
   "id": "7fb1aaac-d6ef-46b0-9c2e-99bceea6decd"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
