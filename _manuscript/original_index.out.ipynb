{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‘Dear LLM..’: Anonimity and privacy in an age of magical machines\n",
    "\n",
    "Frederik J van Deventer (HAN University of Applied Sciences)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "“Hey ChatGPT, what’s the weather like? Do you think I should take the car?”. Taking advice from tools such as ChatGPT or other large language model (LLM) based generative artifical intelligence (genAI) systems has quickly become commonplace since its launch for the masses at the end of 2022 ([P. Zhang 2023](#ref-zhangTakingAdviceChatGPT2023)). Ranging from advice on cardiovascular health ([Lautrup et al. 2023](#ref-lautrupHearttoheartChatGPTImpact2023)), visualisation design advice ([Kim et al. 2025](#ref-kimHowGoodChatGPT2025)), relationship advice ([Hou, Leach, and Huang 2024](#ref-houChatGPTGivingRelationship2024)). It can even perceived as “better” than real humans ([Howe et al. 2023](#ref-howeChatGPTsAdvicePerceived2023); [Oehler and Horn 2024](#ref-oehlerDoesChatGPTProvide2024)). Furthermore, “secret use” of an LLM for real-world tasks makes it difficult to determine whether a real human doing a task is unaided or not ([Z. Zhang et al. 2025](#ref-zhangSecretUseLarge2025)). The models however are flawed and can produce inaccurate, untrue or malevolent results ([Cheung 2024](#ref-cheungRealityCheckBenefits2024); [Liu et al. 2024](#ref-liuRobustnessTimeUnderstanding2024)).\n",
    "\n",
    "To properly make use of an LLM’s based chat such as ChatGPT, users give prompts that provide context for offering a reply. This context users give can be greatly personal if we are to ask for advice such as highlighted in the section above where it concerns medical and relationship advice. It can be in the form of the question itself, but also in the form of documents uploaded to the service ([Naik, Naik, and Naik 2024](#ref-naikChatGPTAllYou2024)).\n",
    "\n",
    "Jailbreak prompts are a way to subvert the main goals and to misuse LLM’s ([Perez and Ribeiro 2022](#ref-perezIgnorePreviousPrompt2022)). Which could lead to the extraction of personally identifiable information ([Li et al. 2023](#ref-liMultistepJailbreakingPrivacy2023)). In older models (GPT-2) training data could be even be extracted after an attack ([Carlini et al. 2021](#ref-carliniExtractingTrainingData2021)). The terms of service for ChatGPT allow for OpenAI (the company behind the popular chat based LLM) to make use of content provided by users to improve services, and even to train models ([OpenAi n.d.](#ref-openaiPrivacyPolicy)). The same holds true for Anthropic (Claude) ([Anthropic n.d.](#ref-anthropicHowYouUse)), Google (Gemini) ([Google n.d.](#ref-googlePrivacyPolicyPrivacy)) and X (Grok) ([X n.d.](#ref-xTermsServiceConsumer)).\n",
    "\n",
    "The extraction and use of personal data by large corporations has been well documented \\[\\]. For consumers there is little to no protection or privacy for unless government regulation explicitly makes it so, like the GDPR program ([Arora 2019](#ref-arora2019general)). However people largely underestimate the small bits of information we give to big tech and how the sum of that can still offer a persona or Gestalt ([Puaschunder 2018](#ref-puaschunder2018dignity))\n",
    "\n",
    "## Conceptual framework\n",
    "\n",
    "In the field of privacy the concept of Contextual Integrity by Nissenbaum ([2004](#ref-nissenbaum2004privacy)) is widely regarded to be able to hold multiple aspects of privacy and to take into account the context in which information flows ([Barth et al. 2006](#ref-barthPrivacyContextualIntegrity2006))."
   ],
   "id": "ecc48229-e43b-43f8-a07d-38ec61f6eec3"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<!-- Not all contexts are\n",
    "\n",
    "Improving workflows and\n",
    "\n",
    "Which raises the question. What is permissable? -->"
   ],
   "id": "e24032db-e319-4971-bb4c-638b111e6218"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<!-- The fact that this data is also used for the creation of economic value and has lead to something more than just a phenomenon of capitalism; it's a manifestation of colonialism [@couldry2019data]. -->"
   ],
   "id": "071a86cf-b520-416d-8f6b-ae4cde790286"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<!-- With new developments in artificial intelligence (AI) and more specifically generative AI (genAI) this becomes more prevalent as data and AI \"entrench power assymetries and engender new forms of structural violence and new inequities between the Global South and North\" [@madianou2024technocolonialism].\n",
    "With the advent of large language models (LLMs) that are available to a wide audience with consumer-friendly applications such as ChatGPT, Claude, Google AI and so forth, this becomes relevant for a much wider audience. -->"
   ],
   "id": "6059e231-58d7-4bb3-98b2-ba542af88157"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<!-- \n",
    "There is little to no protection or privacy for private consumers unless government regulation explicitly makes it so, like the GDPR program [@arora2019general]. Much of Global South legislation is lagging behind or has met with challenges in enforcing the laws set in place [@prinslooDataPrivacyAfrican2022].  -->"
   ],
   "id": "77dfc865-2bfd-4353-9024-c1739113dac9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "Anthropic. n.d. “How Do You Use Personal Data in Model Training? Anthropic Privacy Center.” https://privacy.claude.com/en/articles/10023555-how-do-you-use-personal-data-in-model-training. Accessed November 17, 2025.\n",
    "\n",
    "Arora, Payal. 2019. “General Data Protection Regulation—A Global Standard? Privacy Futures, Digital Activism, and Surveillance Cultures in the Global South.” *Surveillance & Society* 17 (5): 717–25.\n",
    "\n",
    "Barth, A., A. Datta, J. C. Mitchell, and H. Nissenbaum. 2006. “Privacy and Contextual Integrity: Framework and Applications.” In *2006 IEEE Symposium on Security and Privacy (S&P’06)*, 15 pp.–198. Berkeley/Oakland, CA: IEEE. <https://doi.org/10.1109/SP.2006.32>.\n",
    "\n",
    "Carlini, Nicholas, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, et al. 2021. “Extracting Training Data from Large Language Models.” arXiv. <https://doi.org/10.48550/arXiv.2012.07805>.\n",
    "\n",
    "Cheung, Ming. 2024. “A Reality Check of the Benefits of LLM in Business.” arXiv. <https://doi.org/10.48550/arXiv.2406.10249>.\n",
    "\n",
    "Google. n.d. “Privacy Policy – Privacy & Terms – Google.” https://policies.google.com/privacy. Accessed November 17, 2025.\n",
    "\n",
    "Hou, Haonan, Kevin Leach, and Yu Huang. 2024. “ChatGPT Giving Relationship Advice – How Reliable Is It?” *Proceedings of the International AAAI Conference on Web and Social Media* 18 (May): 610–23. <https://doi.org/10.1609/icwsm.v18i1.31338>.\n",
    "\n",
    "Howe, Piers Douglas Lionel, Nicolas Fay, Morgan Saletta, and Eduard Hovy. 2023. “ChatGPT’s Advice Is Perceived as Better Than That of Professional Advice Columnists.” *Frontiers in Psychology* 14 (November): 1281255. <https://doi.org/10.3389/fpsyg.2023.1281255>.\n",
    "\n",
    "Kim, Nam Wook, Yongsu Ahn, Grace Myers, and Benjamin Bach. 2025. “How Good Is ChatGPT in Giving Advice on Your Visualization Design?” *ACM Transactions on Computer-Human Interaction* 32 (5): 1–33. <https://doi.org/10.1145/3745768>.\n",
    "\n",
    "Lautrup, Anton Danholt, Tobias Hyrup, Anna Schneider-Kamp, Marie Dahl, Jes Sanddal Lindholt, and Peter Schneider-Kamp. 2023. “Heart-to-Heart with ChatGPT: The Impact of Patients Consulting AI for Cardiovascular Health Advice.” *Open Heart* 10 (2): e002455. <https://doi.org/10.1136/openhrt-2023-002455>.\n",
    "\n",
    "Li, Haoran, Dadi Guo, Wei Fan, Mingshi Xu, Jie Huang, Fanpu Meng, and Yangqiu Song. 2023. “Multi-Step Jailbreaking Privacy Attacks on ChatGPT.” arXiv. <https://doi.org/10.48550/arXiv.2304.05197>.\n",
    "\n",
    "Liu, Yugeng, Tianshuo Cong, Zhengyu Zhao, Michael Backes, Yun Shen, and Yang Zhang. 2024. “Robustness Over Time: Understanding Adversarial Examples’ Effectiveness on Longitudinal Versions of Large Language Models.” arXiv. <https://doi.org/10.48550/arXiv.2308.07847>.\n",
    "\n",
    "Naik, Ishita, Dishita Naik, and Nitin Naik. 2024. “ChatGPT Is All You Need: Untangling Its Underlying AI Models, Architecture, Training Procedure, Capabilities, Limitations And Applications.” Preprints. <https://doi.org/10.36227/techrxiv.173273427.76836200/v1>.\n",
    "\n",
    "Nissenbaum, Helen. 2004. “Privacy as Contextual Integrity” 79: 119.\n",
    "\n",
    "Oehler, Andreas, and Matthias Horn. 2024. “Does ChatGPT Provide Better Advice Than Robo-Advisors?” *Finance Research Letters* 60 (February): 104898. <https://doi.org/10.1016/j.frl.2023.104898>.\n",
    "\n",
    "OpenAi. n.d. “Privacy Policy.” https://openai.com/policies/row-privacy-policy/. Accessed November 17, 2025.\n",
    "\n",
    "Perez, Fábio, and Ian Ribeiro. 2022. “Ignore Previous Prompt: Attack Techniques For Language Models.” arXiv. <https://doi.org/10.48550/arXiv.2211.09527>.\n",
    "\n",
    "Puaschunder, Julia M. 2018. “Dignity and Utility of Privacy and Information Sharing in the Digital Big Data Age.” *International Journal of Commerce and Management Research* 5 (4): 62–70.\n",
    "\n",
    "X. n.d. “Terms of Service - Consumer <span class=\"nocase\">xAI</span>.” https://x.ai/legal/terms-of-service. Accessed November 17, 2025.\n",
    "\n",
    "Zhang, Peter. 2023. “Taking Advice from ChatGPT.” arXiv. <https://doi.org/10.48550/arXiv.2305.11888>.\n",
    "\n",
    "Zhang, Zhiping, Chenxinran Shen, Bingsheng Yao, Dakuo Wang, and Tianshi Li. 2025. “Secret Use of Large Language Model (LLM).” *Proceedings of the ACM on Human-Computer Interaction* 9 (2): 1–26. <https://doi.org/10.1145/3711061>."
   ],
   "id": "36c796df-a810-4e27-9bc1-7ff92548d0ce"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
