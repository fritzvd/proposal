{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‘Dear LLM..’: Anonimity in an age of magical machines\n",
    "\n",
    "Frederik J van Deventer (HAN University of Applied Sciences)\n",
    "\n",
    "wonderful, monderful\n",
    "\n",
    "## Introduction\n",
    "\n",
    "“Hey ChatGPT, what’s the weather like, should I take the bike?”. A simple “prompt” like this already presumes sharing personal details such like location. Taking advice from tools such as ChatGPT or other large language model (LLM) based generative artifical intelligence (genAI) systems has quickly become commonplace since its launch for the masses at the end of 2022 \\[[23](#ref-zhangTakingAdviceChatGPT2023)\\]. Ranging from advice on cardiovascular health \\[[11](#ref-lautrupHearttoheartChatGPTImpact2023)\\], visualisation design advice \\[[10](#ref-kimHowGoodChatGPT2025)\\], relationship advice \\[[8](#ref-houChatGPTGivingRelationship2024)\\]. It can even perceived as “better” than real humans \\[[9](#ref-howeChatGPTsAdvicePerceived2023), [17](#ref-oehlerDoesChatGPTProvide2024)\\]. Furthermore, “secret use” of an LLM for real-world tasks makes it difficult to determine whether a real human doing a task is unaided or not \\[[24](#ref-zhangSecretUseLarge2025)\\]. The models however are flawed and can produce inaccurate, untrue or malevolent results \\[[6](#ref-cheungRealityCheckBenefits2024), [13](#ref-liuRobustnessTimeUnderstanding2024)\\].\n",
    "\n",
    "To properly make use of an LLM’s based chat such as ChatGPT, users give prompts that provide context for offering a reply. This context users give can be greatly personal if we are to ask for advice such as highlighted in the section above where it concerns medical and relationship advice. It can be in the form of the question itself, but also in the form of documents uploaded to the service \\[[15](#ref-naikChatGPTAllYou2024)\\].\n",
    "\n",
    "Jailbreak prompts are a way to subvert the main goals and to misuse LLM’s \\[[19](#ref-perezIgnorePreviousPrompt2022)\\]. Which could lead to the extraction of personally identifiable information \\[[12](#ref-liMultistepJailbreakingPrivacy2023)\\]. In older models (GPT-2) training data could be even be extracted after an attack \\[[5](#ref-carliniExtractingTrainingData2021)\\]. The terms of service for ChatGPT allow for OpenAI (the company behind the popular chat based LLM) to make use of content provided by users to improve services, and even to train models \\[[18](#ref-openaiPrivacyPolicy)\\]. The same holds true for Anthropic (Claude) \\[[1](#ref-anthropicHowYouUse)\\], Google (Gemini) \\[[7](#ref-googlePrivacyPolicyPrivacy)\\] and X (Grok) \\[[22](#ref-xTermsServiceConsumer)\\], even in areas with stricter legal restrictions such as the European GDPR.\n",
    "\n",
    "The extraction and use of personal data for turning a profit by large corporations has been well documented and has ushered us into an age of new forms of capitalism \\[[4](#ref-birchDataAssetMeasurement2021), [14](#ref-marcianoBigDataBig2020), [21](#ref-sadowskiWhenDataCapital2019)\\]. For consumers there is little to no protection or privacy for unless government regulation explicitly makes it so, like the GDPR program \\[[2](#ref-arora2019general)\\]. However people largely underestimate the small bits of information we give to big tech and how the sum of that can still offer a persona or Gestalt \\[[20](#ref-puaschunder2018dignity)\\].\n",
    "\n",
    "What then can users trust? What level of anonynimity can they enjoy while using the internet and more specifically LLM’s?\n",
    "\n",
    "## Conceptual framework\n",
    "\n",
    "In the field of privacy the concept of Contextual Integrity by \\[[16](#ref-nissenbaum2004privacy)\\] is widely regarded to be able to hold multiple aspects of privacy and to take into account the context in which information flows \\[[3](#ref-barthPrivacyContextualIntegrity2006)\\]."
   ],
   "id": "c32bcdbd-4438-4523-b9e0-7a6cc447bb8c"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<!-- Not all contexts are\n",
    "\n",
    "Improving workflows and\n",
    "\n",
    "Which raises the question. What is permissable? -->"
   ],
   "id": "50258c17-3dbc-49a8-94d0-f42f1995494c"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<!-- The fact that this data is also used for the creation of economic value and has lead to something more than just a phenomenon of capitalism; it's a manifestation of colonialism [@couldry2019data]. -->"
   ],
   "id": "6e0985b3-2b83-45d2-a6bb-754b22de4477"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<!-- With new developments in artificial intelligence (AI) and more specifically generative AI (genAI) this becomes more prevalent as data and AI \"entrench power assymetries and engender new forms of structural violence and new inequities between the Global South and North\" [@madianou2024technocolonialism].\n",
    "With the advent of large language models (LLMs) that are available to a wide audience with consumer-friendly applications such as ChatGPT, Claude, Google AI and so forth, this becomes relevant for a much wider audience. -->"
   ],
   "id": "0be812f9-11e3-4bae-bf98-bfa8663f90bf"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<!-- \n",
    "There is little to no protection or privacy for private consumers unless government regulation explicitly makes it so, like the GDPR program [@arora2019general]. Much of Global South legislation is lagging behind or has met with challenges in enforcing the laws set in place [@prinslooDataPrivacyAfrican2022].  -->"
   ],
   "id": "d938d7b3-aa39-4ec9-b287-733928f64ef6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "<span class=\"csl-left-margin\">1. </span><span class=\"csl-right-inline\">Anthropic: How Do You Use Personal Data in Model Training? Anthropic Privacy Center.</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">2. </span><span class=\"csl-right-inline\">Arora, P.: General data protection regulation—A global standard? Privacy futures, digital activism, and surveillance cultures in the Global South. Surveillance & Society. 17, 5, 717–725 (2019).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">3. </span><span class=\"csl-right-inline\">Barth, A. et al.: Privacy and contextual integrity: Framework and applications. In: 2006 IEEE Symposium on Security and Privacy (S&P’06). pp. 15 pp.–198 IEEE, Berkeley/Oakland, CA (2006). https://doi.org/[10.1109/SP.2006.32](https://doi.org/10.1109/SP.2006.32).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">4. </span><span class=\"csl-right-inline\">Birch, K. et al.: Data as asset? The measurement, governance, and valuation of digital personal data by Big Tech. Big Data & Society. 8, 1, 20539517211017308 (2021). https://doi.org/[10.1177/20539517211017308](https://doi.org/10.1177/20539517211017308).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">5. </span><span class=\"csl-right-inline\">Carlini, N. et al.: Extracting Training Data from Large Language Models, <https://arxiv.org/abs/2012.07805>, (2021). https://doi.org/[10.48550/arXiv.2012.07805](https://doi.org/10.48550/arXiv.2012.07805).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">6. </span><span class=\"csl-right-inline\">Cheung, M.: A Reality check of the benefits of LLM in business, <https://arxiv.org/abs/2406.10249>, (2024). https://doi.org/[10.48550/arXiv.2406.10249](https://doi.org/10.48550/arXiv.2406.10249).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">7. </span><span class=\"csl-right-inline\">Google: Privacy Policy – Privacy & Terms – Google.</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">8. </span><span class=\"csl-right-inline\">Hou, H. et al.: ChatGPT Giving Relationship Advice – How Reliable Is It? Proceedings of the International AAAI Conference on Web and Social Media. 18, 610–623 (2024). https://doi.org/[10.1609/icwsm.v18i1.31338](https://doi.org/10.1609/icwsm.v18i1.31338).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">9. </span><span class=\"csl-right-inline\">Howe, P.D.L. et al.: ChatGPT’s advice is perceived as better than that of professional advice columnists. Frontiers in Psychology. 14, 1281255 (2023). https://doi.org/[10.3389/fpsyg.2023.1281255](https://doi.org/10.3389/fpsyg.2023.1281255).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">10. </span><span class=\"csl-right-inline\">Kim, N.W. et al.: How Good Is ChatGPT in Giving Advice on Your Visualization Design? ACM Transactions on Computer-Human Interaction. 32, 5, 1–33 (2025). https://doi.org/[10.1145/3745768](https://doi.org/10.1145/3745768).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">11. </span><span class=\"csl-right-inline\">Lautrup, A.D. et al.: Heart-to-heart with ChatGPT: The impact of patients consulting AI for cardiovascular health advice. Open Heart. 10, 2, e002455 (2023). https://doi.org/[10.1136/openhrt-2023-002455](https://doi.org/10.1136/openhrt-2023-002455).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">12. </span><span class=\"csl-right-inline\">Li, H. et al.: Multi-step Jailbreaking Privacy Attacks on ChatGPT, <https://arxiv.org/abs/2304.05197>, (2023). https://doi.org/[10.48550/arXiv.2304.05197](https://doi.org/10.48550/arXiv.2304.05197).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">13. </span><span class=\"csl-right-inline\">Liu, Y. et al.: Robustness Over Time: Understanding Adversarial Examples’ Effectiveness on Longitudinal Versions of Large Language Models, <https://arxiv.org/abs/2308.07847>, (2024). https://doi.org/[10.48550/arXiv.2308.07847](https://doi.org/10.48550/arXiv.2308.07847).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">14. </span><span class=\"csl-right-inline\">Marciano, A. et al.: Big data and big techs: Understanding the value of information in platform capitalism. European Journal of Law and Economics. 50, 3, 345–358 (2020). https://doi.org/[10.1007/s10657-020-09675-1](https://doi.org/10.1007/s10657-020-09675-1).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">15. </span><span class=\"csl-right-inline\">Naik, I. et al.: ChatGPT Is All You Need: Untangling Its Underlying AI Models, Architecture, Training Procedure, Capabilities, Limitations And Applications, (2024). https://doi.org/[10.36227/techrxiv.173273427.76836200/v1](https://doi.org/10.36227/techrxiv.173273427.76836200/v1).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">16. </span><span class=\"csl-right-inline\">Nissenbaum, H.: Privacy as contextual integrity. 79, 119 (2004).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">17. </span><span class=\"csl-right-inline\">Oehler, A., Horn, M.: Does ChatGPT provide better advice than robo-advisors? Finance Research Letters. 60, 104898 (2024). https://doi.org/[10.1016/j.frl.2023.104898](https://doi.org/10.1016/j.frl.2023.104898).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">18. </span><span class=\"csl-right-inline\">OpenAi: Privacy policy.</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">19. </span><span class=\"csl-right-inline\">Perez, F., Ribeiro, I.: Ignore Previous Prompt: Attack Techniques For Language Models, <https://arxiv.org/abs/2211.09527>, (2022). https://doi.org/[10.48550/arXiv.2211.09527](https://doi.org/10.48550/arXiv.2211.09527).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">20. </span><span class=\"csl-right-inline\">Puaschunder, J.M.: Dignity and utility of privacy and information sharing in the digital big data age. International Journal of Commerce and Management Research. 5, 4, 62–70 (2018).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">21. </span><span class=\"csl-right-inline\">Sadowski, J.: When data is capital: Datafication, accumulation, and extraction. Big Data & Society. 6, 1, 2053951718820549 (2019). https://doi.org/[10.1177/2053951718820549](https://doi.org/10.1177/2053951718820549).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">22. </span><span class=\"csl-right-inline\">X: Terms of Service - Consumer <span class=\"nocase\">xAI</span>.</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">23. </span><span class=\"csl-right-inline\">Zhang, P.: Taking Advice from ChatGPT, <https://arxiv.org/abs/2305.11888>, (2023). https://doi.org/[10.48550/arXiv.2305.11888](https://doi.org/10.48550/arXiv.2305.11888).</span>\n",
    "\n",
    "<span class=\"csl-left-margin\">24. </span><span class=\"csl-right-inline\">Zhang, Z. et al.: Secret Use of Large Language Model (LLM). Proceedings of the ACM on Human-Computer Interaction. 9, 2, 1–26 (2025). https://doi.org/[10.1145/3711061](https://doi.org/10.1145/3711061).</span>"
   ],
   "id": "97e88c7b-d133-4bd8-9f9e-dfea00608ce6"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
